<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
           "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="GENERATOR" content="TtH 3.89" />
 <style type="text/css"> div.p { margin-top: 7pt;}</style>
 <style type="text/css"><!--
 td div.comp { margin-top: -0.6ex; margin-bottom: -1ex;}
 td div.comb { margin-top: -0.6ex; margin-bottom: -.6ex;}
 td div.hrcomp { line-height: 0.9; margin-top: -0.8ex; margin-bottom: -1ex;}
 td div.norm {line-height:normal;}
 span.roman {font-family: serif; font-style: normal; font-weight: normal;} 
 span.overacc2 {position: relative;  left: .8em; top: -1.2ex;}
 span.overacc1 {position: relative;  left: .6em; top: -1.2ex;} --></style>

                                                                                  
<title>freiesMagazin 12/2013</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<meta http-equiv="content-language" content="de" />
<meta name="publisher" content="Dominik Wagenführ" />
<meta name="author" content="freiesMagazin-Autoren" />
<meta name="description" content="Ubuntu und Kubuntu 13.10 | Der November im Kernelrückblick | GPU-Computing mit R | Äquivalente Windows-Programme unter Linux – Teil 2 | Mit OpenVPN Firmen-Firewalls überwinden | Diagramme in Linux – Vier Tabellenkalkulationen im Vergleich | Rückblick: DANTE-Herbsttagung in Köln | Rezension: Technisches Schreiben | Rezension: Linux Hochverfügbarkeit | Editorial | Veranstaltungen | Vorschau | Konventionen | Impressum" />
<meta name="keywords" content="freiesMagazin, freies, Magazin, Linux, Open Source" />
<meta name="copyright" content="CC-BY-SA 3.0 Unported" />
<meta name="issn" content="1867-7991" />
<meta name="title" content="freiesMagazin 12/2013" />
<meta name="language" content="German" />

<link type="text/css" rel="stylesheet" href="fm_mobil_2013_08.css" />

<link type="text/css" rel="stylesheet" href="freiesMagazin-2013-12-bilder-Dateien/fm_mobil_2016_05.css" />
</head>
<div id="content_idx">
<body style="font-family: sans-serif;"><font size="5"><a href="http://www.freiesmagazin.de/mobil/freiesMagazin-2013-12.html">Zur Version ohne Bilder</a></font><hr class="sigilChapterBreak" />


<font size="+4"><b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font>&nbsp;<font color="#595959"><b>Dezember 2013</b></font></font><br />
<font size="+2">(ISSN 1867-7991)</font><br />

<div class="p"><!----></div>
                        
<h1><font color="#595959"><a id="fm_inhalt" name="fm_inhalt">Topthemen dieser Ausgabe</a></font></h1>


    <font size="+1"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_ubuntu_und_kubuntu_13_10">Ubuntu und Kubuntu 13.10</a></font> <br />
    Ubuntu 13.10 „Saucy Salamander“ bereitet den Weg zur nächsten LTS-Version. Der Artikel soll ein wenig untersuchen, wie es mit der Qualität der Distribution bestellt ist, in dessen Entwicklungszyklus der Hauptaugenmerk von Canonical vor allem auf der Mobilversion „Ubuntu Touch“ lag. Ebenso soll ein Blick auf Kubuntu 13.10 geworfen werden. (<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_ubuntu_und_kubuntu_13_10">weiterlesen</a>) <br />
    <br />

<div class="p"><!----></div>
    <font size="+1"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_gpu_computing">GPU-Computing mit R</a></font> <br />
    Der Artikel bietet eine Einführung in GPU-Computing mit dem Statistikprogramm R. Besitzer von Grafikkarten mit NVIDIA-Chipsatz haben unter Nutzung des „NVIDIA CUDA-Toolkits“ und des R-Pakets „gputools“ die Möglichkeit, parallelisierbare Rechenaufgaben auf ihrer GPU auszuführen. Entsprechende Installationsanleitungen versetzen den Leser in die Lage, eine R-CUDA-Schnittstelle zu implementieren und für einfache mathematisch-statistische Rechenoperationen zu nutzen. (<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_gpu_computing">weiterlesen</a>) <br />
    <br />

<div class="p"><!----></div>
    <font size="+1"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_tabellenkalkulationen">Diagramme in Linux – Vier Tabellenkalkulationen im Vergleich</a></font> <br />
    Tabellenkalkulationen sind aus der Arbeitswelt kaum noch wegzudenken. Eine ihrer Stärken ist die schnelle Visualisierung tabellarischer Daten in Diagrammen. Unter Linux gibt es eine Reihe freier („Free and Open Source Software“) Tabellenkalkulationen, die unterschiedliche Ansätze zur Diagrammerstellung verfolgen. (<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_tabellenkalkulationen">weiterlesen</a>) <br />
    <br />

<div class="p"><!----></div>
<a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
              

                        
<h1><font color="#595959"><a id="fm_index" name="fm_index">Inhalt</a></font></h1><!-- CONTENT -->

<b>Linux allgemein</b><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_ubuntu_und_kubuntu_13_10">Ubuntu und Kubuntu 13.10</a><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_kernel">Der November im Kernelrückblick</a><br /><!-- CONTENT -->
<br /><!-- CONTENT -->
<b>Anleitungen</b><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_gpu_computing">GPU-Computing mit R</a><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_aequivalente_windows_programme_2">Äquivalente Windows-Programme unter Linux – Teil 2</a><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_openvpn">Mit OpenVPN Firmen-Firewalls überwinden</a><br /><!-- CONTENT -->
<br /><!-- CONTENT -->
<b>Software</b><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_tabellenkalkulationen">Diagramme in Linux – Vier Tabellenkalkulationen im Vergleich</a><br /><!-- CONTENT -->
<br /><!-- CONTENT -->
<b>Community</b><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_dante_herbst2013">Rückblick: DANTE-Herbsttagung in Köln</a><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_rezension_technisches_schreiben">Rezension: Technisches Schreiben</a><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_rezension_linux_hochverfuegbarkeit">Rezension: Linux Hochverfügbarkeit</a><br /><!-- CONTENT -->
<br /><!-- CONTENT -->
<b>Magazin</b><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_editorial">Editorial</a><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_veranstaltungen">Veranstaltungen</a><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_vorschau">Vorschau</a><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_konventionen">Konventionen</a><br /><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_13_12_impressum">Impressum</a><br /><!-- CONTENT -->



<div class="p"><!----></div><!-- CONTENT -->
<a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" /><!-- CONTENT -->

<div class="p"><!----></div>
<h1><font color="#595959"><a id="fm_13_12_editorial" name="fm_13_12_editorial">Editorial</a></font></h1>
    



<h2>Kein Editorial</h2>


Das Editorial zum Jahresabschluss wird dieses Mal von dem Wörtchen „kein“ 
überschattet. Immerhin gibt es wieder ein Editorial! Nur einem Leser ist 
aufgefallen, dass wir in der Novemberausgabe von <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> kein Editorial 
hatten.

<div class="p"><!----></div>
Der Grund dafür war einfach Zeitmangel! Natürlich hat der Tag bei uns wie 
bei jeder anderen Person auch volle 24 Stunden, aber oft stehen viele andere 
Dinge gleichzeitig an, sodass nicht immer für alles Zeit bleibt.

<div class="p"><!----></div>
So fanden im Oktober einige Messen und Veranstaltungen statt und durch den 
Weggang eines Redaktionsmitgliedes hatten die zwei verbliebenen Redakteure 
nicht mehr die Zeit gefunden, ein Editorial zu schreiben.

<div class="p"><!----></div>

<h2>Kein Programmierwettbewerb</h2>


Aus dem gleichen Grund gibt es auch im Dezember keinen neuen 
Programmierwettbewerb. Wir hatten im September noch die Hoffnung gehabt, 
wenigstens einen Wettbewerb auf die Beine zu stellen&nbsp;<a href="http://www.freiesmagazin.de/20130909-ergebnisse-der-abstimmung-fuer-programmi
erwettbewerb">[1]</a>. Da Dominik Wagenführ, Ausrichter des jährlichen Wettbewerbs, 
aber privat und beruflich eingespannt ist, wird es leider keinen geben.

<div class="p"><!----></div>
Der Wettbewerb wird damit verschoben und findet vielleicht im Januar 2014 
statt. Das Interesse bei den Lesern war da, wie wir bei der Umfrage gesehen 
haben.

<div class="p"><!----></div>

<h2>Keine Leserbriefe</h2>


Was dagegen niemanden aufgefallen war, waren die fehlenden Leserbriefe in 
der Novemberausgabe von <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font>. Und auch diesen Monat haben wir nur zwei 
Zusendungen erhalten (siehe weiter unten), die aber nicht eine ganze Seite 
einnehmen können, weswegen es auch diesen Monat keine Leserbriefe gibt.

<div class="p"><!----></div>
Passenderweise trifft ein Leserbrief von Adolf Winterer aber genau das Thema 
des Editorials dieser Ausgabe. Er fragte uns, ob wir nicht Flattr einsetzen 
wollen, um einem Lob in einem Leserbrief noch mehr Nachdruck verleihen zu 
können.

<div class="p"><!----></div>
Das Thema Flattr hatten wir vor drei Jahren schon einmal im Editorial von
<b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> 06/2013&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2010-06">[2]</a> 
ausführlich behandelt. Neben zahlreiche steuerrechtlichen, lizenzrechtlichen 
und verwendungstechnischen Problemen, die Flattr mitbringt, haben wir uns 
bei <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> entschieden, kein Geld für unsere Arbeit anzunehmen. Alle Autoren 
und alle Helfer sollen freiwillig ihre Zeit opfern. Selbst wenn 1000 Euro 
eingehen, wäre die Frage einer gerechten Verteilung auf die Autoren, 
Layouter, Lektoren und Redakteure nahezu unmöglich zu beantworten.

<div class="p"><!----></div>
Zusätzlich können wir mit (mehr) Geld nichts anfangen, denn dies führt nicht 
dazu, dass neue Artikel geschrieben werden (dazu unten mehr) oder sich das 
Magazin von alleine setzt. Auch

wenn es für viele einfacher ist, mit einem Klick 
einen Euro zu spenden, benötigen wir viel mehr helfende Hände.

<div class="p"><!----></div>
Daher sind Leserbriefe, die sich mit den Artikeln und Beiträgen in <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> 
auseinandersetzen, auch viel wertvoller als Geld. Denn wenn sich ein Leser 
die Zeit nimmt, ein paar Zeilen zu schreiben und abzusenden, sehen der Autor 
und die Redaktion, dass die geschriebenen Texte nicht umsonst waren oder 
in den Weiten des Netzes untergegangen sind.

<div class="p"><!----></div>
Wenn Sie also Ihre Wertschätzung für das Magazin und die Artikel darin zum 
Ausdruck bringen wollen, schreiben Sie uns per E-Mail <img src="freiesMagazin-2013-12-bilder-Dateien/redaktionmail.png" alt="redaktion ETT freiesmagazin PUNKT de" height="17" width="168" align="top" /> oder über 
den Kommentarlink am Ende der Seite. Das Gefühl, dass das eigene Werk 
gelesen wird, bedeutet vielen Autoren wesentlich mehr als Geld.

<div class="p"><!----></div>

<h2>Keine Artikel</h2>


Und was bei den Leserbriefen anfängt, setzt sich bei den Artikeln fort. 
Anstatt nur einfach zu „jammern“, dass wir zu wenig Artikel haben, soll ein 
kleiner Einblick in unsere Redaktionsarbeit und den Kontakt mit den Autoren 
gegeben werden.

<div class="p"><!----></div>
Im letzten Jahr (seit 1. November 2013) haben uns 32 neue Autoren 
angeschrieben und angeboten, einen Artikel für <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> zu schreiben. Das war 
entweder das Angebot irgendetwas zu schreiben oder es wurden schon fertige 
Entwürfe eingereicht. Wenn man rechnet, dass wir pro Monat circa acht Artikel 
im Magazin veröffentlichen (also 96 im Jahr), ist allein das nur ca. 
ein Drittel des Bedarfs für das Magazin.

<div class="p"><!----></div>
Von diesen 32 Angeboten sind nur elf Artikel tatsächlich fertig geworden, sieben 
Angebote sind derzeit noch offen. Einige Autoren haben sich nach dem ersten 
Kontakt nie wieder gemeldet. Selbst auf mehrfache Anfrage haben sich zehn 
Autoren nicht mehr gemeldet. Immerhin vier Absagen gab es auf eine Nachfrage 
hin. Eigenständige Absagen (wegen anderer Verpflichtungen, 
Interessenwechsel etc.) gab es keine.

<div class="p"><!----></div>
Das heißt also, von nahezu der Hälfte der Autoren hören wir nie wieder etwas 
bzw. das Angebot wird zurückgenommen. Der jährliche Bedarf von <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> wird 
damit also nur noch zu einem Sechstel durch neue Autoren abgedeckt. Dieser 
Wert ist erschreckend gering.

<div class="p"><!----></div>
Da sich viele Autoren leider gar nicht mehr zurückmelden, können wir auch 
nicht genau sagen, wo die Gründe hierfür liegen. Bei den Autoren, die sich 
melden und absagen, hat es meistens mit veränderten Lebenssituationen zu 
tun, sodass eine Absage absolut verständlich ist.

<div class="p"><!----></div>
Natürlich könnten wir jetzt verzweifeln und <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> aufgeben, wäre da nicht 
dieses eine Sechstel von neuen Autoren, die Artikel abliefern. Manchmal führt 
das dazu, dass daraus auch ein zweiter oder dritter Artikel entsteht. Und 
dann haben wir in der Redaktion eine relative Sicherheit, dass der Autor 
wieder etwas Gutes abliefert.

<div class="p"><!----></div>
Dieses lange Editorial ist daher allen freiwilligen Autoren gewidmet, die 
sehr viel Zeit in das Schreiben der Artikel für <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> investieren. Vor allem 
wollen wir aber auch allen danken, die Wiederholungstäter sind und, wenn auch 
nicht regelmäßig jeden Monat, aber zumindest ab und an etwas zum Magazin 
beitragen. Wer sich von Ihnen auch in diesen Kreis einreihen möchte, kann 
uns ja unter <img src="freiesMagazin-2013-12-bilder-Dateien/redaktionmail.png" alt="redaktion ETT freiesmagazin PUNKT de" height="17" width="168" align="top" /> einfach einen Artikelvorschlag zusenden. Der Weg ins 
Magazin ist nicht so schwer, wenn beide Seiten in Kontakt bleiben.

<div class="p"><!----></div>
Aber natürlich dankt die Redaktion zum Jahresende auch noch dem ganzen 
<b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font>-Team für die teilweise langjährige Hilfe beim Korrigieren und Setzen der 
Artikel. Wir wissen alle, welche Arbeit darin steckt und freuen uns, dass 
sich ein Gruppe gefunden hat, die an der Verteilung freien Wissens Spaß 
gefunden hat.

<div class="p"><!----></div>
Abschließend wünschen wir allen Lesern, Autoren und Teammitglieder ein 
schönes Weihnachtsfest und hoffen, dass wir 2014 wieder viele 
interessante Themen im Magazin präsentieren können.

<div class="p"><!----></div>
Ihre <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font>-Redaktion

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="http://www.freiesmagazin.de/20130909-ergebnisse-der-abstimmung-fuer-programmierwettbewerb"><tt class="big">http://www.freiesmagazin.de/20130909-ergebnisse-der-abstimmung-fuer-programmierwettbewerb</tt></a><br />
[2] <a href="http://www.freiesmagazin.de/freiesMagazin-2010-06"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2010-06</tt></a><br />
    

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=Editorial#comment-form"><i>Das Editorial kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>



<h1><font color="#595959"><a id="fm_13_12_ubuntu_und_kubuntu_13_10" name="fm_13_12_ubuntu_und_kubuntu_13_10">Ubuntu und Kubuntu 13.10</a></font></h1>von Hans-Joachim Baader

<div class="p"><!----></div>
    <b>U</b><b>buntu 13.10 „Saucy Salamander“ bereitet den Weg zur nächsten LTS-Version. 
Der Artikel soll ein wenig untersuchen, wie es mit der Qualität der 
Distribution bestellt ist. Ebenso soll ein Blick auf Kubuntu 13.10
geworfen werden.</b>

<div class="p"><!----></div>
<b>Redaktioneller Hinweis:</b> <i>Der Artikel „Ubuntu und Kubuntu 13.10“ erschien erstmals bei
Pro-Linux&nbsp;<a href="http://www.pro-linux.de/artikel/2/1655/ubuntu-und-kubuntu-1310.html">[1]</a>.</i>

<div class="p"><!----></div>

<h2>Vorwort</h2>


Planmäßig erschien Ubuntu 13.10 „Saucy Salamander“ ein halbes Jahr nach 
Version 13.04. Schon die Ankündigung seitens Canonical machte klar, dass die 
meiste Arbeit im letzten halben Jahr wohl in die Mobilversion „Ubuntu Touch“ 
mit dem neuen Display-Server Mir geflossen ist. Diese Variante soll aber 
nicht Gegenstand des Artikels sein, der sich auf Ubuntu und Kubuntu 
beschränkt. Somit ist zu erwarten, dass die neue Version, die nur neun 
Monate lang mit Updates versorgt wird, „bemerkenswert unbemerkenswert“ 
ausfällt. Zahlreiche Software-Updates gab es natürlich, aber kaum eines 
davon stellt einen großen Bruch mit der Vorversion dar.

<div class="p"><!----></div>
Wie immer sei angemerkt, dass es sich hier nicht um einen Test der 
Hardwarekompatibilität handelt. Es ist bekannt, dass Linux mehr Hardware 
unterstützt als jedes andere Betriebssystem, und das überwiegend bereits im 
Standard-Lieferumfang.
Ein Test spezifischer Hardware wäre zu viel Aufwand 
für wenig Nutzen. Falls man auf Probleme mit der Hardware stößt, stehen die 
Webseiten von Ubuntu zur Lösung bereit.

<div class="p"><!----></div>
Da eine Erprobung auf realer Hardware nicht das Ziel des Artikels ist, 
werden für den Artikel zwei identische virtuelle Maschinen, 64 Bit, unter 
KVM mit jeweils 1024 MB RAM verwendet. In der ersten wurde Ubuntu 
installiert, in der anderen Kubuntu.

<div class="p"><!----></div>

<h2>Installation</h2>


Ubuntu wird meist von einem Live-System aus installiert, das als ISO-Image 
zum Download bereitsteht. In der aktuellen Version ist es auf eine Größe von 
0,9 bis 1,0 GB je nach Variante angewachsen. Dieses Desktop-Image kann auf 
DVD oder einem USB-Medium verwendet werden.

<div class="p"><!----></div>
Das Installationsprogramm Ubiquity bietet ähnlich wie der Debian-Installer 
oder Anaconda von Fedora jetzt alle Möglichkeiten an, die Festplatten zu 
partitionieren und das System darauf zu installieren. Die gesamte Festplatte 
oder einzelne Partitionen können verschlüsselt werden und LVM wird 
unterstützt, auch in Form einer automatischen Partitionierung.

<div class="p"><!----></div>
Der Speicherbedarf wird dieses Mal in der vernachlässigt wirkenden 
Dokumentation bei der Desktop-Version auf 512 MB beziffert, beim Server auf 
256 MB. Unter Umständen soll eine Installation mit 64 MB RAM bereits 
gelingen. Zu empfehlen sind jedoch auf dem Desktop mindestens ein GB, so dass 
alle benötigten Anwendungen zugleich ohne zu swappen laufen können, denn nur 
so läuft das System vollständig flüssig.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-beginn-der-installation.jpg" alt="ubuntu1310-beginn-der-installation.jpg" style="max-width:100%" /><br /><em>Beginn der Installation.</em><br />

<div class="p"><!----></div>
Hier soll nur die Installation von der Desktop-DVD kurz vorgestellt werden. 
Die Installation unterlag nur wenigen sichtbaren Änderungen gegenüber der 
letzten Version. Standardmäßig wird nur eine einzige große Partition mit dem 
Dateisystem ext4 sowie eine Swap-Partition angelegt. Wenn man LVM einsetzt, 
kommt noch eine 230 MB große ext2-Partition für <b><tt class="big">/boot</tt></b> hinzu. Will man 
seine Partitionierung selbst definieren, muss man „<em>Etwas anderes</em>“ 
auswählen, wodurch das 

Partitionierungswerkzeug gestartet wird. Dort können 
die gängigen Dateisysteme einschließlich Btrfs ausgewählt werden.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-auswahl-der-installationsart.jpg" alt="ubuntu1310-auswahl-der-installationsart.jpg" style="max-width:100%" /><br /><em>Auswahl der Installationsart.</em><br />

<div class="p"><!----></div>
Direkt nach der Definition der Partitionen beginnt der Installer mit der 
Partitionierung und der Installation der Pakete im Hintergrund. Ein 
Fortschrittsbalken zeigt von hier an den Stand der Installation an. Parallel 
dazu kann man die Zeitzone auswählen und danach das gewünschte 
Tastatur-Layout einstellen.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-laufende-installation.jpg" alt="ubuntu1310-laufende-installation.jpg" style="max-width:100%" /><br /><em>Laufende Installation.</em><br />

<div class="p"><!----></div>
Im letzten Schritt gibt man seinen Namen, Anmeldenamen, Passwort und den 
Computernamen ein. Wenn zuvor bereits per DHCP ein Name ermittelt werden 
konnte, wird dieser als Vorgabe angezeigt. Wenn erkannt wird, dass die 
Installation in einer virtuellen Maschine läuft, wird
dagegen der Name 
<b><tt class="big">benutzer-virtual-machine</tt></b> vorgegeben. Optional können Daten im 
Home-Verzeichnis verschlüsselt werden. Während man das Ende der Installation 
abwartet, kann man nun noch einige Tipps zu Ubuntu ansehen.

<div class="p"><!----></div>

<h2>Ausstattung</h2>


Sowohl Ubuntu als auch Kubuntu starten ähnlich schnell wie in den 
Vorversionen. Ubuntu setzt eigentlich eine Hardware-3-D-Beschleunigung 
voraus, Kubuntu dagegen nicht. Bei Grafikkarten, die keine 
Hardware-3-D-Beschleunigung bieten, wird auf <b><tt class="big">llvmpipe</tt></b> zurückgegriffen, 
das die 3-D-Funktionen in Software emuliert. Bei einer ausreichend schnellen 
CPU ist das Verfahren von der Geschwindigkeit etwas besser als in den ersten 
Versionen, aber immer noch gerade so erträglich. Überraschenderweise ist es 
inzwischen aber

schnell genug, um sogar kleine Videos abzuspielen.

<div class="p"><!----></div>
Das Grafiksystem ist bei X.org 7.7 geblieben,
da es in der Zwischenzeit keine neue Version gab.
Allerdings wurden einige Komponenten von 
X.org aktualisiert, darunter der X-Server 1.14.3 und Mesa 9.2. Unity liegt 
in Version 7.1 vor.

<div class="p"><!----></div>
Unter den größten Änderungen seit Ubuntu 13.04 findet sich der Linux-Kernel, 
der auf Version 3.11.3 aktualisiert wurde. Aus Benutzersicht bedeutet das 
eine Vielzahl zusätzlicher Treiber und viele Optimierungen. Daneben enthält 
der Kernel viele neue Features, die nur für Spezialisten von Interesse sind.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-login-bildschirm.jpg" alt="ubuntu1310-login-bildschirm.jpg" style="max-width:100%" /><br /><em>Log-in-Bildschirm von Ubuntu.</em><br />

<div class="p"><!----></div>
Das Init-System Upstart ermöglicht in Version 1.10 Jobs, die auf Änderungen 
im Dateisystem reagieren, und das neue zugehörige Werkzeug 
<b><tt class="big">upstart-monitor</tt></b> ermöglicht das Beobachten von Ereignissen in Echtzeit. In 
den Desktop-Varianten&nbsp;<a href="https://wiki.ubuntu.com/SaucySalamander/ReleaseNotes">[2]</a> 
erhielt Upstart zudem Benutzersitzungen.

<div class="p"><!----></div>
Das Drucksystem CUPS konnte von allen Ubuntu-spezifischen Anpassungen 
befreit werden. In CUPS 1.6.2 wurde durch die OpenPrinting-Arbeitsgruppe der 
Linux Foundation eine mit früheren Versionen kompatible Erkennung von 
Netzwerkdruckern implementiert&nbsp;<a href="https://wiki.ubuntu.com/OpenPrinting">[3]</a>. 
CUPS wurde außerdem in mehr Pakete aufgeteilt, so dass es unterschiedlichen 
Anforderungen besser gerecht wird.

<div class="p"><!----></div>
Für Entwickler stehen GCC 4.8.1, Python 2.7.5 und 3.3.2, OpenJDK 6b27 und 
7u25 und vieles mehr bereit. Python 3.3 ist die installierte Version von 
Python, doch da sowohl innerhalb des Ubuntu-Archivs als auch außerhalb noch 
viele Pakete auf Python 2 beruhen, ist auch diese Version installierbar. 
AppArmor&nbsp;<a href="https://wiki.ubuntu.com/AppArmor">[4]</a> kann jetzt auch den Zugriff 
auf D-Bus und Unix-Sockets kontrollieren, und eigene Richtlinien sollen sich 
leichter erstellen lassen.

<div class="p"><!----></div>
Kubuntu&nbsp;<a href="http://www.kubuntu.org/news/kubuntu-13.10">[5]</a> enthält in Version 
13.10 KDE SC 4.11, das unter anderem eine schnellere Indexierung bei Nepomuk 
und Verbesserungen in der PIM-Suite Kontact bringt und den Grundstein für 
einen späteren Umstieg auf Wayland und Qt 5 legt. Die Dokumentation von 
Kubuntu ist zurück. Dazu kommen „Muon Discover“, eine nach Entwicklerangaben 
„<em>benutzerfreundliche Art, Anwendungen zu entdecken und zu installieren</em>“, 
ein neuer Benutzer-Manager, KDE Telepathy 0.6.2 mit verbessertem Editieren 
von Text und verbesserten Benachrichtigungen und ein neues Network 
Manager-Applet. Bei der Installation kann nun auch WLAN eingerichtet werden.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-login-bildschirm-kubuntu.jpg" alt="ubuntu1310-login-bildschirm-kubuntu.jpg" style="max-width:100%" /><br /><em>Log-in-Bildschirm von Kubuntu.</em><br />

<div class="p"><!----></div>
Wie gewohnt hat Root keinen direkten Zugang zum System, sondern die Benutzer 
der Gruppe <b><tt class="big">sudo</tt></b> können über das Kommando <b><tt class="big">sudo</tt></b> Befehle als Root ausführen.

<div class="p"><!----></div>
Der Speicherverbrauch von Unity ist augenscheinlich noch weiter gewachsen. 
Nicht weniger als 660 MB benötigt die Umgebung allein, ohne dass 
irgendwelche produktive Software gestartet wurde. Davon benötigt Compiz 
bereits 365 MB. KDE benötigt in der Standardinstallation mit einem 
geöffneten Terminal-Fenster etwa 430 MB. Die Messung des Speicherverbrauchs 
der Desktops kann jeweils nur ungefähre Werte ermitteln, die zudem in 
Abhängigkeit von der Hardware und anderen Faktoren schwanken. Aber als 
Anhaltspunkt sollten sie allemal genügen.

<div class="p"><!----></div>

<h2>Unity</h2>


Die Neuerungen in Unity, der offiziellen Desktopumgebung von Ubuntu, halten 
sich in Grenzen. Unity erhielt neue „intelligente Sichten“. Diese 
ermöglichen es, nach eingegebenen Suchbegriffen in mehr als 50 
Online-Quellen zu suchen und die Ergebnisse übersichtlich darzustellen. 
Dabei sollen die erkannten Benutzervorlieben berücksichtigt werden.

<div class="p"><!----></div>
Die Suchfunktion, die standardmäßig auch Online-Shops und andere 
Online-Quellen umfasst, lässt nach wie vor die Frage nach dem Datenschutz 
aufkommen. Einige der Suchanfragen gehen über einen Proxy-Server von Ubuntu 
und werden durch HTTPS verschlüsselt. Andere gehen der 
Datenschutzerklärung&nbsp;<a href="http://www.ubuntu.com/privacy-policy">[6]</a> zufolge 
direkt an „ausgewählte Drittanbieter“. Die preisgegebenen Daten sollten sich 
auf die Suchbegriffe und die IP-Adresse beschränken. Dass Ubuntu und andere 
Anbieter daraus Statistiken generieren, darf angenommen werden. Das ist 
jedoch üblich und sollte den Unternehmen auch nicht angekreidet werden, 
solange sie damit nur versuchen, ihr Angebot zu optimieren.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-unity-suche.jpg" alt="ubuntu1310-unity-suche.jpg" style="max-width:100%" /><br /><em>Übersichtsseite von Unity mit Ergebnissen der Suche im Netz.</em><br />

<div class="p"><!----></div>
Ohnehin dürften die Anbieter kaum eine Möglichkeit haben, mit diesen Daten 
mehr anzufangen.
Denn anders als bei Webbrowsern, die fast

individuellen 
Benutzern zugeordnet werden können, sollte die Suchfunktion von Ubuntu eine 
solche Identifikation nicht möglich machen. Man sollte sich also nicht zu 
sehr darüber aufregen, dass die Funktion standardmäßig eingeschaltet ist.

<div class="p"><!----></div>
Das heißt natürlich nicht, dass die Netz-Suchfunktion tolerierbar ist; in 
den meisten Fällen ist sie einfach nur lästig und nutzlos und sollte 
abgeschaltet werden. Das Deaktivieren der Funktion ist weiterhin über einen 
Schalter in den Systemeinstellungen unter der Kategorie
„<em>Privatsphäre</em>“ 
möglich. Einzelne Linsen lassen sich wohl
nur durch die Deinstallation 
deaktivieren. Eine separate Shopping- oder Amazon-Linse gibt es jedoch 
nicht; eine feinere Auswahl als ein globales Ein oder Aus scheint nicht mehr 
möglich zu sein.

<div class="p"><!----></div>
Unity ist eigentlich nicht schlecht, aber es hat grundsätzliche Probleme. 
Eines davon ist Compiz, das auf dem Testsystem 365 MB RAM „frisst“, was das 
System natürlich nicht schneller macht. Andere Eigenschaften von Unity sind 
für manche Benutzer eine Freude, für andere eine Last.
Unity ist, wie GNOME 3, offenbar nur noch auf Mobilgeräte mit Touchscreen
ausgerichtet, und diesem Ziel wird jeglicher Benutzer-Komfort geopfert. 
Ohne massive Änderung der Konfiguration halte ich Unity auf dem Desktop für 
unbenutzbar. Die „verpeilten“ Scrollbalken, das umständliche globale Menü 
und die Anordnung der Fenster-Buttons auf der falschen Seite sind für mich 
weiterhin unakzeptabel. 
Die Fehlerhaftigkeit des Menükonzepts zeigt sich z.&nbsp;B. an Rhythmbox, für das 
nun außer Rechtsklick auf die Startleiste (und <b><tt class="big">kill</tt></b> auf der 
Kommandozeile) keine Möglichkeit mehr zum Beenden existiert. Doch wie 
gesagt, manche nutzen diese Funktionen gern, und wer will, kann es anders 
einstellen.

<div class="p"><!----></div>
Der Standard-Webbrowser in Ubuntu ist Firefox 24.0. LibreOffice ist in 
Version 4.1.2.3 vorinstalliert. Für E-Mails ist Thunderbird zuständig. Die 
sonstigen installierten Programme sind im Wesentlichen die 
Standard-Programme von GNOME, die zumindest grundlegend die häufigsten 
Aufgaben abdecken. In den meisten Fällen bieten sie gerade einmal 
Grundfunktionen, so dass man sich gerne nach leistungsfähigeren Programmen 
im Software-Center umsieht.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-firefox.png" alt="ubuntu1310-firefox.png" style="max-width:100%" /><br /><em>Firefox in Unity.</em><br />

<div class="p"><!----></div>
Für Software-Updates ist weiterhin die Software-Aktualisierung zuständig. 
Hat man das Software-Center geöffnet und startet die 
Aktualisierung,

wird der Fortschritt auch in der Icon-Leiste des 
Software-Centers angezeigt. Die Software-Aktualisierung selbst sortiert die 
Pakete jetzt nach Komponenten, von denen eine „Ubuntu-Kern“ heißt. Da diese 
anfänglich zugeklappt dargestellt wird, könnte man es für ein reines 
Kernel-Update halten, doch tatsächlich können darin mehrere einzelne Updates 
vorliegen.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-software-aktualisierungen.png" alt="ubuntu1310-software-aktualisierungen.png" style="max-width:100%" /><br /><em>Software-Aktualisierungen.</em><br />

<div class="p"><!----></div>
Für die Installation und Deinstallation von Paketen ist weiterhin 
das Software-Center zuständig, das in Version 13.10 vorliegt. Neue 
Funktionen sind gegenüber früheren Versionen nicht auszumachen. Das Angebot 
an proprietärer Software, die man über das Software-Center kaufen kann, ist 
schon recht stattlich. Den größten Anteil daran haben wohl Spiele, aber auch 
Hilfsprogramme und Produktivitätswerkzeuge werden angeboten.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-softwarecenter.png" alt="ubuntu1310-softwarecenter.png" style="max-width:100%" /><br /><em>Das Ubuntu-Software-Center.</em><br />

<div class="p"><!----></div>
Richtig konfigurierbar ist Unity auch weiterhin nicht. Es gibt in dieser 
Version keinerlei Einstellungen in den Systemeinstellungen. Einiges kann man 
über Compiz konfigurieren. Dazu muss man <b>compizconfig-settings-manager</b> 
(ccsm) nachinstallieren. Für noch mehr Konfigurierbarkeit sollte man auch 
<b>dconf-tools</b> installieren. Allerdings ist besonders letzteres Programm 
eher für Experten. Leicht zu benutzen ist dagegen <b>unity-tweak-tool</b>, bei 
dem etwas unklar ist, ob es etwas enthält, was nicht in den 
Systemeinstellungen
oder in CompizConfig zu finden ist.

„Ubuntu Tweak“ ist 
dagegen nicht mehr im Paketarchiv enthalten, möglicherweise ist es veraltet.

<div class="p"><!----></div>

<h2>KDE</h2>


In Kubuntu&nbsp;<a href="http://www.kubuntu.org/">[7]</a> wurde KDE SC auf die Version 4.11.2 
aktualisiert. Der Standard-Webbrowser in Kubuntu ist Rekonq, jetzt in 
Version 2.3.2. Als Musik-Player ist Amarok 2.8 vorinstalliert, das jetzt 
einige Oberflächenelemente der Version 1.x zurückbringt, die seit Version 
2.0 fehlten, und viele weitere kleine Funktionen hinzufügt. OwnCloud wurde 
in Version 5 aufgenommen, die die Benutzbarkeit, Geschwindigkeit und 
Sicherheit verbessern soll. OwnCloud ist allerdings nicht standardmäßig 
installiert, sondern nur in den Repositorys vorhanden. KDE PIM mit Kontact 
ist ebenfalls in Version 4.11.2 installiert. Außerdem sind LibreOffice, 
Krita und Firefox vorhanden. Weitere Anwendungen muss man aus den 
Repositorys nachinstallieren, wenn man sie braucht.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-rekonq.png" alt="ubuntu1310-rekonq.png" style="max-width:100%" /><br /><em>Rekonq.</em><br />

<div class="p"><!----></div>
Die Neuerungen und Verbesserungen in KDE SC 4.11 gegenüber der 
Vorgängerversion sind überwiegend klein, aber zahlreich und können

daher 
nicht alle genannt werden. Nur ein Teil davon ist überhaupt sichtbar. So 
wurde in der PIM-Suite Kontact 
unter anderem die 
Indexierung bei Nepomuk beschleunigt. Die Monitor-Konfiguration in den 
Systemeinstellungen wurde durch das neue KScreen ersetzt. Die Web Shortcuts 
wurden weiter verbessert und der Window-Manager KWin nutzt jetzt das 
XCB-Protokoll mit X11.

<div class="p"><!----></div>
Die Paketverwaltung Muon wurde auf Version 2.0.65 angehoben. Muon besteht 
aus drei

separaten Programmen, denn neben der Muon-Paketverwaltung und der 
zugehörigen Muon-Aktualisierungsverwaltung existiert noch Muon Discover, ein 
Ersatz für die frühere Muon-Programmverwaltung. Das neue Muon Discover 
erinnert ein wenig an das Software-Center, leistet jedoch noch längst nicht 
so viel. Es dient zum Finden von Anwendungen, kann aber auch Updates 
durchführen.
Witzig ist die Kategorie
Comics, die offenbar 
zahlreiche Plug-ins für das Applet <b>plasma-comics</b> enthält.


<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-muon-discover.png" alt="ubuntu1310-muon-discover.png" style="max-width:100%" /><br /><em>Muon Discover.</em><br />

<div class="p"><!----></div>
Mit Muon traten erhebliche Ungereimtheiten auf, die auch in diversen Foren 
schon berichtet wurden. Sie betreffen die Zahl der zu aktualisierenden 
Pakete. Während <b><tt class="big">apt-get</tt></b> beispielsweise zwölf zu aktualisierende Pakete 
meldet, besagt die KDE-Benachrichtigung, dass es fünf seien, und ein Aufruf der 
Muon-Aktualisierungsverwaltung ergibt schlicht, dass alle Pakete auf dem 
neuesten Stand wären. Die Aktualisierung über Muon Discover funktionierte 
hingegen genauso, wie es mit <b><tt class="big">apt-get</tt></b> funktioniert hätte. Letztlich macht 

die Software auch nichts anderes, als <b><tt class="big">apt-get</tt></b> aufzurufen und dessen 
Ausgaben im Fenster anzuzeigen.

<div class="p"><!----></div>
Wer KDE Plasma Active testen will, findet Version 0.5 in den Archiven. Das 
Paket <b>kubuntu-low-fat-settings</b> existiert dagegen nicht mehr, 
wahrscheinlich wurde das System inzwischen so weit verkleinert, dass das 
Paket unnötig wurde.

<div class="p"><!----></div>

<h2>Multimedia im Browser und auf dem Desktop</h2>


Nichts wesentlich Neues gibt es im Multimedia-Bereich. Firefox ist jetzt in 
Version 24 enthalten. Mehrere Plug-ins zum Abspielen von Videos in freien 
Formaten sind wie immer vorinstalliert. Die vorinstallierte Erweiterung 
„Ubuntu Firefox Modifications“ hat Version 2.8 erreicht. Weitere 
vorinstallierte Erweiterungen sorgen für die Integration mit Unity und den 
Ubuntu-Online-Accounts.

<div class="p"><!----></div>
Zum Testen von Web-Videos wurden tagesschau.de, heute.de und Youtube
ausgewählt. Ohne weiteres Zutun funktionieren Videos bei 
tagesschau.de und erstmals auch bei heute.de. Flash ist ein anderes 
Thema. Standardmäßig ist kein Flash-Player vorinstalliert, sodass sich kein 
Flash-Video abspielen lässt. Auf Youtube funktioniert dagegen der 
HTML5-Modus ganz ohne Flash. Die Tests wurden wegen der Langsamkeit von 
Unity auf ein Minimum beschränkt; flüssige Video-Wiedergabe ist mit 
<b><tt class="big">llvmpipe</tt></b> nicht möglich, auch wenn sie besser geworden ist.

<div class="p"><!----></div>
Unter KDE ist der vorinstallierte Webbrowser Rekonq 2.3.2 in den 
Grundfunktionen Firefox
ebenbürtig. Videos bei tagesschau.de und heute.de 
waren problemlos abspielbar. Youtube funktioniert im HTML5-Modus wie Firefox.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/ubuntu1310-video-in-rekonq.png" alt="ubuntu1310-video-in-rekonq.png" style="max-width:100%" /><br /><em>Video in Rekonq in Kubuntu.</em><br />

<div class="p"><!----></div>
Auf dem Unity-Desktop sollte in den bekannten Anwendungen Rhythmbox und 
Totem, das jetzt allerdings „Filmwiedergabe“ heißt, bei standardmäßig nicht 
unterstützten Formaten eine Dialogbox erscheinen, die eine Suche nach 
passenden GStreamer-Plug-ins ermöglicht und sie installiert. Wenn Ubuntu 
mehr als ein Paket findet, das geeignet ist, kann man auswählen, welches 
installiert werden soll. Beim MP3-Format sind das beispielsweise ein 
Fluendo-Plug-in und eine GStreamer-Plug-in-Sammlung. Es ist zu empfehlen, 
das Fluendo-Plug-in zu ignorieren, so dass das FFmpeg-Plug-in installiert wird.

<div class="p"><!----></div>
Wie schon früher funktioniert die Erkennung der benötigten Formate meistens 
leider nicht. Es kann also unter Umständen nötig sein, weitere 
GStreamer-Pakete von Hand zu installieren, beispielsweise für das 
MPEG2-Format. Es kann außerdem passieren, dass beim ersten Installationslauf 
nicht alle benötigten Plug-ins installiert wurden – wahrscheinlich ist 
dieser Mechanismus nur für das Nachladen einzelner Plug-ins gedacht. Daher 
sollte man, wenn man es weiß, im Software-Center gleich alle 
GStreamer-Plug-ins installieren, und vielleicht noch andere Player wie VLC 
dazu. Schaden kann es nicht. Normalerweise muss Totem noch einmal neu 
gestartet werden, um die neuen Plug-ins zu erkennen.

<div class="p"><!----></div>
Unter KDE sieht es im Prinzip genauso aus, nur dass die Geschwindigkeit auch 
ohne 3-D-Hardware akzeptabel ist. Amarok ist der Standard-Audioplayer. 
Amarok oder Dragonplayer erkennen fehlende Plug-ins und starten die 
Paketverwaltung, ähnlich wie bei GNOME. Sinnvoller ist es aber auch hier, 
die GStreamer-Plug-ins schon vorab zu installieren. Zu beachten ist dabei 
allerdings, dass KDE noch GStreamer 0.10 verwendet.

<div class="p"><!----></div>

<h2>Fazit</h2>


Wie immer, wenn es keine revolutionären Neuerungen gibt, fühlt man sich 
versucht, zu schreiben, dass es an Neuerungen fehlt. Tatsächlich gibt es 
allerdings Neuerungen, die einfach nur zu zahlreich sind, sie alle zu 
erwähnen. Schon die aktualisierten Programme bringen zahllose Erweiterungen 
und Korrekturen. Dabei sind das durchweg Verbesserungen; Verschlechterungen 
lassen sich in Ubuntu 13.10 nicht ausmachen.

<div class="p"><!----></div>
Somit ist Ubuntu 13.10 wie gewohnt von hoher Qualität, allerdings muss die 
vernachlässigte Dokumentation kritisiert werden, die sich in größeren Lücken 
sowohl in den Anmerkungen zur Veröffentlichung als auch in den Artikeln auf 
der Webseite äußert. Man sollte Ubuntu-Versionen, die keine LTS-Versionen 
sind, trotzdem weiterhin mehr oder weniger als Betaversionen betrachten. Wie 
immer liegen inzwischen in den einschlägigen Foren auch Berichte über 
Probleme mit dem Update vor. Ihre Zahl hält sich allerdings in Grenzen und 
es muss offen bleiben, wie viele davon durch Faktoren verursacht wurden, auf 
die Ubuntu keinen direkten Einfluss hat.

<div class="p"><!----></div>
Stellt man tatsächlich einmal Mängel fest, kann man oft damit leben oder es 
existiert ein Workaround. Zudem werden im Laufe der Zeit durch Updates viele 
Probleme behoben. Man kann das unterstützen, indem man Fehler meldet. In 
diesem Fall sollte man dann natürlich auch am Ball bleiben, auf Rückfragen 
reagieren und regelmäßig im Bugtracker&nbsp;<a href="https://bugs.launchpad.net/">[8]</a> 
nachsehen.

<div class="p"><!----></div>
Benutzern, die auf größtmögliche Stabilität Wert legen, sei empfohlen, bei 
einer der LTS-Versionen von Ubuntu zu bleiben. Alle anderen, von Einsteigern 
bis zu erfahrenen Anwendern und Entwicklern, können auch mit Ubuntu 13.10 
gut auskommen. Wer sicher gehen will, nicht zu viele Probleme zu erleben, 
sollte (wie fast immer) die Updates der ersten Wochen abwarten.

<div class="p"><!----></div>
Die Wahl des Desktop-Systems bleibt weiterhin eine Geschmacksfrage. Aber ob 
Unity, KDE, GNOME, Cinnamon, Enlightenment E17, Xfce, LXDE oder eine andere 
Oberfläche, letztlich kann jeder Benutzer selbst wählen und den Desktop 
weitgehend seinen Ansprüchen anpassen. Unter Linux herrscht, anders als 
anderswo, eben keine Einfalt auf dem Desktop.

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="http://www.pro-linux.de/artikel/2/1655/ubuntu-und-kubuntu-1310.html"><tt class="big">http://www.pro-linux.de/artikel/2/1655/ubuntu-und-kubuntu-1310.html</tt></a><br />
[2] <a href="https://wiki.ubuntu.com/SaucySalamander/ReleaseNotes"><tt class="big">https://wiki.ubuntu.com/SaucySalamander/ReleaseNotes</tt></a><br />
[3] <a href="https://wiki.ubuntu.com/OpenPrinting"><tt class="big">https://wiki.ubuntu.com/OpenPrinting</tt></a><br />
[4] <a href="https://wiki.ubuntu.com/AppArmor"><tt class="big">https://wiki.ubuntu.com/AppArmor</tt></a><br />
[5] <a href="http://www.kubuntu.org/news/kubuntu-13.10"><tt class="big">http://www.kubuntu.org/news/kubuntu-13.10</tt></a><br />
[6] <a href="http://www.ubuntu.com/privacy-policy"><tt class="big">http://www.ubuntu.com/privacy-policy</tt></a><br />
[7] <a href="http://www.kubuntu.org/"><tt class="big">http://www.kubuntu.org/</tt></a><br />
[8] <a href="https://bugs.launchpad.net/"><tt class="big">https://bugs.launchpad.net/</tt></a><br />
    

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="1" align="center"><b>Autoreninformation</b></td></tr>
<tr><td align="left"><b>Hans-Joachim Baader</b>&nbsp;(<a href="http://www.pro-linux.de/">Webseite</a>)
befasst sich seit 1993 mit Linux. 1994 schloss er erfolgreich sein 
Informatikstudium ab, machte die Softwareentwicklung zum Beruf und ist einer 
der Betreiber von Pro-Linux.de. 
    </td></tr></table>
<br />

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=Ubuntu und Kubuntu 13.10#comment-form"><i>Diesen Artikel kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
<h1><font color="#595959"><a id="fm_13_12_kernel" name="fm_13_12_kernel">Der November im Kernelrückblick</a></font></h1>von Mathias Menzer

<div class="p"><!----></div>
    <b>B</b><b>asis aller Distributionen ist der Linux-Kernel, der fortwährend
weiterentwickelt wird. Welche Geräte in einem halben Jahr unterstützt werden und
welche Funktionen neu hinzukommen, erfährt man, wenn man den aktuellen
Entwickler-Kernel im Auge behält.</b>

<div class="p"><!----></div>

<h2>Linux 3.12</h2>


Auf eine achte Entwicklerversion hatte Torvalds verzichtet, am ersten 
November-Wochenende wurde die Kernel-Version 3.12 
veröffentlicht&nbsp;<a href="https://lkml.org/lkml/2013/11/3/160">[1]</a>. Sie hatte 62 Tage zum
Reifen und stellt damit eine der schnellsten Entwicklungen dar, insbesondere
wenn man berücksichtigt, dass das diesjährige Kernel 
Summit&nbsp;<a href="http://events.linuxfoundation.org/events/linux-kernel-summit">[2]</a> in den
Entwicklungszeitraum fiel. Trotzdem rangiert sie mit fast 12000 Änderungen
immerhin im Mittelfeld und braucht sich auch nicht hinsichtlich der Neuerungen
zu verstecken.

<div class="p"><!----></div>

<h3>Grafik</h3>


Der neue Linux-Kernel ermittelt die richtige Taktfrequenz für die
jeweilige Situation nun mittels einer neuen Methode. Diese verhindert unter
anderem, dass die Ergebnisse innerhalb kleiner Zeiträume stark variieren und
verschaffte damit den Radeon-Grafikchips von AMD/ATI einen Leistungszuwachs. Wie
das Portal Phoronix.com feststellen 
konnte&nbsp;<a href="http://www.phoronix.com/scan.php?page=article&amp;item=amd_linux312_preview">[3]</a>,
ist dies darauf zurückzuführen, dass
stark schwankende Taktraten die Leistung der Grafikkomponenten erheblich
beeinträchtigten. Weitere Änderungen an der Infrastruktur für die Radeon-
Chipsätze sind Erweiterungen des mit Linux 3.11 eingeführten Dynamischen
Energiemanagements (DPM). Es unterstützt nun weitere Chipsätze, ist jedoch nach
wie vor in der Standardkonfiguration nicht aktiviert.

<div class="p"><!----></div>
Systeme, die mehrere Grafikprozessoren (GPU) besitzen, profitieren von
Änderungen an den Grafik-Treibern, die nun das Umschalten zwischen den
verschiedenen GPUs ohne zusätzliche Treiber, Skripte oder sonstigen Hacks
erlauben. Die macht zum Beispiel bei Notebooks Sinn, die neben einer sparsamen
Grafikeinheit eine sehr leistungsstarke und -hungrige GPU aufweisen. Je nach
Anwendungsfall kann nun mit Bordmittel zwischen den beiden gewechselt werden.

<div class="p"><!----></div>
Eine weitere Änderung im Grafikbereich trennt nun das Rendern der
Bildschirmanzeige vom Umschalten der Grafik- und Displaymodi. Damit wird der
Entwicklung Rechnung getragen, dass speziell im ARM-Bereich die beiden Aufgaben
von unterschiedlichen Geräten wahrgenommen werden. Somit kann künftig ein Device
Controller auch mit mehreren Grafikprozessoren zusammenarbeiten.

<div class="p"><!----></div>

<h3>Speicherverwaltung und Scheduling</h3>


Tickless Multitasking wurde
weiterentwickelt. Seit Linux 3.10 können dadurch alle Prozessoren eines Systems
ohne die Timeticks, zeitgesteuerte Interrupts, arbeiten bis auf einen. Dieser
stellt quasi den Zeitgeber für die anderen Prozessoren dar und sendet mindestens
einmal pro Sekunde ein Signal. Mit dem aktuellen Linux-Kernel ist die Aufgabe
nun überflüssig und auch die letzte CPU kann in Zeiten, in denen das System nicht zu
tun hat, schlafen gehen, ohne ständig auf die Uhr schauen zu müssen.

<div class="p"><!----></div>
Locking ist ein Schlagwort, mit dem das Sperren von Ressourcen zum Schutz vor
konkurrierenden Zugriffen beschrieben wird. Im Zusammenhang mit virtualisierten
Systemen und ihren Host-Systemen mutiert Locking bisweilen zum 
Performance-Alptraum, da sowohl Gastgeber als auch die Gast-Systeme Locks – also
Sperren – einsetzen. Zumindest paravirtualisierte
Systeme&nbsp;<a href="https://de.wikipedia.org/wiki/Paravirtualisierung">[4]</a> wie KVM oder Xen
können nun eine angepasste Locking-Methode nutzen, die in diesem Umfeld bessere
Leistungen erzielt und weniger Prozessorzeit der Host-CPU vergeudet.

<div class="p"><!----></div>
Wenn der Speicher knapp wird, also Arbeitsspeicher und Auslagerungsspeicher voll
sind, zieht Linux die Notbremse und beendet einen Prozess, um wieder Speicher
frei zu bekommen. Wartet ein aktiver Prozess darauf, neuen Speicher zugewiesen
zu bekommen, kann er Sperren auf Ressourcen gelegt haben, die der zum Abschuss
ausgewählte Prozess benötigen würde, um sich sauber zu beenden und wieder
Speicher frei zu machen. Verbesserungen am „Out-of-Memory-Killer“ sollen solchen
Situationen vorbeugen. Systemaufrufe, denen nicht genug Speicher zur Verfügung
gestellt werden kann, erhalten künftig einen Fehler zurück, statt ins Wartezimmer
geschickt zu werden – ein Verhalten, das Entwickler berücksichtigen müssen, da
der Systemaufruf ebenfalls einen Fehler an die auslösende Anwendung zurückgibt.
Zum zweiten hebt der Kernel nun alle Sperren auf, wenn der OOM-Killer aktiv wird,
um die oben beschriebenen „Deadlocks“ zu vermeiden.

<div class="p"><!----></div>

<h3>Dateisysteme</h3>


Im Bereich der Dateisysteme hat man Btrfs die Unterstützung
für Deduplizierung spendiert. Das bedeutet, dass doppelt oder mehrfach
vorkommende Daten innerhalb des Dateisystems entfernt werden und somit der
tatsächlich benötigte Speicherplatz reduziert wird. Insbesondere im Zusammenhang
mit Virtualisierung lässt sich hier Platz einsparen, da Teile virtueller
Maschinen auf den Datenträgern des Host-Systems gleich sind. Hier handelt es
sich um die „Offline“-Deduplizierung, die nicht automatisch, sondern nur auf
Anforderung durchgeführt wird.

<div class="p"><!----></div>
Die Fähigkeit, die Arbeit auf mehrere Prozessoren zu verteilen, soll einen
Leistungszuwachs für RAID-5, 
einer Methode
zur Zusammenfassung mehrerer physikalischer Datenträger, bringen. Hierbei können
mehr Ein-/Ausgabe-Operationen pro Sekunde erfolgen, wovon insbesondere 
SSD-Laufwerke profitieren können.

<div class="p"><!----></div>
Diese Liste ist bei weitem nicht komplett,
eine ausführliche Aufzählung der Änderungen liefert die
englischsprachige Seite Kernelnewbies.org&nbsp;<a href="http://kernelnewbies.org/Linux_3.12">[5]</a>.

<div class="p"><!----></div>

<h2>Linux 3.13</h2>


Fast drei Wochen hatten die Linux-Entwickler Zeit, um ihre Zweige
für den Entwicklungszyklus des kommenden Kernels einzureichen, bevor Torvalds
das Merge-Window schloss und die erste Entwicklerversion
veröffentlichte&nbsp;<a href="https://lkml.org/lkml/2013/11/22/439">[6]</a>. Der vollständig
überarbeitete Paketfilter nftables (siehe „Der Oktober im Kernelrückblick“,
<b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> 10/2013&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2013-11">[7]</a>) ist
mit dabei. Eine weitere Neuerung betrifft die blockorientierten Geräte. Hier
wird den Treibern für Massenspeicher künftig ein Modus bereitgestellt, der
mehrere Warteschlangen zur Behandlung von Abfragen ermöglicht. Jedem Prozessor
des Systems wird eine eigene Warteschlange zugewiesen, sodass sich deren
Zugriffe auf den Datenträger nicht überschneiden.

<div class="p"><!----></div>

<h2>Linux 4</h2>


In der Freigabe-Mail zu Linux 3.12 dachte Torvalds wieder über die
Versionsnummern des Kernels nach. Mittlerweile müsse er die Socken ausziehen,
um bis zur aktuellen Version zu zählen, was Linux 4 als Nachfolger für zum
Beispiel Linux 3.19 ins Spiel bringt. Zudem regte der Entwickler Dirk Hohndel
während des Kernel Summit an, bei Gelegenheit mal eine Bugfix-Version
einzuschieben, die keine Neuerungen sondern ausschließlich Fehlerkorrekturen
und Verbesserungen in der Stabilität ausweisen solle. Diesem Vorschlag stand
Torvalds zuerst ablehnend gegenüber, kann sich zwischenzeitlich mit dem Gedanken
anfreunden. Eine Version 4 könnte dann eine Gelegenheit für einen solche 
Bugfix-Version darstellen.

Doch bis dem Linux-Hauptentwickler die Finger und Zehen
ausgehen und Linux 4 in greifbare Nähe rückt, dürfte es noch bis mindestens
Anfang 2015 dauern. Zeit genug für weitere Überlegungen …

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="https://lkml.org/lkml/2013/11/3/160"><tt class="big">https://lkml.org/lkml/2013/11/3/160</tt></a><br />
[2] <a href="http://events.linuxfoundation.org/events/linux-kernel-summit"><tt class="big">http://events.linuxfoundation.org/events/linux-kernel-summit</tt></a><br />
[3] <a href="http://www.phoronix.com/scan.php?page=article&amp;item=amd_linux312_preview"><tt class="big">http://www.phoronix.com/scan.php?page=article&amp;item=amd_linux312_preview</tt></a><br />
[4] <a href="https://de.wikipedia.org/wiki/Paravirtualisierung"><tt class="big">https://de.wikipedia.org/wiki/Paravirtualisierung</tt></a><br />
[5] <a href="http://kernelnewbies.org/Linux_3.12"><tt class="big">http://kernelnewbies.org/Linux_3.12</tt></a><br />
[6] <a href="https://lkml.org/lkml/2013/11/22/439"><tt class="big">https://lkml.org/lkml/2013/11/22/439</tt></a><br />
[7] <a href="http://www.freiesmagazin.de/freiesMagazin-2013-11"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2013-11</tt></a><br />
    

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="1" align="center"><b>Autoreninformation</b></td></tr>
<tr><td align="left"><b>Mathias Menzer</b>&nbsp;(<a href="http://www.menzer.net/">Webseite</a>)
behält die Entwicklung des Linux-Kernels im Blick, um über kommende Funktionen
von Linux auf dem laufenden zu bleiben und immer mit interessanten Abkürzungen
und komplizierten Begriffen dienen zu können.
    </td></tr></table>
<br />

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=Der November im Kernelr%C3%BCckblick#comment-form"><i>Diesen Artikel kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
    


<h1><font color="#595959"><a id="fm_13_12_gpu_computing" name="fm_13_12_gpu_computing">GPU-Computing mit R</a></font></h1>von Markus Lilienthal und Markus Herrmann

<div class="p"><!----></div>
    <b>D</b><b>ieser Artikel bietet eine Einführung in GPU-Computing mit dem 
Statistikprogramm R. Besitzer von Grafikkarten mit NVIDIA-Chipsatz haben 
unter Nutzung des „NVIDIA CUDA-Toolkits“ und des R-Pakets „gputools“ die 
Möglichkeit, parallelisierbare Rechenaufgaben auf ihrer GPU auszuführen. 
Entsprechende Installationsanleitungen versetzen den Leser in die Lage, eine 
R-CUDA-Schnittstelle zu implementieren und für einfache 
mathematisch-statistische Rechenoperationen zu nutzen.</b>

<div class="p"><!----></div>

<h2>GPUs – ungenutzte Rechenkraft!</h2>


General Purpose Computing On Graphics Processing Units (GPGPU) – die 
Verwendung von GPUs zur Erledigung allgemeiner (Rechen-)Aufgaben – war lange 
Zeit eine Domäne von Profi-Anwendern in Grafik-, Video- und 
wissenschaftlichen Bereichen. Mittlerweile bietet sie auch in abgespeckter Form auf 
herkömmlichen Arbeitsplatzrechnern bei parallelisierbaren Anwendungen 
oft erstaunliche Geschwindigkeitsvorteile im Vergleich zu einer CPU. 

<div class="p"><!----></div>
Die Gründe hierfür liegen in der unterschiedlichen Architektur und 
Funktionsweise der beiden Recheneinheiten. GPUs sind generell für einen 
schnellen Datenfluss und auf die vielfach parallele Berechnung von 
Gleitkommazahlen konzipiert, während die maximale Leistung einer CPU nur auf 
eine begrenzte Anzahl gleichzeitiger Threads verteilt werden kann. 
GPU-Rechenkapazität für mathematisch/statistische Aufgabenstellungen zu 
nutzen, bietet sich also immer dann an, wenn eine Vielzahl an Berechnungen 
gleichzeitig ausgeführt werden kann, wobei die jeweiligen Rechenoperationen 
voneinander unabhängig sind (z.&nbsp;B. bei Matrixmultiplikationen oder 
Distanzmessungen zwischen Vektoren). Derartige Problemstellungen werden auch 
als „embarrassingly parallel“ bezeichnet.

<div class="p"><!----></div>
Insbesondere Besitzer von Grafikkarten mit einem geeigneten „CUDA-fähigen“  
NVIDIA-Chipsatz&nbsp;<a href="https://developer.nvidia.com/cuda-gpus">[1]</a> können so mit 
Hilfe von NVIDIAs CUDA-Toolkit&nbsp;<a href="https://developer.nvidia.com/">[2]</a> und der 
Statistik-Software R&nbsp;<a href="http://www.r-project.org/">[3]</a> einfache statistische 
Methoden effizient umsetzen, insofern die Datenmengen ein bestimmtes Maß 
nicht überschreiten. Einer der limitierenden Faktoren ist hierbei der 
Arbeitsspeicher der Grafikeinheit. Werden Objekte geladen, die die Größe des 
Arbeitsspeichers überschreiten, entstehen massive Kosten durch den ständigen 
Datenfluss von und zu den beteiligten Speicherbausteinen. Insbesondere 
einfachere Grafikkarten mit weniger als 512 MB RAM kommen dabei, trotz zum 
Teil über hundert nutzbaren CUDA-Kernen, schnell an die Grenzen ihrer 
Leistungsfähigkeit und bieten sich deshalb besser für Entwicklungsaufgaben an. 

<div class="p"><!----></div>
Der Kauf hochperformanter Grafikkarten, wie zum Beispiel der NVIDIA 
„Tesla“-Reihe, ist aber für den Gelegenheitsanwender meist wenig rentabel, 
da selbst bei kleineren GPU-Clustern durchaus der Gegenwert eines 
Kleinwagens aufkommen kann. Bei umfangreichen Rechenoperationen mit 
erhöhtem Datenfluss besteht allerdings auch die Möglichkeit, auf 
Internetdienste wie z.&nbsp;B. Amazon Web Services (AWS) 
auszuweichen&nbsp;<a href="https://aws.amazon.com/de/ec2/instance-types/">[4]</a>. Dort können 
beispielsweise GPU-Cluster-Instanzen mit zwei NVIDIA „Tesla“ M2050 
GPU-Recheneinheiten angemietet werden („cg1.4xlarge“ GPU-Instanz). Die 
Abrechnung erfolgt dort auf Stundenbasis, der Satz beträgt momentan 2,10 
US-Dollar. Dies mag im ersten Augenblick zwar nicht gerade günstig 
erscheinen, allerdings erhält man dafür auch die Leistung von zwei 
Grafikkarten mit jeweils drei GB GDDR5-Arbeitsspeicher und 448 CUDA-Kernen 
sowie ein weitgehend vorkonfiguriertes Systemabbild. Amazon hat über 
das AWS-Blog bereits angekündigt, das Angebot an GPU-Instanzen weiter 
ausbauen zu wollen und stellt zukünftig auch eine „g2.2xlarge instance“ mit einer 
NVIDIA „Kepler“ GK104 GPU (1536 CUDA-Kerne und vier GB Arbeitsspeicher) zur 
Anmietung bereit.

<div class="p"><!----></div>
Die Installation des CUDA-Toolkits obliegt allerdings weiterhin dem Nutzer. 
Um unnötige Kosten bei der Anmietung von GPU-Instanzen zu vermeiden, wird 
daher empfohlen, innerhalb der Webdienste möglichst nur produktiv tätig zu 
werden und den Code vorab lokal zu entwickeln. Die Kosten der Anmietung 
sollte man auf diese Weise so gering wie möglich halten können. 

<div class="p"><!----></div>
Diese Vorgehensweise soll auch im praktischen Teil des vorliegenden Artikels 
verfolgt werden: Es wird gezeigt, wie im Anschluss an die lokale und 
kostengünstige Entwicklung eines einfachen, GPU-gestützten statistischen 
Programmcodes eine effiziente Produktionsphase mit Hilfe von zeitweilig 
angemieteten GPU-Instanzen erfolgen kann. 

<div class="p"><!----></div>
Zum besseren Verständnis für R-Einsteiger erfolgt zunächst eine kurze 
Einführung zum GPU-Computing mit R und zur Funktionalität des R-Pakets 
„gputools“&nbsp;<a href="http://cran.r-project.org/web/packages/gputools/">[5]</a>, welches 
eine einfache  Schnittstelle zum CUDA-Toolkit zur Verfügung stellt. Diese 
Installationsanweisung erfolgt beispielhaft für Ubuntu Server 12.04 LTS in 
Verbindung mit dem CUDA-Toolkit 5.0.35. Als geeignete Compiler erwiesen sich 
GCC 4.4 und 4.6. Anschließend wird chronologisch 
durch die relevanten Installationsvorgänge zum Aufbau einer 
CUDA-R-Schnittstelle geführt und eine Beispielsimulation mit 
Geschwindigkeitsvergleich vorgestellt. 

<div class="p"><!----></div>
Der Vollständigkeit halber sei erwähnt, dass mit 
OpenCL&nbsp;<a href="http://www.khronos.org/opencl/">[6]</a> eine weitere Schnittstelle für 
GPU-gestützte Parallelisierungsaufgaben erhältlich ist. Diese ist im 
Gegensatz zu CUDA plattformunabhängig und Open Source.

<div class="p"><!----></div>

<h2>GPU Computing mit R</h2>


R&nbsp;<a href="http://www.r-project.org/">[3]</a> ist eine der bekanntesten 
Entwicklungssysteme für statistisches Rechnen. Im Gegensatz zu vielen 
kommerziellen Statistikprogrammen ist R durchgehend als Programmiersprache 
angelegt. Dadurch ist R zwar für Einsteiger schwieriger zu erlernen, bietet 
aber die volle Flexibilität einer Programmiersprache bei komplexen 
Anwendungen. Nicht zuletzt ist R ein GNU-Projekt und steht unter der GNU 
General Public License&nbsp;<a href="https://de.wikipedia.org/wiki/GPL">[7]</a>. R wird sehr 
intensiv in der Wissenschaft eingesetzt, ist aber auch in der Wirtschaft 
wegen seiner geringen Kosten geschätzt. R läuft prinzipiell auf allen 
gängigen Betriebssystemen. Mit der 2013 veröffentlichten Version 3 wird nun 
auch 64-Bit unterstützt, d.&nbsp;h. Vektoren und Matrizen können bis zu 2<sup>52</sup> 
(2 hoch 52) Einträge besitzen.

<div class="p"><!----></div>


R als Programmiersprache ist speziell ausgelegt auf Datenanalyse und 
Statistik. R unterstützt beispielsweise ohne Zusatzpakete Matrixalgebra und 
viele statistische Funktionen sowie zahlreiche Funktionen zur Erzeugung von 
Diagrammen und Grafiken. Man kann als Nutzer in der Regel davon ausgehen, 
dass viele der existierenden statistischen Analyseverfahren entweder im 
Kernsystem oder als Zusatzpaket (unter R „library“ genannt) frei verfügbar 
sind. Bei Schleifenberechnungen ist R selbst jedoch langsam. Deshalb sind 
viele verfügbare Funktionen in der Programmiersprache C implementiert und 
als Bibliothek eingebunden. Matrixoperationen werden z.&nbsp;B. standardmäßig mit 
der alleinstehenden Matrixbibliothek 
LAPACK&nbsp;<a href="http://www.netlib.org/lapack/">[8]</a> ausgeführt. 

<div class="p"><!----></div>
Wenn man mit großen Daten und/oder vielen Schleifen arbeitet, reicht oft die 
Leistungsfähigkeit der Programmiersprache R für den Kern der gewünschten 
Berechnung nicht aus. Daher bietet R die Möglichkeit, auch selbst 
geschriebene Bibliotheken in C, C++ oder FORTRAN zu verlinken. Viele 
installierbare Pakete arbeiten nach diesem Prinzip. Die Methode ist 
effektiv, hat aber auch zwei Nachteile bei der Entwicklung. Zum einen muss 
man eine dieser Programmiersprachen zusätzlich beherrschen. Viele R-Nutzer 
sind aber keine Programmierer, sondern kommen aus angewandten Fachgebieten 
mit empirischen Aufgabenstellungen (Sozialwissenschaften, 
Wirtschaftswissenschaften, Naturwissenschaften). Das Erlernen einer weiteren 
Sprache bedeutet eine große Hürde. Zweitens ist die Umsetzung bspw. in C in 
der Praxis oft aufwendiger als in R gewohnt, weil viele höhere Datentypen 
und Funktionen dort nicht existieren. Selbst wenn man diese Mühe auf sich 
nimmt, haben viele statistische Berechnungen auch als solche Bibliothek eine 
beträchtliche Laufzeit. Typische Beispiele sind iterative, 
simulationsbasierte 
Bayes-Verfahren&nbsp;<a href="https://de.wikipedia.org/wiki/Satz_von_Bayes">[9]</a>. Aber auch 
Anwendungsfälle, bei denen die Datenmenge sehr groß ist, können merkliche 
Rechenzeit beanspruchen. Schon eine simple Multiplikation von Matrizen der 
Dimension n&times;n wird bei großen n zum Geduldsspiel. An dieser Stelle wäre der 
Einsatz der GPU eine vielversprechende zusätzliche Verbesserung, zumal in 
vielen Desktop-Rechnern ohnehin bereits Grafikkarten verbaut sind.

<div class="p"><!----></div>


Es existieren derzeit etwa ein halbes Dutzend R-Pakete, die sich 
GPU-Leistung zunutze machen. Drei Pakete haben ganz spezielle 
Analysefunktionen für die GPU implementiert (permGPU, cudaBayesreg, WideLM). 
Zwei weitere Pakete (magma, HiPLARM) setzen auf den Ersatz des 
Standard-Algebra-Pakets LAPACK durch GPU-fähige Bibliotheken. Alle genannten 
Pakete basieren auf der CUDA-Plattform von NVIDIA, funktionieren also auch 
nur mit einer GPU dieses Herstellers. Das OpenCL-Paket nutzt die 
plattformunabhängige Schnittstelle OpenCL, allerdings ist der 
Funktionsumfang recht begrenzt und nicht selbsterklärend. Das Paket 
gputools, das der Artikel genauer vorstellen will, hat sich als das momentan 
am einfachsten zu installierende und in der Praxis nützlichste und 
vielseitigste erwiesen. Allerdings basiert auch dieses Paket auf der 
proprietären, wenngleich kostenlosen CUDA-Plattform.

<div class="p"><!----></div>

<h2>Das Paket gputools und Anwendungsszenarien</h2>


Das Paket gputools bietet Altenativimplementierungen für einige grundlegende 
Matrixoperationen und rechenintensive statistische Verfahren. Die 
Prozedurbezeichnungen halten sich syntaktisch an die bekannten (CPU-) 
Funktionen in R; es ist lediglich jeweils das Präfix <b><tt class="big">gpu</tt></b> dem Namen der 
Funktion vorangestellt.

<div class="p"><!----></div>
Das Paket bietet Funktionen aus den folgenden Bereichen:

<div class="p"><!----></div>


    
<dl>
 <dt><b><b>Matrixoperationen:</b></b></dt>
	<dd> Als GPU-Matrixmultiplikationen stehen Multiplikation 
(<b><tt class="big">gpuMatMult</tt></b>) und Inverse (<b><tt class="big">gpuSolve</tt></b>) zur Verfügung, sowie die der 
Inversion nahe stehende QR-Zerlegung und das der Multiplikation nahestehende 
Kreuzprodukt. Einfache lineare Operationen wie Spaltensummen oder 
Multiplikation mit einem Skalar sind leider nicht implementiert. Versuche und 
Beispielsimulationen haben gezeigt, dass hierbei die GPU keinen 
Geschwindigkeitsvorteil erzielen kann: Die GPU kann ihren 
Geschwindigkeitsvorteil immer nur dann zum Tragen bringen, wenn der 
Zeitaufwand für das Kopieren der Daten vom Arbeitsspeicher in den 
Arbeitsspeicher der GPU und umgekehrt im Vergleich zur eigentlichen 
Berechnung lediglich einen kleinen Teil einnimmt. Das ist bei solchen einfachen 
Befehlen offensichtlich noch nicht der Fall. Erfahrungswerte haben aber 
gezeigt, dass allein diese beiden Matrixfunktionen in Prozeduren mit vielen 
Operationen großer Matrizen zweistellige Beschleunigungsfaktoren erzielen 
können, obwohl ein Großteil des Codes immer noch ganz normal auf der CPU verarbeitet wird.
</dd>
 <dt><b><b>Lineare Regression und kleinste Quadrate:</b></b></dt>
	<dd> gputools bietet mit den Befehlen 
<b><tt class="big">gpuLm</tt></b> und <b><tt class="big">gpuGlm</tt></b> lineare und generalisierte lineare Modelle an, also 
zum Beispiel lineare Regression und multinomiale Regressionsmodelle. Diese Funktionen 
berechnen das gesamte Modell auf der GPU und nicht nur einzelne, isolierte
Matrixoperationen. Daher sind die Funktionen effizienter und schneller, als wenn man sie 
mit den Matrixoperationen nachbaut.
</dd>
 <dt><b><b>Distanzen und Clustering:</b></b></dt>
	<dd> Clustering ist ein Verfahren, bei dem eine 
Anzahl von Objekten (Beobachtungen, Befragte) in Klassen mit ähnlichen 
Eigenschaften zerlegt wird. Grundlage der Berechnung ist ein Distanzmaß, das 
die Unähnlichkeit zweier Objekte als eine Zahl beschreibt. Mit der Funktion 
<b><tt class="big">gpuDist</tt></b> kann man solche Distanzen berechnen. Es stehen dabei verschiedene 
Metriken zur Auswahl. Anschließend kann mit <b><tt class="big">gpuHclust</tt></b> ein hierarchisches 
Clustering auf Basis der Distanzen ausgeführt werden. Der Befehl 
<b><tt class="big">gpuDistClust</tt></b> vereinigt beide Funktionalitäten in einer Prozedur.
</dd>
</dl>


<div class="p"><!----></div>
Bevor in der Beispielanwendung näher auf das Paket gputools eingegangen 
wird, folgt zunächst eine exemplarische Installationsanleitung für das 
CUDA-Toolkit und die entsprechenden R-Komponenten.

<div class="p"><!----></div>

<h2>Installation NVIDIA CUDA-Toolkit</h2>


Bei der Installation des CUDA-Toolkits gilt es zu beachten, dass diese 
ausschließlich auf Kommandozeilenebene, d.&nbsp;h. nur mit deaktiviertem 
Displaymanager, möglich ist. Hierzu muss man den jeweils laufenden 
Displaymanager stoppen. Beispielsweise lässt sich der GNOME Displaymanager 
„gdm“ nach einem Wechsel nach tty1 (<i>„Strg“</i>&nbsp;+&nbsp;<i>„Alt“</i>&nbsp;+&nbsp;<i>„F1“</i>) mit dem Befehl

<div class="p"><!----></div>

<div class="command"># gdm stop</div>

<div class="p"><!----></div>


anhalten.

<div class="p"><!----></div>
Zu Beginn geht es an die Installation notwendiger Abhängigkeiten. Die 
folgenden Compiler und Bibliotheken sind vorab zu installieren (die Namen 
entstammen einer Ubuntu-Distribution): <b>gcc</b>, <b>g++</b>, <b>build-essential</b>, 
<b>linux-headers-`uname -r`</b>, <b>freeglut3-dev</b>,
<b>libx11-dev</b>, <b>libxmu-dev</b>, 
<b>libxi-dev</b>, <b>libgl1-mesa-glx</b>, <b>libglu1-mesa</b>, <b>libglu1-mesa-dev</b> und 
<b>mpi-default-dev</b>.

<div class="p"><!----></div>
Dann muss noch ein Softlink zur Bibliothek <b><tt class="big">libglut.so.3.9.0</tt></b> erstellt 
werden, da CUDA sie als <b><tt class="big">/usr/lib/libglut.so</tt></b> erwartet:

<div class="p"><!----></div>

<div class="command"># ln -s /usr/lib/x86_64-linux-gnu/libglut.so.3.9.0 /usr/lib/libglut.so</div>

<div class="p"><!----></div>


Im Anschluss wird das automatische Laden ausgewählter Treiber bzw. 
Kernelmodule 
verhindert&nbsp;<a href="http://www.tldp.org/HOWTO/Module-HOWTO/x73.html">[10]</a>. Hierzu muss man
die folgenden grafikspezifischen Module in die „Blacklist“ unter 
<b><tt class="big">/etc/modprobe.d/blacklist.conf</tt></b> aufnehmen:

<div class="p"><!----></div>

<div class="listing">blacklist amd76x_edac<br />
blacklist vga16fb<br />
blacklist nouveau<br />
blacklist rivafb<br />
blacklist nvidiafb<br />
blacklist rivatv</div>

<div class="p"><!----></div>


Die bestehenden NVIDIA-Treiber müssen nun vollständig deinstalliert werden. 
Hierzu alle Pakete mit dem Präfix „nvidia“ vom System entfernen und im 
Anschluss

<div class="p"><!----></div>

<div class="command"># update-initramfs -u </div>

<div class="p"><!----></div>


ausführen, um das „initial ram filesystem“ auf den neuesten Stand zu 
bringen. Initramfs wird beim Systemstart ausgeführt und ist unter anderem 
zum Initialisieren von Hardware und Modulen 
zuständig&nbsp;<a href="https://www.kernel.org/doc/Documentation/filesystems/ramfs-rootfs-initramfs.txt">[11]</a>.

<div class="p"><!----></div>
Danach wird ein Neustart empfohlen:

<div class="p"><!----></div>

<div class="command"># reboot</div>

<div class="p"><!----></div>


Nach dem Neustart kann jetzt mit der eigentlichen Installation des 
CUDA-Toolkits begonnen werden. Dazu muss dieses von der NVIDIA 
Developer Zone&nbsp;<a href="https://developer.nvidia.com/cuda-downloads">[12]</a> 
heruntergeladen und die Installationsdatei als ausführbar gekennzeichnet 
werden. Für den Artikel wird die etwas ältere Version 5.0.35 
verwendet&nbsp;<a href="http://developer.download.nvidia.com/compute/cuda/5_0/rel-update-1/installers/cuda_5.0.35_linux_64_ubuntu11.10-1.run">[13]</a>).

<div class="p"><!----></div>

<div class="command"># chmod a+x cuda_5.0.35_linux_64_ubuntu11.10-1.run</div>

<div class="p"><!----></div>


Dann kann man die eigentliche Setup-Datei ausführen und muss nur den 
Installationsanweisungen folgen:

<div class="p"><!----></div>

<div class="command"># sh ./cuda_5.0.35_linux_64_ubuntu11.10-1.run</div>

<div class="p"><!----></div>


Jetzt muss sichergestellt werden, dass die Datei <b><tt class="big">/etc/environment</tt></b> den 
Pfad zum CUDA-Verzeichnis enthält. Dafür ergänzt man in der eben genannten Datei mit Root-Rechten die
Variable <b><tt class="big">PATH</tt></b> um den Eintrag <b><tt class="big">/usr/local/cuda-5.0/bin</tt></b>.

<div class="p"><!----></div>
Zuletzt müssen noch die neuen Bibliotheken referenziert werden. Hierzu ist 
die Datei <b><tt class="big">/etc/ld.so.conf.d/cuda.conf</tt></b> mit den folgenden Einträgen 
zu erstellen:

<div class="p"><!----></div>

<div class="listing">/usr/local/cuda/lib64<br />
/usr/local/cuda/lib</div>

<div class="p"><!----></div>


Zum Abschluss muss noch ein 

<div class="p"><!----></div>

<div class="command"># ldconfig</div>

<div class="p"><!----></div>


ausgeführt werden, um die Benutzer- und Systembibliotheken gegenseitig zu 
referenzieren.

<div class="p"><!----></div>
Nach einer erfolgreichen Installation kann wieder zurück in den grafischen Modus 
gewechselt werden. Hierzu muss man einfach den entsprechenden Startbefehl des verwendeten 
Displaymanagers aufrufen, zum Beispiel beim GNOME Displaymanager:

<div class="p"><!----></div>

<div class="command"># gdm start</div>

<div class="p"><!----></div>


Ein erster Test, mit dem gleichzeitig auch die CUDA-Grafikkartenverbindung
durch das Einhängen von <b><tt class="big">/dev/nvidia</tt></b>
initialisiert wird, kann mit den mitgelieferten, jedoch noch nicht 
kompilierten, CUDA-Samples durchgeführt werden. Um die Beispielanwendungen 
zu kompilieren, muss zunächst in das entsprechende Verzeichnis gewechselt 
und der „make“-Befehl ausgeführt werden. Mit der nachfolgenden Befehlsfolge 
wird die Beispielanwendung kompiliert und gestartet:

<div class="p"><!----></div>

<div class="command">$ cd CUDA-Samples/0_Simple/matrixMul <br />
$ make <br />
# ./matrixMul</div>

<div class="p"><!----></div>


Die obige Installationsanweisung funktioniert, mit versionsbedingten 
Anpassungen, auch für die aktuelle Version CUDA 5.5.

<div class="p"><!----></div>

<h2>Installation R und RStudio (Desktop/Server)</h2>


R, inklusive einiger Basispakete, kann unter den meisten 
Linux-Distributionen mit dem systemeigenen Paketmanager installiert 
werden&nbsp;<a href="http://cran.r-mirror.de/bin/">[14]</a>. Um aber die jeweils neuesten 
R-Versionen und Pakete zu erhalten, kann R natürlich auch selbst kompiliert 
werden&nbsp;<a href="http://cran.r-mirror.de/sources.html">[15]</a>. Die Installation ist im 
Allgemeinen recht unkompliziert. Es wird empfohlen, den mitgelieferten 
Installationsanweisungen zu folgen.

<div class="p"><!----></div>
Nach erfolgreicher Installation kann man R mit folgendem Kommandozeilenaufruf starten.

<div class="p"><!----></div>

<div class="command">$ R</div>

<div class="p"><!----></div>


Da eine R-Code-Entwicklung auf Konsolenebene allerdings nur 
äußerst mühsam zu handhaben ist, empfiehlt sich die Nutzung einer grafischen 
Schnittstelle, wie der von RStudio Desktop&nbsp;<a href="http://www.rstudio.com/">[16]</a>.  

<div class="p"><!----></div>
Auf Systemen ohne graphische Benutzeroberfläche, wie bei virtuellen Servern 
durchaus üblich, kann auf die Serverversion von RStudio ausgewichen werden. 
Bei Benutzung der Serverversion ist es möglich, mit der von der 
Desktopversion bekannten Oberfläche innerhalb eines Webbrowsers zu arbeiten. 

<div class="p"><!----></div>
Sowohl die Desktop-, als auch die Serverversion kann auf gängigen 
Linux-Distributionen ebenfalls komfortabel mit bereitgestellten Paketen von 
der offiziellen RStudio-Internetseite installiert werden. Die 
Quellcodedateien stehen dort ebenfalls zum Download bereit. Es wird auch 
hier empfohlen, den Installationsanweisungen zu 
folgen&nbsp;<a href="http://www.rstudio.com/ide/docs/">[17]</a>.

<div class="p"><!----></div>
Standardmäßig ist RStudio per HTTP über Port 8787 erreichbar. Sollte der 
entfernte Server allerdings nur über SSH erreichbar sein, empfiehlt sich der 
ssh-Aufruf in Verbindung mit der Portforwarding-Option:

<div class="p"><!----></div>

<div class="command">$ ssh -L8787:localhost:8787 user@host</div>

<div class="p"><!----></div>


Über den Browseraufruf <a href="http://localhost:8787"><tt class="big">http://localhost:8787</tt></a> steht nach der Eingabe des 
System-Benutzernamens und System-Passworts die RStudio-Oberfläche im Browser 
zur Verfügung.

<div class="p"><!----></div>

<h2>Installation des R-Pakets gputools</h2>


Zum Abschluss erfolgt die Installation von gputools. Hiermit wird die 
Schnittstelle zwischen R und dem CUDA-Toolkit geschaffen. Das Paket kann über 
„The Comprehensive R Archive Network“&nbsp;<a href="http://cran.r-project.org">[18]</a> 
heruntergeladen werden. Für die Installation soll die Version 0.28 als 
Beispiel dienen&nbsp;<a href="http://cran.r-project.org/src/contrib/gputools_0.28.tar.gz">[19]</a>. 
Für eine Verwendung von R auf Kommandozeilenebene genügt ein:

<div class="p"><!----></div>

<div class="command"># R CMD INSTALL gputools_0.28.tar.gz</div>

<div class="p"><!----></div>


Wird RStudio/RStudio Server verwendet, empfiehlt sich die Installation über 
„<em>Tools&nbsp;-&#62;&nbsp;Install Packages ...</em>“. Hintergrund hierfür sind unterschiedliche 
Library-Zielverzeichnisse in den Standardeinstellungen von R und RStudio. 
Während R zusätzliche Pakete unter <b><tt class="big">/usr/lib/R/site-library</tt></b> installiert, 
legt RStudio die Dateien im Homeverzeichnis ab. Dies ist von der 
Installationsart (Benutzer/Administrator) abhängig und kann individuell 
angepasst werden.

<div class="p"><!----></div>
Bei der Installation sind zwingend die Ausgaben im Konsolenfenster zu 
beachten. Hier erfolgt die Fehlerausgabe, wenn beispielsweise Abhängigkeiten 
wie andere R-Pakete oder Compiler nicht vorhanden sind. Die fehlenden Pakete 
müssen dann zunächst installiert werden, bevor der Vorgang wiederholt wird.

<div class="p"><!----></div>
Nach erfolgreicher Installation muss noch ein symbolischer Link erstellt werden, 
damit R die shared library <b><tt class="big">include</tt></b> finden kann:

<div class="p"><!----></div>

<div class="command"># ln -s /usr/share/R/include /usr/lib/R</div>

<div class="p"><!----></div>


Außerdem muss noch der folgende Code im Home-Verzeichnis in die versteckte 
Datei <b><tt class="big">.Rprofile</tt></b> einfügt werden, um die CUDA-Pfade und -Bibliotheken bei 
Ausführung von R als Umgebungsvariablen zu referenzieren:

<div class="p"><!----></div>

<div class="listing">.First&lt;-function() <br />
{ <br />
Sys.setenv(PATH="/usr/local/sbin:/usr/local/bin:/usr/bin:/usr/sbin:/sbin:/bin:/usr/local/cuda-5.0/bin")        <br />
Sys.setenv(LD_LIBRARY_PATH="/usr/lib/R/lib:/lib:/usr/local/cuda-5.0/lib64:/usr/local/cuda-5.0/lib") <br />
Sys.setenv(CUDA_HOME="/usr/local/cuda-5.0") <br />
} </div>

<div class="p"><!----></div>


Sobald R bzw. RStudio gestartet ist, wird das Paket gputools mit dem 
folgenden Code aufgerufen:

<div class="p"><!----></div>

<div class="command">&#62; library(gputools)</div>

<div class="p"><!----></div>


Ab jetzt kann gputools genutzt werden. In RStudio können Pakete zusätzlich 
auch innerhalb der grafischen Paketübersicht bequem ge- und entladen werden.

<div class="p"><!----></div>

<h2>Eigenen C-Code einsetzen</h2>


Genügen die vorgefertigten R-Pakete nicht, kann man eigene C-Bibliotheken 
einbinden. Der Königsweg ist dabei die Zusammenstellung eines eigenen 
R-Pakets. Man kann aber auch zur Laufzeit einzelne, in C geschriebene 
Funktionen einbinden. Das prinzipielle Vorgehen unterscheidet sich nämlich von 
normalen R-Paketen, da zur Kompilierung der CUDA-basierten C-Codes ein 
spezieller Compiler benötigt wird. Der Hersteller NVIDIA stellt hierfür den 
Compiler <b><tt class="big">nvcc</tt></b> zur Verfügung.

<div class="p"><!----></div>
Nachfolgend wird demonstriert, wie man eine einfache Hallo-Welt-Bibliothek 
in R einbinden kann. Auf die Besonderheiten der CUDA-Programmierung wird an 
dieser Stelle nicht detailliert eingegangen, interessierte Benutzer finden 
aber zahlreiche Anleitungen im Internet. Als Beispiel dient der Quellcode
<a href="http://www.freiesmagazin.de/mobil/2013-12-listings/helloworld.cu"><b><tt class="big">helloworld.cu</tt></b></a>.

<div class="p"><!----></div>



<div class="listing">#include &lt;stdio.h&#62;<br />
#include &lt;cuda.h&#62;<br />
#define N 10<br />
<br />
__global__ <br />
void add( int *a, int *b, int *c ) {<br />
&nbsp;&nbsp;int tid = blockIdx.x; <br />
&nbsp;&nbsp;if (tid &lt; N)<br />
&nbsp;&nbsp;&nbsp;&nbsp;c[tid] = a[tid] + b[tid];<br />
}<br />
<br />
extern "C"<br />
int myadd( int *a, int *b, int *c ) {<br />
&nbsp;&nbsp;int *dev_a, *dev_b, *dev_c;<br />
&nbsp;&nbsp;<br />
&nbsp;&nbsp;// allocate the memory on the GPU<br />
&nbsp;&nbsp;cudaMalloc( (void**)&amp;dev_a, N * sizeof(int) );<br />
&nbsp;&nbsp;cudaMalloc( (void**)&amp;dev_b, N * sizeof(int) );<br />
&nbsp;&nbsp;cudaMalloc( (void**)&amp;dev_c, N * sizeof(int) ); <br />
&nbsp;&nbsp;<br />
&nbsp;&nbsp;// copy the arrays 'a' and 'b' to the GPU<br />
&nbsp;&nbsp;cudaMemcpy( dev_a, a, N * sizeof(int),cudaMemcpyHostToDevice );<br />
&nbsp;&nbsp;cudaMemcpy( dev_b, b, N * sizeof(int),cudaMemcpyHostToDevice );<br />
<br />
&nbsp;&nbsp;//run core procedure on GPU<br />
&nbsp;&nbsp;add&lt;&lt;&lt;N,1&#62;&#62;&#62;( dev_a, dev_b, dev_c );<br />
&nbsp;&nbsp;<br />
&nbsp;&nbsp;// copy the array 'c' back from the GPU to the CPU<br />
&nbsp;&nbsp;cudaMemcpy( c, dev_c, N * sizeof(int),cudaMemcpyDeviceToHost );<br />
&nbsp;&nbsp;<br />
&nbsp;&nbsp;// display the results<br />
&nbsp;&nbsp;for (int i=0; i&lt;N; i++) {<br />
&nbsp;&nbsp;&nbsp;&nbsp;printf( "  }<br />
&nbsp;&nbsp;<br />
&nbsp;&nbsp;// free the memory allocated on the GPU<br />
&nbsp;&nbsp;cudaFree( dev_a );<br />
&nbsp;&nbsp;cudaFree( dev_b );<br />
&nbsp;&nbsp;cudaFree( dev_c );<br />
&nbsp;&nbsp;return 0;<br />
}</div>

<div class="p"><!----></div>
<i>Listing: <a href="http://www.freiesmagazin.de/mobil/2013-12-listings/helloworld.cu">helloworld.cu</a></i>

<div class="p"><!----></div>


Die Funktion <b><tt class="big">__global__</tt></b> wird auf jedem GPU-Kern parallel ausgeführt. Sie 
bestimmt den GPU-Block, gespeichert in <b><tt class="big">tid</tt></b>, in dem sie gerade ausgeführt 
wird, addiert die Elemente der Vektoren <b><tt class="big">a</tt></b> und <b><tt class="big">b</tt></b> mit Index <b><tt class="big">tid</tt></b>, und 
legt das Ergebnis im Vektor <b><tt class="big">c</tt></b> im entsprechenden Indexelement ab. Der 
Einfachheit halber ist die Länge der Vektoren <b><tt class="big">a</tt></b>, <b><tt class="big">b</tt></b> und <b><tt class="big">c</tt></b> mit der 
globalen Konstante <b><tt class="big">N</tt></b> festgelegt.

<div class="p"><!----></div>
Die Funktion <b><tt class="big">myadd</tt></b> wird dann aus R heraus aufgerufen. Damit der 
nvcc-Compiler sie als C-Code erkennt, muss die Zeile <b><tt class="big">extern "C"</tt></b> 
vorangestellt werden. Der <b><tt class="big">printf</tt></b>-Befehl wird seine Ausgabe direkt in die 
R-Konsole schreiben. 

<div class="p"><!----></div>
Die shared library wird mit dem Befehl

<div class="p"><!----></div>

<div class="command">$ nvcc --shared -o helloworld.so helloworld.cu --compiler-options '-fPIC'</div>

<div class="p"><!----></div>


erzeugt. In R kann die Bibliothek nun mit folgendem Beispielcode geladen werden:

<div class="p"><!----></div>

<div class="listing">dyn.load("helloworld.so")<br />
<br />
n=10<br />
a=rep(1,n)<br />
b=seq(from=2,to=20,length.out=n)<br />
c=rep(-1,n)<br />
<br />
.C("myadd",<br />
&nbsp;&nbsp;&nbsp;a=as.integer(a),<br />
&nbsp;&nbsp;&nbsp;b=as.integer(b),<br />
&nbsp;&nbsp;&nbsp;c=as.integer(c))$c</div>

<div class="p"><!----></div>
<i>Listing: <a href="http://www.freiesmagazin.de/mobil/2013-12-listings/helloworld.r">helloworld.r</a></i>

<div class="p"><!----></div>



<h2>Geschwindigkeitsmessungen in R</h2>


Nachfolgend wird eine einfach zu programmierende Geschwindigkeitsmessung mit 
dem R-Paket gputools auf einem lokalen Rechner mit einer NVIDIA Quadro 410 
Grafikkarte und unter Verwendung der in der Einleitung bereits angesprochenen 
Amazon-GPU-Instanz „cg1.4xlarge“ mit dem Ubuntu Server 12.04 LTS Systemabbild 
„ami-c87b6fbc“ gezeigt. Es wurde jeweils zwischen der verwendeten CPU und 
GPU verglichen.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/R_screenshot.png" alt="R_screenshot.png" style="max-width:100%" /><br /><em>Matrixmultiplikation mit CPU und GPU.</em><br />

<div class="p"><!----></div>
Das erste Beispiel zeigt eine Matrixmultiplikation von zwei mit 
normalverteilten Zufallszahlen gefüllten Matrizen der Dimension 3000x3000 
auf einem herkömmlichen Arbeitsplatzrechner mit einer AMD A8-5500 4-Kern CPU 
und einer NVIDIA Quadro 410 mit 192 CUDA-Kernen:

<div class="p"><!----></div>

<div class="command">&#62; n&lt;-3000 <br />
&#62; set.seed(100)<br />
&#62; M1=matrix(rnorm(n^2),ncol=n)<br />
&#62; M2=matrix(rnorm(n^2),ncol=n) <br />
<br />
&#62; system.time(M1%*%M2) <br />
user        system      elapsed<br />
35.642      0.056       35.758<br />
&#62; system.time(gpuMatMult(M1, M2))<br />
user        system      elapsed<br />
5.144       0.032       5.187</div>

<div class="p"><!----></div>


Das folgende Beispiel wurde auf der Amazon-GPU-Instanz mit zwei Intel Xeon 
X5570 CPUs und zwei NVIDIA „Tesla“ M2050 GPUs berechnet. Hier erfolgt eine 
Matrixmultiplikation von zwei mit normalverteilten Zufallszahlen gefüllten 
Matrizen der Dimension 5000x5000:

<div class="p"><!----></div>

<div class="command">&#62; n=5000 <br />
&#62; set.seed(100) <br />
&#62; M1=matrix(rnorm(n^2),ncol=n) <br />
&#62; M2=matrix(rnorm(n^2),ncol=n) <br />
<br />
&#62; system.time(M1%*%M2) <br />
user        system      elapsed <br />
161.930     0.140       162.036 <br />
&#62; system.time(gpuMatMult(M1, M2)) <br />
user        system      elapsed <br />
0.792       0.280       1.073</div>

<div class="p"><!----></div>


Bei beiden Szenarien wurde eine Überlegenheit der GPU-gestützten Berechnung 
beobachtet. Konnten schon beim lokalen Vergleich spürbare 
Geschwindigkeitsvorteile, Faktor 6-8, beobachtet werden, so zeigt die 
Nutzung der Tesla-GPU eine massive Beschleunigung.  Hier dauerte die 
CPU-gestützte Berechnung 161,930 Sekunden,
die GPU-gestützte Berechnung 
jedoch nur 0,792 Sekunden. 

<div class="p"><!----></div>
Diese Ergebnisse sind allerdings auch kritisch zu hinterfragen. So sind 
diese Messungen natürlich von der individuellen Systemkonfiguration und der 
gewählten Aufgabenstellung abhängig. Zudem konnte mit dem vorhandenen 
lokalen Testsystem
(unter Verwendung der NVIDIA Quadro 410) eine 
Matrixmultiplikation mit Matrizen der Dimension 5000x5000 mangels 
Arbeitsspeichers schon nicht mehr durchgeführt werden. Insofern müssen die 
Komplexität beziehungsweise Dimensionen der Tests immer auch an die Leistungsfähigkeit 
der für die Tests verwendeten Grafikkarte angepasst werden.

<div class="p"><!----></div>
Dennoch machen diese Ergebnisse mit Nachdruck deutlich, dass 
Matrixmultiplikationen durch entsprechende Hardware und gputools extrem 
beschleunigt werden können und man somit in der Lage ist, stunden- oder 
tagelange Rechenprozeduren deutlich zu verkürzen. Nun muss nur noch 
abgewogen werden, ob dieser Geschwindigkeitsvorteil die monetären Kosten 
ausgleicht.

<div class="p"><!----></div>
Hier schließt sich dann der Kreis zu der Empfehlung, die CUDA-basierte 
Entwicklung, wenn möglich, lokal durchzuführen. Unter Minderung der 
Dimensionen kann bei einer Vielzahl von Aufgabenstellungen ohne den 
Kostendruck, der durch die Anmietung eines Hochleistungssystems entstehen 
würde, ausgiebig getestet werden. 

<div class="p"><!----></div>

<h2>Fazit</h2>


Die Nutzung von GPUs für statistische Berechnungen in R ist eine 
interessante Option. Da auf den meisten Desktop-Rechnern Grafikkarten 
installiert sind, benötigt man für den Einstieg oft nicht einmal neue 
Hardware. Wem die Heim-Grafikkarte nicht ausreicht, dem werden 
Cloud-Angebote für Gelegenheitsprojekte empfohlen. Die Einrichtung ist 
allgemein recht unproblematisch. In R selbst kann man entweder auf einige 
bereits existierende Pakete zurückgreifen oder auch eigene Bibliotheken 
schreiben. Da der Funktionsumfang der verfügbaren Pakete leider noch sehr 
übersichtlich ist, wird man schnell das Bedürfnis entwickeln, letztere 
Option auszuprobieren. Dennoch können allein die verfügbaren Pakete 
beachtliche Geschwindigkeitsvorteile mit sich bringen. Die 
Beschleunigungsfaktoren bei speziellen Operationen liegen im dreistelligen 
Bereich.

<div class="p"><!----></div>
Ein paar Mankos sollten allerdings nicht unerwähnt bleiben:

<div class="p"><!----></div>

<ul>
<li> NVIDIAs CUDA-Plattform ist momentan dominierend. Wünschenswert wäre eine 
stärkere Öffnung hin zu offenen Plattformen (OpenCL).</li>
<li> GPU-Einsatz lohnt sich nur dann, wenn die Fixkosten durch die Übertragung 
zwischen dem Arbeitsspeicher der GPU und der CPU im Vergleich zum 
Gesamtzeitverbrauch der Berechnung klein ist. Der Einsatz lohnt sich also 
nur bei rechenintensiven Aufgaben.</li>
<li> Da der Arbeitsspeicher einer GPU recht knapp bemessen ist, passen sehr 
große Daten nur scheibchenweise dort hinein. Die Programmierung wird dann 
zusätzlich aufwändig. </li>
</ul>

<div class="p"><!----></div>
Wünschenswert wäre ein noch stärkeres Engagement der 
R-Entwicklergemeinschaft, entsprechende Funktionalitäten über fertige Pakete 
auch Laien verfügbar zu machen. Dies wäre für viele R-Nutzer eine große 
Bereicherung. 

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="https://developer.nvidia.com/cuda-gpus"><tt class="big">https://developer.nvidia.com/cuda-gpus</tt></a><br />
[2] <a href="https://developer.nvidia.com/"><tt class="big">https://developer.nvidia.com/</tt></a><br />
[3] <a href="http://www.r-project.org/"><tt class="big">http://www.r-project.org/</tt></a><br />
[4] <a href="https://aws.amazon.com/de/ec2/instance-types/"><tt class="big">https://aws.amazon.com/de/ec2/instance-types/</tt></a><br />
[5] <a href="http://cran.r-project.org/web/packages/gputools/"><tt class="big">http://cran.r-project.org/web/packages/gputools/</tt></a><br />
[6] <a href="http://www.khronos.org/opencl/"><tt class="big">http://www.khronos.org/opencl/</tt></a><br />
[7] <a href="https://de.wikipedia.org/wiki/GPL"><tt class="big">https://de.wikipedia.org/wiki/GPL</tt></a><br />
[8] <a href="http://www.netlib.org/lapack/"><tt class="big">http://www.netlib.org/lapack/</tt></a><br />
[9] <a href="https://de.wikipedia.org/wiki/Satz_von_Bayes"><tt class="big">https://de.wikipedia.org/wiki/Satz_von_Bayes</tt></a><br />
[10] <a href="http://www.tldp.org/HOWTO/Module-HOWTO/x73.html"><tt class="big">http://www.tldp.org/HOWTO/Module-HOWTO/x73.html</tt></a><br />
[11] <a href="https://www.kernel.org/doc/Documentation/filesystems/ramfs-rootfs-initramfs.txt"><tt class="big">https://www.kernel.org/doc/Documentation/filesystems/ramfs-rootfs-initramfs.txt</tt></a><br />
[12] <a href="https://developer.nvidia.com/cuda-downloads"><tt class="big">https://developer.nvidia.com/cuda-downloads</tt></a><br />
[13] <a href="http://developer.download.nvidia.com/compute/cuda/5_0/rel-update-1/installers/cuda_5.0.35_linux_64_ubuntu11.10-1.run"><tt class="big">http://developer.download.nvidia.com/compute/cuda/5_0/rel-update-1/installers/cuda_5.0.35_linux_64_ubuntu11.10-1.run</tt></a><br />
[14] <a href="http://cran.r-mirror.de/bin/"><tt class="big">http://cran.r-mirror.de/bin/</tt></a><br />
[15] <a href="http://cran.r-mirror.de/sources.html"><tt class="big">http://cran.r-mirror.de/sources.html</tt></a><br />
[16] <a href="http://www.rstudio.com/"><tt class="big">http://www.rstudio.com/</tt></a><br />
[17] <a href="http://www.rstudio.com/ide/docs/"><tt class="big">http://www.rstudio.com/ide/docs/</tt></a><br />
[18] <a href="http://cran.r-project.org"><tt class="big">http://cran.r-project.org</tt></a><br />
[19] <a href="http://cran.r-project.org/src/contrib/gputools_0.28.tar.gz"><tt class="big">http://cran.r-project.org/src/contrib/gputools_0.28.tar.gz</tt></a><br />
    

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="1" align="center"><b>Autoreninformation</b></td></tr>
<tr><td align="left"><b>Markus Lilienthal und Markus Herrmann</b>
sind beide in der Marktforschung tätig. Lilienthal hat über den 
Einsatz von Cloud Computing promoviert und arbeitet intensiv mit R. Herrmann ist im Bereich 
Computational Statistics beschäftigt.
    </td></tr></table>
<br />

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=GPU-Computing mit R#comment-form"><i>Diesen Artikel kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
<h1><font color="#595959"><a id="fm_13_12_aequivalente_windows_programme_2" name="fm_13_12_aequivalente_windows_programme_2">Äquivalente Windows-Programme unter Linux – Teil 2</a></font></h1>von Maria Seliger

<div class="p"><!----></div>
    <b>D</b><b>er zweite Teil der Artikelserie widmet sich der PDF-Erstellung und 
-Bearbeitung. Ein PDF-Dokument (Portable Document 
Format&nbsp;<a href="https://de.wikipedia.org/wiki/PDF">[1]</a>) ist ein Dateiformat für 
Dokumente, das vom Unternehmen Adobe Systems&nbsp;<a href="http://www.adobe.com/de/">[2]</a> 
entwickelt wurde. Die Dokumente werden in der Regel auf jeder Plattform bzw.
Betriebssystem immer in der Form angezeigt, wie sie der jeweilige Autor 
ursprünglich formatiert hat (Seitenumbrüche etc.). Dabei eignet sich das 
Format insbesondere auch als Austauschformat für Dokumente.</b>

<div class="p"><!----></div>

<h2>PDF-Betrachter</h2>


Unter Linux gibt es eine ganze Menge PDF-Betrachter. Hier werden einige 
davon vorgestellt, die besonders empfehlenswert sind (siehe hierzu auch den 
Artikel „PDF-Betrachter im Test“ in <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> 
08/2009&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2009-08">[3]</a>).

<div class="p"><!----></div>

<h3>Adobe Reader</h3>


Der Standard, an dem sich alle PDF-Betrachter messen müssen, ist der Adobe 
Reader&nbsp;<a href="http://get.adobe.com/de/reader/">[4]</a>, unter Linux in der Version 9. Der 
Adobe Reader ist in manchen Fällen erforderlich, hat aber auch erhebliche 
Nachteile.

<div class="p"><!----></div>
Erforderlich ist der Adobe Reader z.&nbsp;B. dann, wenn man sich PDF-Dokumente 
ausleiht (z.&nbsp;B. elektronische Bücher aus der Stadtbücherei), die mit DRM 
(Digital Rights 
Management&nbsp;<a href="https://de.wikipedia.org/wiki/Digitale_Rechteverwaltung">[5]</a>) 
versehen sind. Auch eignet sich der Adobe Reader gut für die Bearbeitung von 
PDF-Dokumenten, die für die direkte Kommentierung freigegeben worden sind.

<div class="p"><!----></div>
Nachteilig beim Adobe Reader ist der große Ressourcenverbrauch und die oft 
auftretenden Sicherheitslücken (speziell unter Windows).

<div class="p"><!----></div>

<ul>
<li> Homepage: <a href="http://get.adobe.com/de/reader/"><tt class="big">http://get.adobe.com/de/reader/</tt></a></li>
<li> Lizenz: proprietär, Freeware, kostenlos</li>
<li> Unterstützte Betriebssysteme: Windows, Mac OS X, Linux, Solaris, UNIX,
MS-DOS, Palm OS, Symbian OS, Android, iOS, Windows Phone</li>
</ul>

<div class="p"><!----></div>
Auch wenn man andere PDF-Betrachter bevorzugt – manchmal muss es dieser 
sein. Besonders, wenn es sich um DRM-geschützte Dokumente handelt.

<div class="p"><!----></div>

<h3>Evince Document Viewer</h3>


Der Evince Document Viewer&nbsp;<a href="https://projects.gnome.org/evince/">[6]</a> ist ein 
Dokumentbetrachter für die GNOME-Arbeitsumgebung. Mit diesem Programm lassen 
sich PDF- und PostScript-Dokumente betrachten.

<div class="p"><!----></div>
Das Programm bietet die klassischen Funktionen eines PDF-Betrachters, wie 
Drucken, Versenden, Drehen von Seiten, Zoom, Thumbnails, Präsentationsmodus. 


<div class="p"><!----></div>
Mit dem Programm lassen sich auch Lesezeichen (Bookmarks) erstellen, 
allerdings werden diese nur innerhalb des Document Viewers angezeigt. Das 
Programm bietet (theoretisch) auch die Möglichkeit Anmerkungen zu erstellen, 
aber beim Test unter Lubuntu 13.10 hat dies nicht funktioniert.

<div class="p"><!----></div>

<ul>
<li> Homepage: <a href="https://projects.gnome.org/evince/"><tt class="big">https://projects.gnome.org/evince/</tt></a></li>
<li> Lizenz: GPL, kostenlos</li>
<li> Unterstützte Betriebssysteme: Linux, Solaris, BSD, andere Unix-Derivate, Windows</li>
</ul>

<div class="p"><!----></div>
Evince Document Viewer ist ein geeigneter Viewer für PDF-Dokumente, bietet 
aber kaum

Mehrwert und der Seitenaufbau ist bei komplexen PDF-Dokumenten 
relativ langsam.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/winprog2-Evince.png" alt="winprog2-Evince.png" style="max-width:100%" /><br /><em>Evince Document Viewer mit Vorschauleiste.</em><br />

<div class="p"><!----></div>

<h3>Okular Universal Document Viewer</h3>


Okular&nbsp;<a href="http://okular.kde.org/">[7]</a> ist das Gegenstück zu Evince, es ist der 
Dokumentbetrachter für die KDE-Arbeitsumgebung. Es handelt sich um einen 
Dokumentbetrachter mit „Mehrwert“. Über diverse Bibliotheken unterstützt 
dieser Dokumentbetrachter nicht nur PDF- und Postscript-Dokumente, sondern 
auch sehr viele andere Formate, wie z.&nbsp;B. TIFF, ODF oder DjVU. Anders als im 
Adobe Reader kann man in beliebigen Dokumenten (sofern diese nicht besonders 
geschützt sind)
Anmerkungen erstellen, die auch im Adobe Reader betrachtet 
werden können.

<div class="p"><!----></div>
Mit dem Programm lassen sich auch Lesezeichen (Bookmarks) erstellen, 
allerdings werden diese nur innerhalb von Okular angezeigt. 

<div class="p"><!----></div>

<ul>
<li> Homepage: <a href="http://okular.kde.org/"><tt class="big">http://okular.kde.org/</tt></a></li>
<li> Lizenz: GPL, kostenlos</li>
<li> Unterstützte Betriebssysteme: Unix-ähnliche (u.&nbsp;a. FreeBSD, Linux, Mac OS X), Windows</li>
</ul>

<div class="p"><!----></div>
Okular ist eine gute Alternative zum Adobe Reader, vor allem dann,
wenn man 
Dokumente kommentieren möchte.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/winprog2-Okular.png" alt="winprog2-Okular.png" style="max-width:100%" /><br /><em>Okular Universal Document Viewer mit Werkzeugleiste für Anmerkungen.</em><br />

<div class="p"><!----></div>

<h2>PDF-Erzeugung und -Bearbeitung</h2>



<h3>LibreOffice und OpenOffice</h3>


LibreOffice und OpenOffice bieten die Möglichkeit, Dateien in das PDF-Format 
zu exportieren.

<div class="p"><!----></div>
Dabei bietet der Export verschiedene Möglichkeiten an, was 
alles exportiert werden soll (z.&nbsp;B. Lesezeichen). Wichtig ist 
die Möglichkeit, dass die Ursprungsdatei mit in das PDF-Format einfließt, 
sodass eine spätere Bearbeitung möglich ist.

<div class="p"><!----></div>
Durch die Aktivierung des Schalters „<em>Embed OpenDocument file</em>“ beim Export 
als PDF-Datei lässt sich das Dokument später leichter in LibreOffice 
nachbearbeiten. Zur Bearbeitung werden die PDF-Dokumente mit LibreOffice Draw 
geöffnet. Dort kann z.&nbsp;B. der Text in einem PDF-Dokument dann geändert werden.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/winprog2-LibreOfficeExportAsPDF.png" alt="winprog2-LibreOfficeExportAsPDF.png" style="max-width:100%" /><br /><em>LibreOffice-PDF-Export.</em><br />

<div class="p"><!----></div>
Weitere Informationen zu LibreOffice bzw. OpenOffice finden sich im ersten 
Teil der Serie „Äquivalente Windows-Programme unter Linux” in 
<b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> 11/2013&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2013-11">[8]</a>.

<div class="p"><!----></div>

<h2>PDF-Erzeugung</h2>


PDF-Dateien können mit verschiedenen Programmen erzeugt werden. Dazu zählen 
klassische Office-Programme, aber auch Textauszeichnungssysteme wie z.&nbsp;B. 
eine LaTeX-Umgebung. 

<div class="p"><!----></div>

<h3>PDF-Erzeugung per Export</h3>


Die meisten Office-Programme, die das Open-Document-Format erzeugen können, 
bieten auch die Möglichkeit der PDF-Erzeugung an, z.&nbsp;B. LibreOffice, 
OpenOffice, AbiWord (siehe oben).

<div class="p"><!----></div>

<h3>PDF-Erzeugung per Drucker</h3>



<h4>cups-pdf-Drucker</h4>


Um PDF-Dateien unter Linux zu erzeugen, bietet sich der virtuelle 
cups-pdf-Drucker&nbsp;<a href="http://www.cups-pdf.de/">[9]</a> an. Es handelt sich um einen 
virtuellen Druckertreiber, der aus allen Programmen, die die Möglichkeit des 
Druckens bieten, angesprochen werden kann. Dieser Drucker erscheint 
in der Systemsteuerung unter den Druckern und lässt sich dort 
auch konfigurieren.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/winprog2-cupspdfproperties.png" alt="winprog2-cupspdfproperties.png" style="max-width:100%" /><br /><em>cups-pdf-Drucker: Konfiguration.</em><br />

<div class="p"><!----></div>
Um z.&nbsp;B. ein PDF von einer Grafik zu erzeugen, ruft man die Druckfunktion 
des Bildbetrachters auf und wählt den PDF-Drucker als Ziel aus. Die erzeugte 
PDF-Datei wird im Home-Verzeichnis im Ordner <b><tt class="big">PDF</tt></b> gespeichert.

<div class="p"><!----></div>

<ul>
<li> Homepage: <a href="http://www.cups-pdf.de/"><tt class="big">http://www.cups-pdf.de/</tt></a></li>
<li> Lizenz: GPL, kostenlos</li>
<li> Unterstützte Betriebssysteme: Linux, Mac OS X, BSD</li>
</ul>

<div class="p"><!----></div>
Der Drucker kann überall dort eingesetzt werden, wo ein Programm keinen 
nativen PDF-Export bietet.

<div class="p"><!----></div>

<h3>PDF-Erzeugung aus gescannten Dokumenten</h3>



<h4>gscan2pdf</h4>


Das Programm gscan2pdf&nbsp;<a href="http://gscan2pdf.sourceforge.net/">[10]</a> ermöglicht es, 
aus gescannten Dokumenten PDF-Dokumente zu erzeugen und den Inhalt der 
Dateien per Texterkennung (OCR&nbsp;<a href="https://de.wikipedia.org/wiki/Texterkennung">[11]</a>) 
zu ermitteln. Somit eignet sich das Programm insbesondere dann, wenn man 
Papierdokumente in einem elektronischen Archiv aufbewahren will.


<div class="p"><!----></div>
Zunächst scannt man die Papierdokumente ein. Dies kann direkt aus gscan2pdf 
erfolgen. Dann lässt man eine Texterkennung über die Dokumente laufen. 
Anschließend speichert man die Dokumente als PDF mit optionalen OCR-Inhalt.

<div class="p"><!----></div>
Folgende OCR-Maschinen werden von gscan2pdf unterstützt:

<div class="p"><!----></div>

<ul>
<li> gocr&nbsp;<a href="http://jocr.sourceforge.net/">[12]</a></li>
<li> tesseract&nbsp;<a href="https://code.google.com/p/tesseract-ocr/">[13]</a></li>
<li> cuneiform&nbsp;<a href="http://en.openocr.org/">[14]</a></li>
</ul>

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/winprog2-gscan2pdf.png" alt="winprog2-gscan2pdf.png" style="max-width:100%" /><br /><em>gscan2pdf mit tesseract-Texterkennung.</em><br />

<div class="p"><!----></div>
Die Texterkennung mit tesseract in Deutsch funktioniert einigermaßen gut – 
zumindest ist sie ausreichend, um die Datei per Schlagwörtern 
wiederzufinden. Der Editor für den OCR-Text ist allerdings etwas umständlich 
zu bedienen.

<div class="p"><!----></div>

<ul>
<li> Homepage: <a href="http://gscan2pdf.sourceforge.net/"><tt class="big">http://gscan2pdf.sourceforge.net/</tt></a></li>
<li> Lizenz: GPL, kostenlos</li>
<li> Unterstützte Betriebssysteme: Linux</li>
</ul>

<div class="p"><!----></div>
gscan2pdf eignet sich hervorragend für die elektronische Archivierung von 
Papierdokumenten. Die OCR-Erkennung könnte aber etwas besser sein.

<div class="p"><!----></div>

<h2>PDF-Bearbeitung</h2>


Für die PDF-Bearbeitung steht unter Linux eine Vielzahl von Programmen zur 
Verfügung. Allerdings sind diese meistens auf einen Teilbereich 
spezialisiert, sodass man oft mehrere Tools parallel nutzen muss.

<div class="p"><!----></div>

<h3>PDF Mod</h3>


PDF Mod&nbsp;<a href="https://wiki.gnome.org/Apps/PdfMod">[15]</a> bietet vielfältige 
Funktionen, um PDF-Dokumente zu manipulieren:

<div class="p"><!----></div>

<ul>
<li> Ändern der Eigenschaften der PDF-Datei („<em>Properties</em>“: Titel, Stichwörter, Autor, Thema)</li>
<li> Einfügen von Seiten („<em>Insert from</em>“)</li>
<li> Entnehmen von Seiten („<em>Extract</em>“)</li>
<li> Entfernen von Seiten aus einem Dokument („<em>Remove</em>“)</li>
<li> Drehen von Seiten</li>
<li> Hinzufügen von Lesezeichen („<em>Bookmarks</em>“) zu einem Dokument.</li>
</ul>


<div class="p"><!----></div>



PDF Mod ist Teil der GNOME-Umgebung, benötigt GTK und nutzt die Poppler-Bibliothek zur Darstellung der PDF-Dateien.

<div class="p"><!----></div>

<ul>
<li> Homepage: <a href="https://wiki.gnome.org/Apps/PdfMod"><tt class="big">https://wiki.gnome.org/Apps/PdfMod</tt></a></li>
<li> Lizenz: GPL, kostenlos</li>
<li> Unterstützte Betriebssysteme: Linux, BSD</li>
</ul>


<div class="p"><!----></div>
Mit PDF Mod lassen sich PDF-Dateien nachbearbeiten und neu 
zusammenstellen. Die Bookmark-Funktion ist besonders hervorzuheben.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/winprog2-PDFMod.png" alt="winprog2-PDFMod.png" style="max-width:100%" /><br /><em>PDF Mod: Bearbeiten der Eigenschaften der PDF-Datei.</em><br />

<div class="p"><!----></div>

<h4>Alternativen</h4>




<ul>
<li> PDF Sam (Split &amp; Merge)&nbsp;<a href="http://www.pdfsam.org/">[16]</a> (siehe auch 
„PDF-Zerteilung nach Maß“, freiesMagazin  
07/2009&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2009-07">[17]</a></li>
<li> PDF Shuffler&nbsp;<a href="http://pdfshuffler.sourceforge.net/">[18]</a></li>
</ul>

<div class="p"><!----></div>

<h3>PDF Chain</h3>


PDF Chain&nbsp;<a href="http://pdfchain.sourceforge.net/">[19]</a> ist ein ähnlich mächtiges 
Tool wie PDF Mod, bietet aber andere Manipulationen als dieses an:

<div class="p"><!----></div>

<ul>
<li> Verbinden von PDF-Dateien („<em>Concatenate</em>“)</li>
<li> Seiten-Extraktion („<em>Burst</em>“), d.&nbsp;h. das PDF-Dokument wird in einzelne 
Seiten aufgeteilt</li>
<li> Hinzufügen eines Hintergrundes oder eines Wasserzeichens zu einer 
PDF-Datei („<em>Background&nbsp;-&#62;&nbsp;Stamp</em>“). Dabei muss der Hintergrund bzw. das 
Wasserzeichen in einer Datei gespeichert sein.</li>
<li> Hinzufügen von Anhängen zum PDF-Dokument („<em>Attachments</em>“).</li>
<li> Verschiedene Manipulationen von Anhängen, Datenfelder und Formulardaten 
(„<em>Tools</em>“). Hier können z.&nbsp;B. Anhänge aus einem PDF-Dokument extrahiert 
werden („<em>Unpack attached files from PDF file</em>“) oder Kommentare in einem 
PDF-Dokument in dieses fest und unlöschbar integriert werden („<em>A PDF 
flatten file</em>“).</li>
<li> Ändern der Rechte an einem PDF-Dokument (unter „<em>Permissions</em>“). So kann
man z.&nbsp;B. ein Password zum Öffnen des PDF-Dokuments vergeben.</li>
</ul>

<div class="p"><!----></div>
PDF Chain ist eine grafische GUI für das kostenlose 
Kommandozeilen-Pdftk-Toolkit (siehe hierzu auch „Auf Klick folgt Schnitt: PDF Chain“, 
freiesMagazin 08/2009&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2009-08">[3]</a>, 
und „Kurztipp: Bastelstunde mit Pdftk“, freiesMagazin 
03/2009&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2009-03">[20]</a>).

<div class="p"><!----></div>

<ul>
<li> Homepage: <a href="http://pdfchain.sourceforge.net/"><tt class="big">http://pdfchain.sourceforge.net/</tt></a></li>
<li> Lizenz: GPL, kostenlos</li>
<li> Unterstützte Betriebssysteme: Linux</li>
</ul>

<div class="p"><!----></div>
PDF Chain bietet sich besonders dafür an, Wasserzeichen oder Anhänge zu 
einem Dokument hinzuzufügen oder die Rechte oder die Daten in einem 
PDF-Dokument zu manipulieren.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/winprog2-PDFChain.png" alt="winprog2-PDFChain.png" style="max-width:100%" /><br /><em>PDF Chain – Registerkarte „<em>Tools</em>“.</em><br />

<div class="p"><!----></div>

<h3>Vergleich von zwei PDF-Dateien</h3>


Mit dem Tool DiffPDF&nbsp;<a href="http://www.qtrac.eu/diffpdf.html">[21]</a> lassen sich zwei 
PDF-Dateien inhaltlich vergleichen. Dabei werden dann die Unterschiede in 
den Dateien vermerkt. Das ist sinnvoll, wenn man nicht mehr weiß, was die 
aktuelle Version eines Dokuments ist.

<div class="p"><!----></div>
Das Programm bietet verschiedene Vergleichsmodi an: visuell, 
Zeichen-für-Zeichen, Wort-für-Wort. Für Textdateien eignet sich insbesondere 
der Wort-für-Wort-Vergleichsmodus, für Bilddateien der visuelle 
Vergleichsmodus.

<div class="p"><!----></div>

<ul>
<li> Homepage: <a href="http://www.qtrac.eu/diffpdf.html"><tt class="big">http://www.qtrac.eu/diffpdf.html</tt></a></li>
<li> Lizenz: GPL, kostenlos</li>
<li> Unterstützte Betriebssysteme: Linux, spezielle Builds für Windows, Mac OS X, OS/2</li>
</ul>

<div class="p"><!----></div>
Das Programm eignet sich gut, um verschiedene Versionen eines Dokumentszu vergleichen.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/winprog2-DiffPDF.png" alt="winprog2-DiffPDF.png" style="max-width:100%" /><br /><em>Vergleich zweier PDF-Dateien mit DiffPDF.</em><br />

<div class="p"><!----></div>

<h3>PDF-Dokumente beschneiden</h3>


Wenn man einen E-Book-Reader besitzt, möchte man oft auch mit diesem auch 
PDF-Dateien lesen. Dabei gibt es das 
Problem, dass je nach Reader die PDF-Dateien nur schlecht auf einem Reader 
zu lesen sind, weil sie einen großen Rand besitzen oder weil sie mehrspaltig 
angelegt sind. Für solche Dokumente gibt es PDF-Programme, die solche 
Dokumente beschneiden (crop) bzw. aus mehrspaltigen einspaltige Dokumente 
machen. Damit lassen sich dann PDF-Dokumente besser mit einem E-Book-Reader 
lesen.

<div class="p"><!----></div>
Ein betriebssystemübergreifendes Tool ist 
briss&nbsp;<a href="http://briss.sourceforge.net/">[22]</a>. Das Programm ist in Java 
programmiert und bietet sowohl die Beschneidung als

auch die Umwandlung 
mehrspaltiger in einspaltige Dokumente an.

<div class="p"><!----></div>
Beim Laden eines Dokuments kann man festlegen, welche Teile des Dokuments 
übereinandergelegt und beschnitten werden sollen. Im Standard werden alle 
geraden und alle ungeraden Seiten übereinandergelegt und dann ein 
Rahmen definiert, der die Seiten beschneiden soll.

<div class="p"><!----></div>

<ul>
<li> Homepage: <a href="http://briss.sourceforge.net/"><tt class="big">http://briss.sourceforge.net/</tt></a></li>
<li> Lizenz: GPL, kostenlos</li>
<li> Unterstützte Betriebssysteme: alle Betriebssysteme, die auch Java können</li>
</ul>

<div class="p"><!----></div>
briss ist ein hervorragendes Werkzeug, um PDF-Dokumente zu beschneiden oder um aus mehrspaltigen Dokumenten einspaltige zu machen.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/winprog2-briss.png" alt="winprog2-briss.png" style="max-width:100%" /><br /><em>PDF-Beschneidung mit briss.</em><br />

<div class="p"><!----></div>
Eine Alternative ist Scan Tailor&nbsp;<a href="http://scantailor.sourceforge.net/">[23]</a>.

<div class="p"><!----></div>

<h2>Fazit</h2>


Wie man in diesem Artikel gesehen hat, gibt es unter Linux eine Vielzahl von 
Werkzeugen, mit denen sich PDF-Dateien erzeugen, ansehen und bearbeiten 
lassen. Allerdings gibt es nicht eine „eierlegende Wollmilchsau“ wie z.&nbsp;B. 
den kommerziellen Acrobat Standard, sondern im Allgemeinen ist eine Vielzahl 
von Programmen erforderlich. 

<div class="p"><!----></div>
Für eine erfolgreiche PDF-Bearbeitung decken die Programme cups-pdf-Drucker, 
Okular, PDF Mod, PDF Chain, DiffPDF sowie briss alle wichtigen Funktionen im 
PDF-Bereich ab. 

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="https://de.wikipedia.org/wiki/PDF"><tt class="big">https://de.wikipedia.org/wiki/PDF</tt></a><br />
[2] <a href="http://www.adobe.com/de/"><tt class="big">http://www.adobe.com/de/</tt></a><br />
[3] <a href="http://www.freiesmagazin.de/freiesMagazin-2009-08"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2009-08</tt></a><br />
[4] <a href="http://get.adobe.com/de/reader/"><tt class="big">http://get.adobe.com/de/reader/</tt></a><br />
[5] <a href="https://de.wikipedia.org/wiki/Digitale_Rechteverwaltung"><tt class="big">https://de.wikipedia.org/wiki/Digitale_Rechteverwaltung</tt></a><br />
[6] <a href="https://projects.gnome.org/evince/"><tt class="big">https://projects.gnome.org/evince/</tt></a><br />
[7] <a href="http://okular.kde.org/"><tt class="big">http://okular.kde.org/</tt></a><br />
[8] <a href="http://www.freiesmagazin.de/freiesMagazin-2013-11"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2013-11</tt></a><br />
[9] <a href="http://www.cups-pdf.de/"><tt class="big">http://www.cups-pdf.de/</tt></a><br />
[10] <a href="http://gscan2pdf.sourceforge.net/"><tt class="big">http://gscan2pdf.sourceforge.net/</tt></a><br />
[11] <a href="https://de.wikipedia.org/wiki/Texterkennung"><tt class="big">https://de.wikipedia.org/wiki/Texterkennung</tt></a><br />
[12] <a href="http://jocr.sourceforge.net/"><tt class="big">http://jocr.sourceforge.net/</tt></a><br />
[13] <a href="https://code.google.com/p/tesseract-ocr/"><tt class="big">https://code.google.com/p/tesseract-ocr/</tt></a><br />
[14] <a href="http://en.openocr.org/"><tt class="big">http://en.openocr.org/</tt></a><br />
[15] <a href="https://wiki.gnome.org/Apps/PdfMod"><tt class="big">https://wiki.gnome.org/Apps/PdfMod</tt></a><br />
[16] <a href="http://www.pdfsam.org/"><tt class="big">http://www.pdfsam.org/</tt></a><br />
[17] <a href="http://www.freiesmagazin.de/freiesMagazin-2009-07"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2009-07</tt></a><br />
[18] <a href="http://pdfshuffler.sourceforge.net/"><tt class="big">http://pdfshuffler.sourceforge.net/</tt></a><br />
[19] <a href="http://pdfchain.sourceforge.net/"><tt class="big">http://pdfchain.sourceforge.net/</tt></a><br />
[20] <a href="http://www.freiesmagazin.de/freiesMagazin-2009-03"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2009-03</tt></a><br />
[21] <a href="http://www.qtrac.eu/diffpdf.html"><tt class="big">http://www.qtrac.eu/diffpdf.html</tt></a><br />
[22] <a href="http://briss.sourceforge.net/"><tt class="big">http://briss.sourceforge.net/</tt></a><br />
[23] <a href="http://scantailor.sourceforge.net/"><tt class="big">http://scantailor.sourceforge.net/</tt></a><br />
    

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="1" align="center"><b>Autoreninformation</b></td></tr>
<tr><td align="left"><b>Maria Seliger</b>&nbsp;(<a href="http://scriptogr.am/msel">Webseite</a>)
ist vor fünf Monaten von Windows 7 auf Lubuntu umgestiegen, was wider 
Erwarten schnell und problemlos ging, da sich für die meisten Programme eine gute Alternative unter Linux fand.
    </td></tr></table>
<br />

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=%C3%84quivalente Windows-Programme unter Linux - Teil 2#comment-form"><i>Diesen Artikel kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
<h1><font color="#595959"><a id="fm_13_12_openvpn" name="fm_13_12_openvpn">Mit OpenVPN Firmen-Firewalls überwinden</a></font></h1>von Hans-Joachim Baader

<div class="p"><!----></div>
    <b>M</b><b>it OpenVPN kann man jede noch so restriktive Unternehmens-Firewall 
überwinden, sofern sie wenigstens einen Port für ein verschlüsseltes 
Protokoll offen lässt. Oft ist das der Port für das Protokoll HTTPS. Seinen 
eigenen HTTPS-Server kann man trotzdem weiter an diesem Port betreiben.</b>

<div class="p"><!----></div>
<b>Redaktioneller Hinweis:</b> <i>Der Artikel „Über die Mauer – Mit OpenVPN Firmen-Firewalls 
überwinden“ erschien erstmals bei 
Pro-Linux&nbsp;<a href="http://www.pro-linux.de/artikel/2/1650/ueber-die-mauer.html">[1]</a>.</i>

<div class="p"><!----></div>

<h2>Motivation</h2>


Das Szenario dürfte vielen bekannt sein: Man sitzt in der Arbeit hinter 
einer Firewall, die im Extremfall nur das Webbrowsen zulässt. Nur die Ports 
80 (HTTP) und 443 (HTTPS) sind dafür offen. Will man sich jetzt 
beispielsweise per SSH mit seinem Rechner daheim verbinden, hat man ein 
Problem. Es existieren Möglichkeiten, dies mit einem webbasierten SSH-Client 
(Ajaxterm/WebShell&nbsp;<a href="http://code.google.com/p/web-shell/">[2]</a>, Shell in a 
Box&nbsp;<a href="http://code.google.com/p/shellinabox/">[3]</a>) zu umgehen. Die Installation 
dieser Software muss auf dem heimischen Webserver erfolgen. Doch diese 
Programme besitzen, da sie im Browser laufen, einige Einschränkungen und 
Zuverlässigkeitsprobleme.

<div class="p"><!----></div>
Es ist möglicherweise weniger bekannt, dass man ein VPN (Virtual Private 
Network) für den gleichen Zweck verwenden kann und man damit eine 
SSH-Verbindung auf der Konsole (oder wahlweise mit einem grafischen Client) 
erhält, was wesentlich komfortabler und leistungsfähiger ist. Für das VPN 
muss man einen Port auf seinem Heimrechner opfern, und aufgrund dessen, was 
die Firewall zulässt, bedeutet das, dass eventuell nur Port 443 übrig 
bleibt. Dennoch kann der eigene Webserver weiterhin HTTPS auf diesem Port 
anbieten, wie später gezeigt wird.

<div class="p"><!----></div>
Es gibt mehrere Programme zum Aufbau eines VPN unter Linux. 
OpenVPN&nbsp;<a href="http://openvpn.net/">[4]</a> ist eines davon. OpenVPN ist 
plattformunabhängig und unterstützt dynamische IP-Adressen und NAT. Bis auf 
<b><tt class="big">tun</tt></b> oder <b><tt class="big">tap</tt></b>, das in den meisten Distributionen vorhanden sein dürfte, wird 
kein spezielles Kernelmodul benötigt.

<div class="p"><!----></div>

<h2>Installation</h2>


OpenVPN dürfte in den meisten Distributionen vorhanden sein. Somit sollte 
das Paket <b>openvpn</b> ausreichen, um das Programm zu installieren. Doch muss 
OpenVPN erst konfiguriert werden, um es nutzen zu können.

<div class="p"><!----></div>
Es ist zunächst einmal nötig, einen Einstieg in die Konfiguration zu finden. 
Der Aufruf <b><tt class="big">openvpn</tt></b> zeigt eine verwirrende Zahl von Optionen, die 
letztlich die Flexibilität des Programms widerspiegeln. So mancher könnte 
angesichts dieser Optionen anfangen, nach einem anderen Programm zu suchen. 
Doch ohne sich etwas damit zu beschäftigen, geht es nun einmal nicht.

<div class="p"><!----></div>
Zuerst sollte man sich die Manpage anschauen. Schon ein kurzes Überfliegen 
(<b><tt class="big">man openvpn</tt></b>) der Manpage ergibt, dass man alle Optionen sowohl direkt 
beim Aufruf angeben als auch in eine Konfigurationsdatei schreiben kann. 
Diese Konfigurationsdatei legt man zumindest bei Debian und Opensuse unter 
<b><tt class="big">/etc/openvpn</tt></b> ab, wobei der Name beliebig sein kann. Die Dateiendung 
sollte <b><tt class="big">.conf</tt></b> lauten. Jede Datei beschreibt eine VPN-Verbindung, entweder 
als Client oder als Server, und es können beliebig viele Verbindungen 
angelegt werden. Standardmäßig werden alle derartigen Verbindungen beim 
Systemstart geöffnet. Dies kann man aber konfigurieren, bei Debian in der 
Datei <b><tt class="big">/etc/default/openvpn</tt></b>.

<div class="p"><!----></div>

<h2>Konfiguration des Servers</h2>


Der schnellste Weg zu einer funktionierenden Konfiguration ist das
Anpassen einer Beispieldatei. Die Distributionen sollten solche Dateien 
mitliefern. Bei Debian kann man beispielsweise ein VPN namens <b><tt class="big">vpn1</tt></b> 
anlegen, indem man als Root

<div class="p"><!----></div>

<div class="command"># zcat /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz &#62; /etc/openvpn/vpn1.conf</div>

<div class="p"><!----></div>


ausführt. Die Einträge sind kommentiert und mit nur wenig Konsultation der 
Manpage oder der Projekt-Homepage kann man binnen einer Stunde zu einer 
laufenden Konfiguration gelangen. Hier ein Beispiel für die Serverseite:

<div class="p"><!----></div>

<div class="listing">port $portnummer<br />
proto tcp<br />
dev tun<br />
<br />
ca /etc/openvpn/ca.crt<br />
cert /etc/openvpn/vpn1.cert.pem<br />
key /etc/openvpn/vpn1.key.pem<br />
<br />
dh /etc/openvpn/dh2048.pem<br />
<br />
server 10.9.0.0 255.255.255.0<br />
ifconfig-pool-persist ipp.txt<br />
keepalive 10 120<br />
<br />
port-share $servername $serverport<br />
<br />
user nobody<br />
group nogroup<br />
persist-key<br />
persist-tun<br />
status openvpn-status.log<br />
<br />
verb 3<br />
mute 20</div>

<div class="p"><!----></div>
<i>Listing: <a href="http://www.freiesmagazin.de/mobil/2013-12-listings/vpn1-server.conf">vpn1-server.conf</a></i>

<div class="p"><!----></div>


In der Datei sind drei Werte als Variablen markiert. Diese dürfen so 
nicht stehen bleiben, sondern müssen durch konkrete Werte ersetzt werden.

<div class="p"><!----></div>

<ul>
<li> <b><tt class="big">$portnummer</tt></b> ist standardmäßig 1194. Hat man mehrere VPNs, muss man 
natürlich weitere Ports hinzunehmen.</li>
<li> <b><tt class="big">$servername</tt></b> ist der lokale Name des Servers, <b><tt class="big">$serverport</tt></b> dessen 
Portnummer, an den Pakete weitergeleitet werden sollen, die nicht dem 
OpenVPN-Protokoll entsprechen. (optional)</li>
<li> <b><tt class="big">ca</tt></b>, <b><tt class="big">cert</tt></b> und <b><tt class="big">key</tt></b> sind die öffentlichen Krypto-Schlüssel der 
Certification Authority (CA) und des VPN-Servers sowie der private Schlüssel 
des VPN-Servers. </li>
</ul>

<div class="p"><!----></div>
Es können sich beliebig viele Clients (nicht nur einer) mit dem Server verbinden.

<div class="p"><!----></div>

<h2>Erzeugung der Server-Schlüssel</h2>


Der schwierigste Teil der Konfiguration ist die Erstellung 
von Zertifikaten. Es gibt verschiedene Möglichkeiten hierfür. Wer Mitglied 
bei CAcert&nbsp;<a href="https://www.cacert.org/">[5]</a> ist, kann sich kostenlos 
Schlüsselpaare für seine Server und Clients generieren. Kostenpflichtig wird 
es, wenn man dies bei kommerziellen Zertifizierungsstellen macht. 
Doch auch selbstsignierte Schlüssel genügen, wie man sie z.&nbsp;B. mit 
dem freien OpenSSL&nbsp;<a href="http://www.openssl.org/">[6]</a> erzeugen kann. Wer damit 
bisher nichts gemacht hat, sollte in den Beispielen von OpenVPN auch ein 
Verzeichnis <b><tt class="big">easy-rsa/2.0</tt></b> finden, in dem per Skript ganz einfach 
funktionierende Schlüssel erzeugt werden können.

<div class="p"><!----></div>
Am einfachsten ist es wahrscheinlich, wenn man bereits eine eigene CA 
eingerichtet und darin eine Datei <b><tt class="big">openssl.cnf</tt></b> definiert hat. Dann kann man 
leicht ein Server-Zertifikat generieren:

<div class="p"><!----></div>

<div class="command">$ openssl req -new -nodes -extensions server -out req.pem -config ./openssl.cnf <br />
$ openssl ca -extensions server -out cert.pem -config ./openssl.cnf -infiles req.pem</div>

<div class="p"><!----></div>


Dabei sind ein paar Eingaben zu machen, die im Prinzip alle beliebig sind. 
Als Servername kann man beispielsweise einfach <b><tt class="big">vpn1</tt></b> verwenden. Die 
Schlüssellänge kann man bereits in <b><tt class="big">openssl.cnf</tt></b> einstellen; sie sollte 
nicht unter 2048 liegen. Außerdem muss man das Passwort der CA eingeben.

<div class="p"><!----></div>
Bei der Frage „Sign the certificate? [y/n]“ muss man „y“ eingeben, ansonsten
bricht das Programm ab. Ebenso wie bei der abschließenden Frage „Commit?“. Das 
Resultat sind drei Dateien. <b><tt class="big">cert.pem</tt></b> ist der öffentliche Schlüssel des 
Servers, den man auf den Server als <b><tt class="big">/etc/openvpn/vpn1.cert.pem</tt></b> kopiert. 
Die Datei <b><tt class="big">key.pem</tt></b> ist der private Schlüssel des Servers, der auf dem 
Server als <b><tt class="big">/etc/openvpn/vpn1.key.pem</tt></b> installiert werden muss. Den 
privaten Schlüssel schützt man mittels

<div class="p"><!----></div>

<div class="command"># chmod 0600 /etc/openvpn/vpn1.key.pem</div>

<div class="p"><!----></div>


Die dritte Datei <b><tt class="big">req.pem</tt></b> löscht man.
Es fehlt noch der öffentliche 
Schlüssel der CA. Wer seine CA mit OpenSSL angelegt hat, findet ihn unter 
<b><tt class="big">root/private/root.crt</tt></b>, alle anderen müssen recherchieren. Die Datei wird 
auf dem Server als <b><tt class="big">/etc/openvpn/ca.crt</tt></b> installiert.

<div class="p"><!----></div>
Jetzt fehlt nur noch die Datei <b><tt class="big">/etc/openvpn/dh2048.pem</tt></b>. Diese generiert man mit folgendem Befehl

<div class="p"><!----></div>

<div class="command">$ openssl dhparam -out dh2048.pem 2048</div>

<div class="p"><!----></div>


und installiert sie dann auf dem Server.

<div class="p"><!----></div>
Nun kann man testen, ob alles korrekt ist, indem man OpenVPN direkt aufruft:

<div class="p"><!----></div>

<div class="command">$ openvpn /etc/openvpn/vpn1.conf</div>

<div class="p"><!----></div>








Wenn bei der Ausgabe keine Fehlermeldungen erkennbar sind, ist der Server 
nun betriebsbereit. Man kann ihn daraufhin abbrechen und fortan mittels 
<b><tt class="big">/etc/init.d/openvpn start</tt></b> starten, was künftig bei jedem Systemstart 
automatisch passieren sollte. Bei Problemen kann man neben dem Syslog auch 
<b><tt class="big">/etc/openvpn/openvpn-status.log</tt></b> und <b><tt class="big">/etc/openvpn/ipp.txt</tt></b> zu Rate ziehen.

<div class="p"><!----></div>
Nebenbei: Wer detailliertere Informationen zu den privaten und öffentlichen Schlüsseln erfahren will, muss dafür abhängig vom Format verschiedene Kommandos verwenden. Die PEM-kodierten Dateien lassen sich zwar in einem Texteditor ansehen, doch ist die gesamte Information in einer Base64-Kodierung verborgen. Folgende Kommandos helfen Interessierten hier weiter:

<div class="p"><!----></div>

<div class="command">$ openssl x509 -text &lt; /etc/openvpn/ca.crt <br />
$ openssl x509 -text &lt; /etc/openvpn/vpn1.cert.pem <br />
$ openssl rsa -text &lt; /etc/openvpn/vpn1.key.pem<br />
$ openssl dh -text &lt; /etc/openvpn/dh2048.pem</div>

<div class="p"><!----></div>



<h2>Konfiguration des Clients</h2>


Nachdem man die Server-Konfiguration gemeistert hat, ist die 
Client-Konfiguration kein Problem mehr, da sie weitgehend identisch zum 
Server ist. Die Konfigurationsdatei wird etwas modifiziert:

<div class="p"><!----></div>

<div class="listing">client<br />
dev tun<br />
proto tcp<br />
remote $server $serverport<br />
resolv-retry infinite<br />
nobind<br />
<br />
user nobody<br />
group nogroup<br />
persist-key<br />
persist-tun<br />
<br />
http-proxy-retry<br />
http-proxy $proxy $proxyport<br />
<br />
ca /etc/openvpn/ca.crt<br />
cert /etc/openvpn/client.crt<br />
key /etc/openvpn/client.key<br />
ns-cert-type server<br />
<br />
verb 3<br />
mute 20</div>

<div class="p"><!----></div>
<i>Listing: <a href="http://www.freiesmagazin.de/mobil/2013-12-listings/vpn1-client.conf">vpn1-client.conf</a></i>

<div class="p"><!----></div>


Hier sind wieder einige Werte als Variablen markiert. Diese 
dürfen so nicht stehen bleiben, sondern müssen durch konkrete Werte ersetzt 
werden.

<div class="p"><!----></div>

<ul>
<li> <b><tt class="big">$server</tt></b> ist der Name des Servers im Internet, <b><tt class="big">$serverport</tt></b> dessen 
Portnummer (oft 443).</li>
<li> <b><tt class="big">$proxy</tt></b> und <b><tt class="big">$proxyport</tt></b> sind Name (oder IP-Adresse) sowie Portnummer 
des zu verwendeten Web-Proxys. Muss man keinen Proxy verwenden, lässt man 
die beiden Zeilen mit <b><tt class="big">http-proxy</tt></b> weg. Ein konkretes Beispiel mit 
Verwendung des für Squid&nbsp;<a href="http://www.squid-cache.org/">[7]</a> typischen Ports wäre

<div class="p"><!----></div>

<div class="listing">http-proxy proxy 3128</div>

<div class="p"><!----></div>
Beim Einsatz von cntlm&nbsp;<a href="http://cntlm.sourceforge.net/">[8]</a>, der geboten ist, 
wenn man sich an einem Microsoft-Proxy authentifizieren muss, lautet die 
Zeile typischerweise

<div class="p"><!----></div>

<div class="listing">http-proxy localhost 3128</div></li>
<li> <b><tt class="big">ca</tt></b>, <b><tt class="big">cert</tt></b> und <b><tt class="big">key</tt></b> sind die öffentlichen Krypto-Schlüssel der 
Certification Authority (CA) und des Clients sowie der private Schlüssel des 
Clients. </li>
</ul>

<div class="p"><!----></div>
Kann man sich damit bereits mit dem VPN-Server verbinden? Wahrscheinlich 
nicht, es sei denn, die Server-Portnummer ist über den Firmen-Proxy 
erreichbar. Im folgenden soll der Fall betrachtet werden, dass nur die 
Portnummer 443 zur Verfügung steht. Wer keinen Webserver auf dem VPN-Server 
betreibt, kann einfach diese Portnummer für OpenVPN nehmen. Andernfalls gibt 
es zwei Möglichkeiten:

<div class="p"><!----></div>

<ol>
<li> Der VPN-Server ist direkt mit dem Internet verbunden (Root-Server etc.)</li>
<li> Der VPN-Server steht hinter einem Router (zu Hause mit DSL- oder
Kabel-Anschluss etc.) </li>
</ol>

<div class="p"><!----></div>

Fall 2 ist der einfachste. Man lässt OpenVPN auf seinem Standard-Port laufen 
und ändert die Port-Weiterleitung im Router, so dass Port 443 nicht mehr auf 
den gleichen Port des Servers, sondern auf 1194 weitergeleitet wird. Wenn 
dann noch die Zeile

<div class="p"><!----></div>

<div class="listing">port-share $servername 443</div>

<div class="p"><!----></div>


in der Konfigurationsdatei gesetzt ist, ist das Problem gelöst. 
HTTPS-Anfragen an den heimischen Server werden vom Router an den 
OpenVPN-Daemon geleitet. Dieser erkennt, dass es sich nicht um ein 
OpenVPN-Paket handelt und leitet es an den Webserver weiter.

<div class="p"><!----></div>
Fall 1 ist insofern komplizierter, als man den HTTPS-Server auf einen 
anderen Port legen muss. Das ist zwar auch nicht schwierig, aber man muss 
zumindest die Dateien <b><tt class="big">/etc/apache2/ports.conf</tt></b> sowie die Definitionen der 
virtuellen Server anpassen. Ist das erledigt und Apache neu gestartet, so 
legt man den Port von OpenVPN auf 443. Die Weiterleitung mittels 
<b><tt class="big">port-share</tt></b> legt man auf den neuen Port des Webservers.

<div class="p"><!----></div>

<h2>Abschluss</h2>


Anders als webbasierte Shells stellt die Lösung mit OpenVPN eine voll 
funktionsfähige Shell bereit, über die sich sogar X11-Anwendungen starten 
lassen, wenn auch mit einer durch den Anschluss beschränkten 
Geschwindigkeit. Der Artikel konnte nur einen kleinen Teil der vielfältigen 
Optionen von OpenVPN zeigen. Bei Fragen stehen die Dokumentation und die FAQ 
auf der Webseite&nbsp;<a href="http://openvpn.net/">[4]</a> zur Hilfe bereit.

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="http://www.pro-linux.de/artikel/2/1650/ueber-die-mauer.html"><tt class="big">http://www.pro-linux.de/artikel/2/1650/ueber-die-mauer.html</tt></a><br />
[2] <a href="http://code.google.com/p/web-shell/"><tt class="big">http://code.google.com/p/web-shell/</tt></a><br />
[3] <a href="http://code.google.com/p/shellinabox/"><tt class="big">http://code.google.com/p/shellinabox/</tt></a><br />
[4] <a href="http://openvpn.net/"><tt class="big">http://openvpn.net/</tt></a><br />
[5] <a href="https://www.cacert.org/"><tt class="big">https://www.cacert.org/</tt></a><br />
[6] <a href="http://www.openssl.org/"><tt class="big">http://www.openssl.org/</tt></a><br />
[7] <a href="http://www.squid-cache.org/"><tt class="big">http://www.squid-cache.org/</tt></a><br />
[8] <a href="http://cntlm.sourceforge.net/"><tt class="big">http://cntlm.sourceforge.net/</tt></a><br />
    

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="1" align="center"><b>Autoreninformation</b></td></tr>
<tr><td align="left"><b>Hans-Joachim Baader</b>&nbsp;(<a href="http://www.pro-linux.de/">Webseite</a>)
befasst sich seit 1993 mit Linux. 1994 schloss er erfolgreich sein 
Informatikstudium ab, machte die Softwareentwicklung zum Beruf und ist einer 
der Betreiber von Pro-Linux.de. 
    </td></tr></table>
<br />

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=Mit OpenVPN Firmen-Firewalls %C3%BCberwinden#comment-form"><i>Diesen Artikel kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
    


<h1><font color="#595959"><a id="fm_13_12_tabellenkalkulationen" name="fm_13_12_tabellenkalkulationen">Diagramme in Linux – Vier Tabellenkalkulationen im Vergleich</a></font></h1>von Martin Manns

<div class="p"><!----></div>
    <b>T</b><b>abellenkalkulationen sind aus der Arbeitswelt kaum noch wegzudenken. Eine 
ihrer Stärken ist die schnelle Visualisierung tabellarischer Daten in 
Diagrammen. Unter Linux gibt es eine Reihe freier („Free and Open Source 
Software“) Tabellenkalkulationen, die unterschiedliche Ansätze zur 
Diagrammerstellung verfolgen.</b>

<div class="p"><!----></div>

<h2>Die verglichenen Tabellenkalkulationen</h2>



<h3>LibreOffice</h3>


LibreOffice&nbsp;<a href="http://de.libreoffice.org/">[1]</a> ist eine Office-Suite, die 2010 als 
Abspaltung von OpenOffice.org&nbsp;<a href="http://www.openoffice.org/de/">[2]</a> entstanden ist. 
Die Suite umfasst die sechs Komponenten Writer (Textverarbeitung), Calc 
(Tabellenkalkulation), Impress (Präsentation), Base (Datenbankmanagement), 
Draw (Grafik) und Math (Formeleditor).

Alle Komponenten sind eng miteinander verzahnt,
sodass Ergebnisse komponentenübergreifend nutzbar sind. Für den 
Test wurde die Version 4.0.4.2 genutzt.

<div class="p"><!----></div>
Die Diagrammerstellung in LibreOffice erfolgt zunächst über einen geführten 
Dialog (Wizard), der ein Diagramm erzeugt. Anschließend werden anzupassende 
Elemente im Diagramm angeklickt und über das Kontextmenü verändert.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/tabellenkalkulation_libreoffice.png" alt="tabellenkalkulation_libreoffice.png" style="max-width:100%" /><br /><em>Diagrammerstellung in LibreOffice.</em><br />

<div class="p"><!----></div>

<h3>Gnumeric</h3>


Gnumeric&nbsp;<a href="https://projects.gnome.org/gnumeric/">[3]</a> ist eine 
Tabellenkalkulation, die von 1999 bis 2001 entwickelt wurde. Seit 2001 ist 
eine Produktiv-Version verfügbar, die bis heute weiterentwickelt wird. 
Gnumerics Ziel ist es, frei, schnell und akkurat zu sein. Gnumeric ist 
Bestandteil des GNOME Free Software Desktop 
Projekts&nbsp;<a href="https://www.gnome.org/">[4]</a>; es

ist aber nicht direkt in eine 
Office-Suite integriert.
Die Tests wurden in Version 1.12.6 durchgeführt.

<div class="p"><!----></div>
Die Diagrammerstellung in Gnumeric erfolgt zunächst über einen Dialog zur 
Typwahl. Anschließend wird das Diagramm über einen 
Attributsbaum parametriert.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/tabellenkalkulation_gnumeric.png" alt="tabellenkalkulation_gnumeric.png" style="max-width:100%" /><br /><em>Diagrammerstellung in Gnumeric.</em><br />

<div class="p"><!----></div>

<h3>Calligra Sheets</h3>


Calligra Sheets hieß früher Kspread und Calligra Tables. Es ist Teil der 
KDE-basierten Calligra Suite&nbsp;<a href="http://www.calligra.org/">[5]</a>, die 2010 als 
Abspaltung von der Software KOffice entstand. Calligra Sheets nutzt das Plug-in 
KCharts zur Diagrammerzeugung. Im Vergleich wurde die Version 2.6.4 getestet.

<div class="p"><!----></div>
In Calligra Sheets erfolgt die Erzeugung und Parametrierung von Diagrammen 
über Reiter, die im

rechten Bildschirmabschnitt erscheinen. Die Inhalte der 
Reiter hängen vom selektierten Objekt ab.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/tabellenkalkulation_calligra.png" alt="tabellenkalkulation_calligra.png" style="max-width:100%" /><br /><em>Diagrammerstellung in Calligra Sheets.</em><br />

<div class="p"><!----></div>

<h3>Pyspread</h3>


Pyspread&nbsp;<a href="http://manns.github.io/pyspread/">[6]</a> ist eine nicht-traditionelle 
Tabellenkalkulation, die seit 2008 entwickelt wird. Während die meisten 
Tabellenkalkulationen eine Zellensprache mit einem begrenzten 
Funktionsumfang nutzen, die mit Skripten ergänzt werden kann, wertet 
Pyspread in jedem Tabellenfeld Ausdrücke in der Programmiersprache
Python aus. Der Ansatz, Programmiersprachen in
Tabellenfeldern zu nutzen, ist 
bereits seit

langem von SIAG (Scheme In A Grid&nbsp;<a href="http://siag.nu/siag/">[7]</a>) 
her bekannt, das allerdings keine grafischen Diagramme erzeugt. Pyspread 
nutzt die Bibliothek matplotlib&nbsp;<a href="http://matplotlib.org/">[8]</a> zur 
Diagrammerstellung. Die Tests wurden mit der Version 0.2.5 durchgeführt.

<div class="p"><!----></div>
In Pyspread werden Diagramme über einen Dialog erstellt, in dem die 
Parametrierung der Achsen links, die Auswahl unterschiedlicher Diagrammtypen 
in der Mitte und die Parametrierung der Diagramme rechts erfolgt. Im 
Gegensatz zu den anderen Tabellenkalkulationen befindet sich ein Diagramm 
später immer in einer (in der Regel großen) Zelle.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/tabellenkalkulation_pyspread.png" alt="tabellenkalkulation_pyspread.png" style="max-width:100%" /><br /><em>Diagrammerstellung in Pyspread.</em><br />

<div class="p"><!----></div>

<h2>Anwendungsszenario</h2>


Für eine Präsentation sollen drei Diagramme erstellt werden. Diese
Diagramme 
sollen in eine Präsentation einfließen, die mit der Software 
Inkscape&nbsp;<a href="http://inkscape.org/?lang=de">[9]</a> erstellt wird.
Inkscape als 
Zielapplikation hat den Vorteil, dass kein Präsentationsprogramm einer 
Office-Suite genutzt wird. So wird vermieden, die Tabellenkalkulation einer 
Suite zu bevorzugen.

<div class="p"><!----></div>
Die eigentliche Erstellung der Präsentation mit Inkscape und den Komponenten 
JessyInk&nbsp;<a href="http://code.google.com/p/jessyink/">[10]</a> oder 
Sozi&nbsp;<a href="http://sozi.baierouge.fr/">[11]</a> ist nicht Teil des Tests. Da in beiden 
Fällen die Präsentationen im Web-Browser
erfolgen,
wird das Aussehen der 
exportierten Dateien in Firefox 23.0.1 bewertet.

<div class="p"><!----></div>
Die erstellten Diagramme sollen im SVG-Format (Scalable Vector 
Graphics&nbsp;<a href="https://de.wikipedia.org/wiki/SVG">[12]</a>) exportiert werden, da Inkscape 
SVG-basiert arbeitet. 

<div class="p"><!----></div>
Im Test werden keine Makros neu erstellt. Bereits in der Linux-Distribution 
Debian (sid/squeeze) vorhandene Makros können aber genutzt werden.

<div class="p"><!----></div>
Folgende drei Diagramme sollen erstellt werden:

<div class="p"><!----></div>

<ol>
<li> Tortendiagramm einer (fiktiven) Umfrage</li>
<li> Liniendiagramm eines Aktienindizes</li>
<li> Boxplot eines Aktienindizes</li>
</ol>

<div class="p"><!----></div>

<h2>Tortendiagramm einer Umfrage</h2>


Zur Auswertung einer fiktiven Umfrage sollen

30&nbsp;Antworten erfasst und 
ausgewertet werden. Die
Antworten bestehen aus einem Skalenwert 1-7, einer 
Ja/Nein-Frage und einer Auswahl aus den Farben rot, gelb, grün und blau.

<div class="p"><!----></div>
Die Erstellung umfasst vier Teile: 

<div class="p"><!----></div>

<ol>
<li> Eingabe der Umfragedaten von Hand in die Tabelle</li>
<li> Visualisierung der Antworthäufigkeit in Tortendiagrammen</li>
<li> Export der Tabelle und des Diagramms</li>
<li> Import der Daten in Inkscape und Erzeugung einer Browser-geeigneten SVG-Datei</li>
</ol>

<div class="p"><!----></div>

<h3>Ergebnisse</h3>


LibreOffice sticht durch eine besonders schnelle und intuitive manuelle 
Eingabe hervor, die durch die Auto-Ausfüllen-Funktion effektiv unterstützt 
wird. So wird das Abtippen bequem und geht schneller von der Hand. In 
Gnumeric ist auch eine Auto-Ausfüllen-Funktion vorhanden. Sie ist für die 
kurzen Texte des Tests jedoch nutzlos, da sie erst ab dem dritten Zeichen 
Vorschläge macht. Calligra Sheets und Pyspread bieten keine 
Auto-Ausfüllen-Funktion an. In Calligra Sheets irritiert die unscharfe 
Darstellung der Zellenschrift, die laut Bug-Report durch die im Debian Paket 
verlinkte Qt-Bibliotheksversion entsteht. In Pyspread ist die Eingabe 
ungewohnt, da für die Eingabe von Strings <i>„Strg“</i>&nbsp;+&nbsp;<i>„Enter“</i> benötigt wird.

<div class="p"><!----></div>
Alle Tabellenkalkulationen benötigen für die Erstellung der Tortendiagramme 
eine Aufbereitung der Daten in einer Häufigkeitstabelle. In LibreOffice wird 
die Funktion <b><tt class="big">ZÄHLENWENN</tt></b> verwendet, in Gnumeric und Calligra Sheets die 
gleiche, nicht eingedeutschte Funktion <b><tt class="big">COUNTIF</tt></b>. In Pyspread liefert die 
vergleichsweise komplexe List-Comprehension

<div class="p"><!----></div>

<div class="listing">len([ele for ele in S[1:31, Y-7, 0] if ele == S[X, Y-3, 0]])</div>

<div class="p"><!----></div>


das gleiche Ergebnis. Die Dokumentation der Funktionen wirkt in LibreOffice 
besonders gelungen. In Gnumeric erscheint ein eigentlich hilfreiches 
Hilfe-Popup leider an ungeeigneter Stelle über der Zielzelle. Das Popup 
lässt sich aber leicht ausschalten. Calligra Sheets und Pyspread bieten 
keine interaktive Funktionsdokumentation.

<div class="p"><!----></div>
Standard-Tortendiagramme sind in LibreOffice schnell erstellt. Änderungen 
der Diagrammeigenschaften erfolgen grafisch am Element. Dies wirkt zunächst 
intuitiv. Jedoch wird es schnell unübersichtlich, wenn die Optionen in 
unterschiedlichen Ebenen des Diagramms liegen. Will man z.&nbsp;B. jedem 
Tortenstück eine bestimmte Farbe zuweisen, muss man die Tortenstücke einzeln 
durch sehr langsames zweimaliges Klicken auf das Tortendiagramm auswählen. 
Im Vergleich hierzu wirkt die Parametrierung des Diagramms in Gnumeric über 
einen Attributsbaum systematischer. Zur Eingabe kann auch ein dargestelltes 
grafisches Element ausgewählt werden (der Baum springt an die richtige 
Stelle), was sehr zeitsparend ist. Nur die Ergänzung des Baums um neue 
Zweige etwa für Titel und Legende erschließt sich erst nach kurzem 
Durchklicken. In Calligra Sheets ist die Diagrammfunktion bei den 
grafischen Elementen in der rechten Reiterleiste zu finden. Man beginnt 
immer mit einem Balkendiagramm und passt den Diagrammtyp an. Leider 
verändern sich die Diagramme oder verschwinden teilweise beim Speichern. 
Zudem wirkt die Benutzerführung uneinheitlich. Zwei Abstürze verstärken den 
unfertigen Eindruck der Diagrammfunktion von Calligra Sheets. Pyspread 
bietet zur Diagrammerstellung einen übersichtlichen Dialog, in dem jedoch 
relevante Optionen wie die Schriftart-Auswahl und Schraffuren fehlen. Das 
erzeugte Diagramm wird teilweise von der Legende überlappt. 
Tortenbeschriftungen können nicht entfernt werden, ohne dass die Legende 
leer bleibt. Die Parameter-Eingabe erfordert zum Teil, die umfangreichen 
Tooltips zu lesen. Alle Diagramme erscheinen in einer Zelle, die 
anschließend vergrößert werden muss, was mit einem Klick auf den
„<em>Zellen verbinden</em>“-Knopf erfolgt.

<div class="p"><!----></div>
Bis auf Calligra Sheets erlauben alle Programme den direkten Export der 
Diagramme ins SVG Format. Mit LibreOffice erzeugte 
SVG-Dateien lassen sich problemlos in Inkscape öffnen, nicht aber in Firefox. Ein 
Speichern aus Inkscape heraus liefert eine Datei, die Firefox öffnen kann. 
Bei der Anzeige in Firefox verändern sich jedoch die Schriftarten im 
Diagramm. Zudem zeigt Firefox die im Diagramm verwendeten 
Schraffuren nicht 
an, sondern liefert eine weiße Fläche. Die von Gnumeric erzeugten  
SVG-Dateien lassen sich sowohl in Inkscape als auch in Firefox einwandfrei öffnen. Die 
Schraffur wirkt leicht unscharf, wird aber korrekt übernommen. Calligra 
Sheets kann keine SVG-Dateien exportieren. Daher wird stattdessen eine 
Postscript-Datei exportiert und in Inkscape geöffnet. Farben und Rahmen 
werden anschließend von Hand in Inkscape angepasst. Die Schriftart lässt 
sich nachträglich nicht effizient ändern, sodass die Schriftqualität nicht 
überzeugt. Pyspread exportiert SVG-Dateien nur, wenn die Diagrammzelle 
markiert ist. Die so erzeugten SVG-Dateien lassen sich in Inkscape und in 
Firefox problemlos öffnen. Im Test wurde in Inkscape folgendes
manuell 
nachbearbeitet: Die Legende wurde verschoben, die Tortenbeschriftungen 
wurden

entfernt und der Titel sowie das Diagramm in der Größe angepasst.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/tabellenkalkulation_1_farbe.png" alt="tabellenkalkulation_1_farbe.png" style="max-width:100%" /><br /><em>Die Tortendiagramme der Farbauswahlhäufigkeit im Vergleich.</em><br />

<div class="p"><!----></div>

<h2>Liniendiagramm eines Aktienindexes</h2>


Es soll eine Zeitreihe der Schlusskurse eines Aktienindexes importiert und als 
Liniendiagramm visualisiert werden. Die Linie soll dabei blau und 
durchgängig sein. Das Diagramm sollte gestrichelte Gitternetzlinien 
enthalten. 

<div class="p"><!----></div>
Die Erstellung umfasst vier Teile: 

<div class="p"><!----></div>

<ol>
<li> Import der Daten aus einer CSV-Datei</li>
<li> Erstellung eines Liniendiagramms</li>
<li> Export des Diagramms</li>
<li> Import des Diagramms in Inkscape und Erzeugung einer Browser-geeigneten SVG-Datei</li>
</ol>

<div class="p"><!----></div>

<h3>Ergebnisse</h3>


In allen Tabellenkalkulationen erfolgt der CSV-Import unproblematisch und 
sehr schnell. Unterschiede zeigen sich in den Dialogen. Während der Import 
in LibreOffice erwartungsgemäß funktioniert, kann in Gnumeric kein 
Spaltenformat
ausgewählt werden, da der entsprechende Knopf
inaktiv ist. Die 
Standardeinstellung
„<em>automatische Erkennung</em>“ funktioniert jedoch 
fehlerfrei. Calligra Sheets Dialog verwirrt, da beim Markieren der 
Spaltenformat-Auswahl alte Markierungen nicht gelöscht werden. Zudem werden 
für die mit „<em>nicht importieren</em>“ markierte Spalten Leerspalten in der Tabelle 
eingefügt. Pyspread schneidet beim Import die Daten ab, wenn die Tabelle 
nicht vorher vergrößert wurde, und es werden immer alle Spalten importiert.

<div class="p"><!----></div>
Bei der Liniendiagrammerstellung in LibreOffice ist die Reaktion auf Klicks 
zum Parametrieren oft zäh. Gnumeric und Pyspread bleiben dagegen sehr 
schnell. Calligra Sheets benötigt extrem viel Zeit für die 
Diagrammerstellung, ein Anpassen des Datumsbereiches der X-Achse ist nicht 
möglich und das Diagramm wirkt unbrauchbar. Zudem erschweren 
Programmabstürze in Calligra Sheets das Arbeiten. Pyspread erzeugt mit wenig 
Zeitaufwand ein Diagramm. Es fehlen jedoch die Optionen, den 
X-Achsen-Abstand im Dialog zu ändern und Schriftarten anzupassen.

<div class="p"><!----></div>
Das aus LibreOffice exportierte SVG lässt sich wie schon beim ersten 
Diagramm in Firefox erst nach Abspeichern in Inkscape öffnen. Anschließend 
ist in Firefox die Y-Achsenbeschriftung in die Mitte des Diagramms 
verschoben und steht auf dem Kopf. Abhilfe schafft Nacharbeit in Inkscape: 
Eine Kopie der Y-Achsenbeschriftung, der Ersatz des Texts und eine Drehung 
um 90 Grad. Im Gegensatz dazu funktioniert die Darstellung der aus Gnumeric 
und Pyspread im SVG-Format exportierten Diagramme einwandfrei. In Calligra 
Sheets wird beim Export eine riesige Postscript-Datei erzeugt. Beim Import 
dieser Datei in Inkscape fehlt jedoch die Diagrammlinie, ohne die das 
Diagramm unbrauchbar ist. Pyspread liefert ein qualitativ hochwertiges 
Diagramm, in dem jedes zweite Jahr beschriftet ist.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/tabellenkalkulation_2_linien.png" alt="tabellenkalkulation_2_linien.png" style="max-width:100%" /><br /><em>Liniendiagramme im Vergleich.</em><br />

<div class="p"><!----></div>

<h2>Boxplot eines Aktienindexes</h2>


Die Daten aus Aufgabe 2 sollen in eine 
Boxplot-Darstellung&nbsp;<a href="http://de.wikipedia.org/wiki/Boxplot">[13]</a> überführt werden, 
in der jedes Jahr separat in einem Boxplot dargestellt wird. Ein Boxplot ist 
eine statistische Darstellung, die einen schnellen Überblick über die Lage 
und Verteilung von Werten gibt.

<div class="p"><!----></div>
Die Erstellung umfasst vier Teile: 

<div class="p"><!----></div>

<ol>
<li> Trennung der Daten nach Jahren</li>
<li> Erstellung der Boxplots</li>
<li> Export des Diagramms</li>
<li> Import des Diagramms in Inkscape und Erzeugung einer Browser-geeigneten SVG-Datei</li>
</ol>

<div class="p"><!----></div>

<h3>Ergebnisse</h3>


Die Kurswerte der Zeitreihe des Aktienindexes werden zunächst nach Jahren 
aufgeteilt. In allen Programmen bis auf Pyspread werden hierfür rechts neben 
die zwei Spalten mit Datum und Kurswert die Zellen der obersten Zeile mit 
Jahreszahlen befüllt. In den Zellen darunter wird bis zur letzten Zeile der 
Kurswerte folgender Ausdruck (oder die englische Version) eingefügt:

<div class="p"><!----></div>

<div class="listing">=IF(A$1=YEAR(Index.$A2),Index.$B2,)</div>

<div class="p"><!----></div>


wobei <b><tt class="big">Index</tt></b> die Bezeichnung des Blattes/Reiters ist. Dies bewirkt, dass 
jede Zelle genau dann den Wert der Zeitreihe enthält, wenn das Jahr im 
Datumswert mit der Zahl in der ersten Zeile übereinstimmt.

<div class="p"><!----></div>
In Pyspread wird hingegen in ein zweites Tabellenblatt gewechselt. Die 
Jahreszahlen werden in die Zeilen der ersten Spalte geschrieben. Rechts daneben wird folgender Ausdruck eingegeben:

<div class="p"><!----></div>

<div class="listing">[val for date, val in S[1:,:2,0] if date.year == S[X, Y-1, Z]]</div>

<div class="p"><!----></div>


Das Ergebnis ist, dass jede
auf diese Weise
befüllte Zelle eine Liste der Kurswerte des 
jeweiligen Jahres liefert.

<div class="p"><!----></div>
Beide Ausdrücke erscheinen für Office- und Python-Kundige verständlich. Beim 
ersten Ausdruck wirkt die Tabelle jedoch unübersichtlich, da der Ausdruck 
108680 Mal vorkommt. Der Ausdruck in Pyspread wird hingegen nur ein Mal pro 
Jahr, d.&nbsp;h. 20 Mal in der Tabelle genutzt.

<div class="p"><!----></div>
Die Befüllung der großen Zellenzahl ist für LibreOffice kein Problem. In 
Gnumeric lässt sich beim Auto-Ausfüllen die Markierung nur langsam über die 
Tabelle ziehen, sobald sich der Bildausschnitt verschiebt. Pyspread 
berechnet die Listen ohne merkliche Verzögerung. Bei Calligra Sheets stoppt 
der Bildlauf des Blatts nach 360 Zeilen, d.&nbsp;h. man kommt nicht mehr tiefer, 
wenn die Maus während des Ziehens an den unteren Bildschirmrand bewegt wird. 
Daher werden die Zellen besser über Copy&nbsp;&amp;&nbsp;Paste vervielfältigt. Bis auf 
Calligra Sheets erfolgen die Berechnungen der Zellen schnell. Bei Calligra 
Sheets wurde der Test abgebrochen, da die Zellberechnung nach 16 Minuten 
noch nicht abgeschlossen war.

<div class="p"><!----></div>
Da LibreOffice von sich aus keine Boxplots anbietet, wurde ein 
entsprechendes Skript gesucht. Die Suche in LibreOffice selbst gestaltete 
sich durch die immense Anzahl an verfügbaren Skripten unübersichtlich. Daher 
wurde eine Webrecherche durchgeführt, bei der nach 6 Minuten das Skript 
BPH.ots von Gisbert Friege gefunden

wurde, das im 
<b>libreoffice-dmaths</b>-Paket&nbsp;<a href="http://www.dmaths.org/documentation/doku.php?id=presentation:de">[14]</a> 
enthalten ist.
Das Skript ist intuitiv und funktional. Eine 
Darstellung von Ausreißern oder von horizontalen Boxplots ist nicht möglich. 
Da das Skript beim Versuch, die Schriftgröße im Boxplot zu ändern, 
abstürzte, wurde der Boxplot in Inkscape nachbearbeitet. Gnumeric und Pyspread 
bieten Boxplots
ohne zusätzliche Skripte an.

<div class="p"><!----></div>
In Gnumeric wird 
jeder Boxplot mit einer anderen Farbe versehen.
Da Diagramme mit mehreren 
Boxplots
in der Regel einheitlich eingefärbt werden, sind
viele Klicks 
erforderlich, um die Farben jedes Boxplots zu ändern. In Pyspread gibt es 
keine Option, die X-Achsen-Beschriftungen zu verändern. Dies wurde mit 
Inkscape nachträglich korrigiert.

<div class="p"><!----></div>
Die mit LibreOffice erzeugte SVG-Datei musste, um sie in Firefox öffnen zu 
können, vor der
Nachbearbeitung in Inkscape mit LibreOffice Draw ins A2-Format 
übertragen werden. In Gnumeric und Pyspread funktionierte der Import in 
Inkscape und auch in Firefox einwandfrei.

<div class="p"><!----></div>
Während der durch das LibreOffice-Skript erzeugte Boxplot unfertig wirkt, 
sind die von Gnumeric und Pyspread generierten Boxplots vollständig, wobei 
in Pyspread die Achsenbeschriftung zu klein ist.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/tabellenkalkulation_3_boxplots.png" alt="tabellenkalkulation_3_boxplots.png" style="max-width:100%" /><br /><em>Boxplots im Vergleich. In Calligra Sheets wurde der Test abgebrochen.</em><br />

<div class="p"><!----></div>

<h2>Zusammenfassung</h2>


Die 
unten

stehende Tabelle gibt einen Überblick über die drei Tests. Mit 
LibreOffice wurde fast die doppelte Zeit wie mit Gnumeric oder Pyspread 
benötigt. Die Gründe hierfür waren neben der Recherche nach dem Boxplot-Skript 
die aufwendigen Diagrammanpassungen, die viele Klicks benötigten. Gnumeric 
erfüllt seinen Anspruch, wenige Ressourcen zu verbrauchen und machte im
Test 
den stabilsten Eindruck. Calligra Sheets war am langsamsten und schien mit 
den Datenmengen der Zeitreihe überfordert. Pyspread benötigt mehr als die 
doppelte Rechenleistung von LibreOffice oder Gnumeric. Die geringe 
Arbeitszeit resultiert aus der geringeren Anzahl an benötigten Mausklicks. 
Sie erfordert jedoch gute Python-Kenntnisse und ist teilweise der Erfahrung 
des Testers mit dem Programm geschuldet.
Zusätzlich ist zu erwähnen, dass Pyspread sehr kleine native Dateien erzeugt.

<div class="p"><!----></div>
    
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="5" align="center"><b>Kumulierte Kenngrößen und Bewertungen der drei Tests.</b></td></tr>
<tr><td align="left"><b>Kenngröße</b>   </td><td align="left"><b>LibreOffice</b> </td><td align="left"><b>Gnumeric</b> </td><td align="left"><b>Calligra Sheets</b> </td><td align="left"><b>Pyspread</b> </td></tr>
<tr><td align="left">Arbeitszeit </td><td align="left">128 min </td><td align="left">68 min </td><td align="left">81 min* </td><td align="left">65 min  </td></tr>
<tr><td align="left">CPU-Zeit </td><td align="left">154 s* </td><td align="left">120 s </td><td align="left">1664 s* </td><td align="left">341 s  </td></tr>
<tr><td align="left">Max. RAM </td><td align="left">261 MB </td><td align="left">122 MB </td><td align="left">347 MB* </td><td align="left">199 MB  </td></tr>
<tr><td align="left">Nat. Dateigröße </td><td align="left">919,5 kiB </td><td align="left">434,3 KiB </td><td align="left">66,9 KiB** </td><td align="left">86,5 KiB  </td></tr>
<tr><td align="left">SVG-Dateigröße </td><td align="left">127,7 KiB </td><td align="left">305,5 KiB </td><td align="left">166,9 KiB** </td><td align="left">295,2 KiB  </td></tr>
<tr><td align="left">Dateneingabe </td><td align="left">++ </td><td align="left">+ </td><td align="left">+ </td><td align="left">+  </td></tr>
<tr><td align="left">CSV-Import </td><td align="left">+ </td><td align="left">+ </td><td align="left">+ </td><td align="left">+  </td></tr>
<tr><td align="left">Datenauswertung </td><td align="left">+ </td><td align="left">+ </td><td align="left">--** </td><td align="left">+  </td></tr>
<tr><td align="left">Tortendiagramm </td><td align="left">+ </td><td align="left">+ </td><td align="left">o </td><td align="left">o  </td></tr>
<tr><td align="left">Liniendiagramm </td><td align="left">+ </td><td align="left">+ </td><td align="left">-- </td><td align="left">+  </td></tr>
<tr><td align="left">Boxplot </td><td align="left">- </td><td align="left">+ </td><td align="left">--** </td><td align="left">o  </td></tr>
<tr><td align="left">SVG-kompatibel </td><td align="left">o </td><td align="left">+ </td><td align="left">- </td><td align="left">+  </td></tr>
</table>


<div class="p"><!----></div>
<b>Erklärung der Tabelle:</b> * = Wert durch Absturz unterschätzt, ** = Boxplots nicht erstellt, ++ = hervorragend, + = funktioniert, o = erfordert Nacharbeit, - = unbefriedigend, -- = nicht nutzbar

<div class="p"><!----></div>

<h2>Fazit</h2>


LibreOffice, Gnumeric und Pyspread liefern für alle Testaufgaben Diagramme, 
die entweder sofort
oder nach Nacharbeit in Inkscape für Präsentationen 
genutzt werden können.

<div class="p"><!----></div>
Im Test machte Gnumeric die beste Figur. Zunächst ist Gnumeric schnell und 
robust. Es meistert alle getesteten Aufgaben problemfrei und bietet eine 
Vielzahl an Optionen in gut strukturierten Dialogen an. Der Ansatz, 
Diagramm-Parameter über einen Baum zu strukturieren, bewährte sich im Test 
insbesondere dadurch, dass sich beim Klick auf das Diagramm der Baum an der 
richtigen Stelle öffnet. Die durch Gnumeric erzeugten SVG-Dateien lassen 
sich in Inkscape und Firefox problemlos öffnen. 

<div class="p"><!----></div>
LibreOffice brilliert bei der Dateneingabe und liefert gut aussehende 
Standard-Diagramme. Die exportierten SVG-Dateien können jedoch nur über 
Umwege und unter Verlust der Schriftarten in Firefox geöffnet werden. 
Weiterhin erfordert LibreOffice durch den verschachtelten Aufbau der 
Diagrammebenen, an denen die Optionen hängen, mehr Arbeitszeit und wirkt 
zumindest in Debian durch die große Auswahl an Makros unübersichtlich.

<div class="p"><!----></div>
Pyspread erlaubt es, schnell Diagramme zu erzeugen und in kompatible 
SVG-Dateien zu exportieren. Pyspread ist jedoch nicht für jeden Nutzer 
geeignet. Um die Arbeitszeit mit Gnumeric zu unterbieten, sind gute 
Python-Kenntnisse erforderlich. Pyspread arbeitete zwar im gesamten Test 
ohne Absturz. Man darf hierfür jedoch z.&nbsp;B. die Tabelle nicht zu groß wählen, 
da Pyspread Eingaben, die zu sehr langen Berechnungen führen, nicht abfängt. 
Pyspread enthält zudem zu wenige Diagrammoptionen (Schriftartenwahl fehlt) 
im Diagramm-Dialog. Bis die Optionen ergänzt sind, bietet Pyspread die im 
Test nicht genutzte Möglichkeit, Diagramme mittels Makros zu verfeinern. 

<div class="p"><!----></div>
Calligra Sheets wirkt insgesamt instabil und ist nicht auf die getesteten 
Datenmengen ausgelegt. Eine Web-Recherche ergab, dass einige der 
geschilderten Probleme aus der im genutzten Debian-Paket verlinkten 
Qt-Version resultieren könnten. In anderen Linux-Distributionen könnte sich 
daher das Testergebnis verbessern. Die Nutzerführung in Reitern wirkt beim 
Arbeiten eher hinderlich, da zeitnah genutzte Optionen in unterschiedlichen 
Reitern zu finden sind. Daher kann für die getestete Aufgabenstellung die 
vorliegende Version von Calligra Sheets nicht empfohlen werden.

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="http://de.libreoffice.org/"><tt class="big">http://de.libreoffice.org/</tt></a><br />
[2] <a href="http://www.openoffice.org/de/"><tt class="big">http://www.openoffice.org/de/</tt></a><br />
[3] <a href="https://projects.gnome.org/gnumeric/"><tt class="big">https://projects.gnome.org/gnumeric/</tt></a><br />
[4] <a href="https://www.gnome.org/"><tt class="big">https://www.gnome.org/</tt></a><br />
[5] <a href="http://www.calligra.org/"><tt class="big">http://www.calligra.org/</tt></a><br />
[6] <a href="http://manns.github.io/pyspread/"><tt class="big">http://manns.github.io/pyspread/</tt></a><br />
[7] <a href="http://siag.nu/siag/"><tt class="big">http://siag.nu/siag/</tt></a><br />
[8] <a href="http://matplotlib.org/"><tt class="big">http://matplotlib.org/</tt></a><br />
[9] <a href="http://inkscape.org/?lang=de"><tt class="big">http://inkscape.org/?lang=de</tt></a><br />
[10] <a href="http://code.google.com/p/jessyink/"><tt class="big">http://code.google.com/p/jessyink/</tt></a><br />
[11] <a href="http://sozi.baierouge.fr/"><tt class="big">http://sozi.baierouge.fr/</tt></a><br />
[12] <a href="https://de.wikipedia.org/wiki/SVG"><tt class="big">https://de.wikipedia.org/wiki/SVG</tt></a><br />
[13] <a href="http://de.wikipedia.org/wiki/Boxplot"><tt class="big">http://de.wikipedia.org/wiki/Boxplot</tt></a><br />
[14] <a href="http://www.dmaths.org/documentation/doku.php?id=presentation:de"><tt class="big">http://www.dmaths.org/documentation/doku.php?id=presentation:de</tt></a><br />
    

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="1" align="center"><b>Autoreninformation</b></td></tr>
<tr><td align="left"><b>Martin Manns</b>
ist der Autor der Tabellenkalkulation Pyspread, die im Artikel bewertet wird.
    </td></tr></table>
<br />

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=Tabellenkalkulationen im Vergleich#comment-form"><i>Diesen Artikel kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
    






<h1><font color="#595959"><a id="fm_13_12_dante_herbst2013" name="fm_13_12_dante_herbst2013">Rückblick: DANTE-Herbsttagung in Köln 2013</a></font></h1>von Dominik Wagenführ

<div class="p"><!----></div>
    <b>D</b><b>ie Herbsttagung der Deutschsprachigen Anwendervereinigung TeX e.V. 
(DANTE&nbsp;<a href="http://www.dante.de/">[1]</a>) fand dieses Jahr in Köln statt. Von 
Allerheiligen, den 1. November, bis Sonntag, den 3. November, trafen sich 
TeX-Interessierte aus ganz Deutschland und auch über deutsche Grenzen 
hinweg, um einen Tag lang fachspezifische Themen zu verfolgen und ein 
unterhaltsames Rahmenprogramm zu genießen.</b>

<div class="p"><!----></div>

<h2>Vorabendtreff am Freitag</h2>


Auch wenn die eigentliche Tagung und die Vorträge erst für Samstag angesetzt 
waren, trafen sich schon zahlreiche Dante-Mitglieder zum Vorabendtreff am 
Freitag in „Hellers Brauhaus“. Durch die 
sehr gute Vorauswahl der Hotels konnten die meisten sehr gemütlich zu Fuß 
den Weg dorthin finden.

<div class="p"><!----></div>
Wer nebenbei noch shoppen wollte und sich wunderte, dass die Geschäfte 
geschlossen waren, kam wohl eher aus einem evangelischen Landesteil 
Deutschlands, denn in Köln war dank Allerheiligen ein Feiertag. Wer ganz 
clever war, konnte mit dem Reformationstag am Tag davor und Allerheiligen 
gleich zwei Feiertage mitnehmen.

<div class="p"><!----></div>
Der Stimmung schadete der Feiertag natürlich nicht. Man traf sehr viele 
altbekannte Gesichter im Brauhaus und konnte sich so von der letzten Tagung 
in Gießen&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2013-04">[2]</a> synchronisieren. 
Zusätzlich konnte man lernen, dass man den Bierdeckel auf das leere 
Kölsch-Glas legen sollte, wenn man kein Interesse an Nachschub hat. Dieser 
wird nämlich ungefragt hingestellt, wenn das Glas leer ist. 

<div class="p"><!----></div>

<h2>DANTE-Tagung und Mitgliederversammlung am Samstag</h2>


Vom Hotel zum Tagungsgebäude der Universität Köln waren es nur 700 
Meter. Dementsprechend konnte man auch gemütlich ausschlafen, um pünktlich 9 
Uhr vor Ort zu sein. Das Institut für 
Kristallographie&nbsp;<a href="http://www.kristallographie.uni-koeln.de/">[3]</a> stellte unter 
Prof. Dr. Manfred Mühlberg, der leider nicht anwesend sein konnte, einen 
Raum zur Verfügung, in dem die circa 40 Teilnehmer den Vorträgen lauschen 
konnten.

<div class="p"><!----></div>

<h3>49. Mitgliederversammlung</h3>


Um 9 Uhr eröffnete der Vorstandsvorsitzende Martin Sievers die 
Mitgliederversammlung des DANTE 
e.V&nbsp;<a href="http://www.dante.de/events/Herbst2013.html">[4]</a>. Es wurde wieder viel über 
vergangene Tagungen berichtet. Vor allem die Eindrücke der TUG 2013, die 
dieses Jahr in Tokyo stattfand, wurden sehr interessant und unterhaltsam von 
Volker RW Schaa übermittelt.

<div class="p"><!----></div>
Wie bereits bekannt war und noch einmal bestätigt wurde, findet die 
DANTE-Frühjahrstagung 2014 in Heidelberg statt. Zum 25. Jubiläum der 
Vereinsgründung bietet sich der Gründungsort Heidelberg an, um vom 11. 
bis 14. April ein großes Geburtstagsprogramm auf die Beine zu stellen. 
Hierfür werden bereits jetzt Vorträge gesucht, die dann auch in einem 
speziellen Tagungsband erscheinen sollen. Ein gesonderter Aufruf für den 
„Call for Papers“ soll noch folgen.

<div class="p"><!----></div>
Die Herbsttagung 2014 soll dann gleich „um die Ecke“ von Heidelberg in 
Karlsruhe stattfinden und die Frühjahrstagung 2015 dann an der wunderschönen 
Ostseeküste in Stralsund. Die Verlagerung des Veranstaltungsortes soll es 
allen DANTE-Mitgliedern und TeX-Interessierten ermöglichen, einmal an solch 
einer Konferenz teilzunehmen.

<div class="p"><!----></div>
Neben den aktuellen unterstützten Projekten, die sich zumeist mit 
Schiftarten beschäftigen, war auch die 
SEPA-Umstellung&nbsp;<a href="https://de.wikipedia.org/wiki/Einheitlicher_Euro-Zahlungsverkehrsraum">[5]</a>
ein Thema, ebenso wie die Auslieferung der TeX-Collection als Doppel-DVD 
oder auf USB-Stick sowie ein Corporate Design für den Verein.

<div class="p"><!----></div>

<h3>Von und nach LaTeX mit Pandoc</h3>


Im ersten Vortrag stellte Blandyna Bogdol den Universalkonverter 
Pandoc&nbsp;<a href="http://johnmacfarlane.net/pandoc">[6]</a> vor, mit dem man Dateien und 
Dokumente zwischen vielen verschiedenen Formaten wandeln kann (siehe auch 
„PDF-Dokumente schreiben mit Pandoc und Markdown“, <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> 
06/2013&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2013-06">[7]</a>). So gibt es auch 
Wandlungsroutinen für LaTeX, ODT und XML. Sinnvoll ist das Programm vor 
allem dann, wenn man von einem Ausgangsformat verschiedene Ausgaben benötigt.

<div class="p"><!----></div>
Neben der Erklärung der Installation und Standardverwendung zeigte die 
Referentin am Beispiel von DocBook&nbsp;<a href="http://www.docbook.org/">[8]</a> (siehe auch 
„Einführung in Docbook“ <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> 
03/2013&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2013-03">[9]</a> auch, wie sie den Text 
nach LaTeX umwandelt. Pandoc ist dabei sehr hilfreich und mächtig, ist aber eher 
für einfachere und nicht allzu komplexe Dokumente geeignet. Die Textmenge ist zwar egal, aber zu 
komplexe LaTeX-Konstrukte können Probleme bereiten. Durch verschiedene 
Vorlagen kann man
die Wandlungsroutine entsprechend beeinflussen. Die 
Anpassung der Vorlagen ist aber noch recht
komplex und umständlich, sodass 
Pandoc nicht für jeden geeignet ist.

<div class="p"><!----></div>
Als Alternative zur Wandlung von PDF nach HTML wurde aus dem Zuschauerraum 
noch pdf2htmlEX&nbsp;<a href="http://coolwanglu.github.io/pdf2htmlEX/">[10]</a> erwähnt, 
welches PDF-Dokumente dank 
CSS&nbsp;<a href="https://de.wikipedia.org/wiki/Cascading_Style_Sheets">[11]</a> eins zu eins in 
HTML darstellen kann. 

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/dante2013_bogdol.jpg" alt="dante2013_bogdol.jpg" style="max-width:100%" /><br /><em>Blandyna Bogdol erklärt den Einsatz von Pandoc.</em><br />

<div class="p"><!----></div>

<h3>PDF-Formulare ausfüllen mit iText &amp; Co.</h3>


Marcus Bitzl von der TU München zeigte anhand eines Anmeldeformular, wie man mithilfe
der Open-Source-Bibliothek iText&nbsp;<a href="http://itextpdf.com/">[12]</a> PDF-Formulare 
ausfüllen kann. Die erste Idee, dass die Daten eingesammelt und mit LaTeX in 
ein fertiges PDF-Dokument gewandelt werden, wurde aufgrund von Zeitproblemen 
verworfen. Stattdessen wurde mittels des Paketes <b><tt class="big">hyperref</tt></b> in LaTeX ein 
PDF-Formular erstellt. Dieses Formular wird dann von der Webanwendung, die 
zum Beispiel in Java geschrieben sein kann, mittels iText ausgefüllt und zum 
Download bereitgestellt.

<div class="p"><!----></div>
Als Alternative zu iText wurde noch 
pdftk&nbsp;<a href="http://www.pdflabs.com/tools/pdftk-the-pdf-toolkit/">[13]</a> genannt 
(siehe auch „Kurztipp: Bastelstunde mit Pdftk“, <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> 
03/2009&nbsp;<a href="http://www.freiesmagazin.de/freiesMagazin-2009-03">[14]</a>). Mithilfe einer 
generierten fdf-Datei kann man damit ebenso ein PDF-Formular automatisiert 
ausfüllen und anbieten.

<div class="p"><!----></div>
Von 12 bis 14 Uhr war dann Mittagspause, in welcher sich kleine Grüppchen 
bildeten, die in der Zürpicher Straße eines der zahlreichen Restaurants und 
Cafés aufsuchten. 

<div class="p"><!----></div>

<h3>ConTeXt Quickie: Tabellen</h3>


Den Nachmittag leitete Leo Arnold mit russischen Tabellen ein. 
Glücklicherweise war der Inhalt der Tabellen nicht von Relevanz, um die 
Beispiele zu verstehen.

<div class="p"><!----></div>
Nach einer kurzen Einführung in ConTeXt&nbsp;<a href="http://wiki.contextgarden.net/">[15]</a> 
stellte er die Tabellenumgebungen <b><tt class="big">Tabulate</tt></b>, <b><tt class="big">bTABLE</tt></b> und <b><tt class="big">tables</tt></b> vor. 
Alle Umgebungen waren mehr oder weniger vergleichbar mit ihren 
LaTeX-Pendants, konnten an anderer Stelle wiederum etwas mehr.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/dante2013_arnold.jpg" alt="dante2013_arnold.jpg" style="max-width:100%" /><br /><em>Leo Arnold zeigt Tabellen in ConTeXt.</em><br />

<div class="p"><!----></div>

<h3>CTAN mit Geschichte</h3>


Unter dem Titel „CTAN mit Geschichte“ hätte man eine historische 
Ausarbeitung von CTAN (Comprehensive TeX Archive 
Network&nbsp;<a href="http://www.ctan.org/">[16]</a>) erwarten können, die Patrick Gundlach aber nicht 
gab. Er erklärte zwar kurz die Bedeutung und den Inhalt der Plattform, 
zeigte in seinem Projekt dann aber ein CTAN-Archiv mit Versionierung.

<div class="p"><!----></div>
Der Hintergrund des Vortrags war die Problemstellung, dass man für einige TeX-Projekte ganz 
oft bestimmte Pakete in speziellen Versionen

benötigt. Wenn diese nicht 
zufällig aufgehoben wurden oder auf einer der TeX-Collection-DVDs vorliegen, 
hat man gegebenenfalls mit der Übersetzung seines Dokuments ein Problem. 
Unter <a href="http://ctanmirror.speedata.de/">ctanmirror.speedata.de</a> stellte 
Patrick Gundlach daher ein Archiv zur Verfügung, über welches man zu jedem 
Datum die richtige Paketversion erhalten kann.


<div class="p"><!----></div>
Ein ähnliches Projekt gab es schon von Martin Scharrer, der unter 
<a href="http://ctanhg.scharrer-online.de/">ctanhg.scharrer-online.de</a> CTAN
mit
Mercurial verbandelte.

<div class="p"><!----></div>

<h3>Eine historisch-kritische Betrachtung des Quelltextes von TeX</h3>


Einen von den restlichen Themen abweichenden Vortrag präsentierte Sven Oos 
von der Universität Trier. Mittels spezieller Textanalyse-Methoden, die auch 
in den Literaturwissenschaften herangezogen werden, untersuchte er in seiner 
Diplomarbeit den Quelltext von TeX.

<div class="p"><!----></div>
Der von Donald Knuth entwickelte Code hat die Besonderheit, dass nur Knuth 
selbst daran arbeitete. So konnte man mithilfe von Changelogs und Knuths 
Entwicklertagebuch die Evolution des Quellcodes von den TeX-Anfängen 1977, als noch in SAIL 
programmiert wurde, bis zu TeX82, der ersten in WEB geschriebenen Version, 
grafisch darstellen.

<div class="p"><!----></div>
Sehr interessant an dem Vortrag waren die Publikumsbeiträge von 
„Zeitzeugen“, das heißt von DANTE-Mitgliedern, die bereits in den ersten Jahren 
der TeX-Entwicklung dabei waren.

<div class="p"><!----></div>

<h3>Wortlisten: Voraussetzung für gute Trennmuster</h3>


Tobias Wendorff von der TU Dortmund wandelte dann auch etwas abseits der 
normalen TeX-Themen und stellte seine Arbeit und die Probleme in der 
Trennmustermannschaft&nbsp;<a href="http://projekte.dante.de/Trennmuster">[17]</a> unter Trainer 
Herbert Voß vor. Die Gruppe kümmert sich darum, dass TeX im Falle eines 
Falles Wörter korrekt trennt und nicht unsinnige Trennungen wie 
„bein-haltet“ statt „be-inhaltet“ benutzt.

<div class="p"><!----></div>
Seine Tätigkeit in der Gruppe nahm er hauptsächlich auf, weil er sich für 
seine Arbeit als Geographiestudent über die (verkürzte) Darstellung von 
Straßennamen auf Karten Gedanken machte. Hier musste er einerseits einen 
Verkürzungsalgorithmus erfinden und zum anderen auch einen guten 
Trennalgorithmus, um überlange Namen darstellen zu können.

<div class="p"><!----></div>
Da sehr wenig Rückfluss aus der TeX-Community selbst zu den Trennlisten 
kommt, wird überlegt,

ob man das Problem der Mitarbeit lösen kann, indem man 
diese einfacher und offener macht. Eine zweite Idee ist es, mit anderen 
Projekten wie „hunspell“ zusammenzuarbeiten, die eigene Trennlisten pflegen.

<div class="p"><!----></div>

<h3>TeXStudio Live</h3>


Im letzten, sehr praxisbezogenen Vortrag zeigte Tim Hoffmann, einer der 
Entwickler von TeXStudio&nbsp;<a href="http://texstudio.sourceforge.net/">[18]</a>, den Editor 
in einer Live-Demonstration. Der Grund für die Entwicklung war der hemmende 
Arbeitsfluss in LaTeX zwischen Schreiben des Textes, Übersetzen auf der 
Konsole und Anschauen in einem PDF-Betrachter.

<div class="p"><!----></div>
TeXStudio fasst diese drei Eigenschaften zusammen und bietet noch zahlreiche 
andere Funktionen. Am beeindruckendsten war sicherlich die Live-Vorschau von 
geschriebenen Formeln oder auch von Bildern, die ohne separate Übersetzung 
des Dokuments eingeblendet wurden. Zusätzlich zeigt der Editor sofort 
eventuelle Fehler wie unbekannte Befehle oder falsch geschriebene Pakete an. 
Ebenso gibt es eine Anbindung an diverse Literaturverwaltungen.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/dante2013_sievers.jpg" alt="dante2013_sievers.jpg" style="max-width:100%" /><br /><em>DANTE-Vorstandsvorsitzender Martin Sievers beendet den Tag mit einem Lachen.</em><br />

<div class="p"><!----></div>

<h3>Abendveranstaltung</h3>


Mit etwas Überzug schloss Martin Sievers die DANTE-Tagung um 18 Uhr. Die 
meisten Teilnehmer machten sich dann auch sogleich auf den Weg zum 
Abendtreff im „Gaffel am Dom“, in dem sich ein 
Großteil gegen 19 Uhr einfinden wollte. Auch wenn die Aufmachung der 
Lokalität sehr kölsch war, kam das den Tischgesprächen nicht sehr zu Gute. 
Nach einigen Bieren und deftigem Essen wie Haxe und Spanferkel, löste sich 
die Gruppe daher aus akustischen Gründen relativ früh gegen 21 Uhr schon auf.

<div class="p"><!----></div>
Die „Jungspunde“ der Tagung störte das natürlich weniger – die suchten sich 
ein neues Lokal. So genoss eine kleine Gruppe noch gemeinsam bis

23 Uhr auf 
dem beheizten Vorplatz eines Lokals einige Cocktails, Kölsch und Tee.

<div class="p"><!----></div>

<h2>Touristisches Programm am Sonntag</h2>


Am Sonntag fand unter der Leitung von Dorothea Wand eine Stadtführung 
durch Köln statt. Alle Teilnehmer schafften es (fast) pünktlich bis 10 Uhr 
zum Kölner Dom und schauten sich neben der historischen Stadtmauer 
Bauwerke mit Einflüssen aus der Romanik, Gotik und dem Barock an.

<div class="p"><!----></div>
Leider war es stellenweise etwas windig und kalt
und zwei Straßenmusikanten gaben ihr Bestes, sich gegenseitig zu übertönen, 
was beim akustischen Verständnis der touristischen Führerin nicht gerade 
half. Dennoch hat die Stadtführung Spaß gemacht und viel Wissenswertes über 
Köln bei allen Beteiligten hinterlassen.

<div class="p"><!----></div>
Gegen 12 Uhr löste sich die Gruppe dann auf. Einige Teilnehmer mussten ihre 
Züge erreichen, andere suchten sich vor der Heimfahrt noch etwas Leckeres zu 
essen und eine dritte Gruppe genossen noch etwas die verschiedenen 
touristischen Angebote in Köln.

<div class="p"><!----></div>
<img src="freiesMagazin-2013-12-bilder-Dateien/dante2013_dom.jpg" alt="dante2013_dom.jpg" style="max-width:100%" /><br /><em>Der Kölner Dom.</em><br />

<div class="p"><!----></div>

<h2>Abschließende Bemerkungen</h2>


Das Vortragsprogramm war auch in diesem 
Jahr&nbsp;<a href="http://www.dante.de/events/Herbst2013/Programm.html">[19]</a> wieder breit 
gestreut, sodass für jeden etwas Interessantes dabei war. Die behandelten 
Lösungen bezogen sich aber sehr oft auf ein so spezielles Problem, dass nur 
in wenigen Fällen jemand anderes direkt etwas davon mitnehmen konnte.

<div class="p"><!----></div>
Aber das ist nicht weiter schlimm! Wie auch bei anderen Veranstaltungen, bei 
der sich eine Community trifft, geht es irgendwann einmal nicht mehr um die 
Vorträge oder Mitgliederversammlungen. Viel wichtiger sind die Menschen und 
die Pflege von Beziehungen. Die DANTE-Tagung bietet die Möglichkeit, dass 
man die Gesichter hinter Beiträgen aus der TeXnischen 
Komödie&nbsp;<a href="http://www.dante.de/DTK.html">[20]</a> oder den Helfern auf der Mailingliste 
und TeX Stack Exchange&nbsp;<a href="http://tex.stackexchange.com/">[21]</a> kennenlernt. Jeder 
ist willkommen und wird normalerweise auch recht schnell in die Gruppe 
integriert. Oft schließen sich auch Freundschaften, die über die Tagung 
hinaus erhalten bleiben – schließlich haben die meisten von uns auch noch 
ein Leben neben TeX.

<div class="p"><!----></div>
Insofern war es eine sehr gelungene Veranstaltung, die Dank Uwe Ziegenhagen 
ohne Schwierigkeiten über die Bühne ging. Interessante Vorträge und wie 
geschrieben vor allem sehr nette Menschen machen die DANTE-Tagung zu einem 
Pflichtprogramm, das man als Community-Mitglied beziehungsweise als 
TeX-Nutzer mitnehmen sollte. Die Freude auf Heidelberg 2014 ist aus dem 
Grund umso größer.

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="http://www.dante.de/"><tt class="big">http://www.dante.de/</tt></a><br />
[2] <a href="http://www.freiesmagazin.de/freiesMagazin-2013-04"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2013-04</tt></a><br />
[3] <a href="http://www.kristallographie.uni-koeln.de/"><tt class="big">http://www.kristallographie.uni-koeln.de/</tt></a><br />
[4] <a href="http://www.dante.de/events/Herbst2013.html"><tt class="big">http://www.dante.de/events/Herbst2013.html</tt></a><br />
[5] <a href="https://de.wikipedia.org/wiki/Einheitlicher_Euro-Zahlungsverkehrsraum"><tt class="big">https://de.wikipedia.org/wiki/Einheitlicher_Euro-Zahlungsverkehrsraum</tt></a><br />
[6] <a href="http://johnmacfarlane.net/pandoc"><tt class="big">http://johnmacfarlane.net/pandoc</tt></a><br />
[7] <a href="http://www.freiesmagazin.de/freiesMagazin-2013-06"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2013-06</tt></a><br />
[8] <a href="http://www.docbook.org/"><tt class="big">http://www.docbook.org/</tt></a><br />
[9] <a href="http://www.freiesmagazin.de/freiesMagazin-2013-03"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2013-03</tt></a><br />
[10] <a href="http://coolwanglu.github.io/pdf2htmlEX/"><tt class="big">http://coolwanglu.github.io/pdf2htmlEX/</tt></a><br />
[11] <a href="https://de.wikipedia.org/wiki/Cascading_Style_Sheets"><tt class="big">https://de.wikipedia.org/wiki/Cascading_Style_Sheets</tt></a><br />
[12] <a href="http://itextpdf.com/"><tt class="big">http://itextpdf.com/</tt></a><br />
[13] <a href="http://www.pdflabs.com/tools/pdftk-the-pdf-toolkit/"><tt class="big">http://www.pdflabs.com/tools/pdftk-the-pdf-toolkit/</tt></a><br />
[14] <a href="http://www.freiesmagazin.de/freiesMagazin-2009-03"><tt class="big">http://www.freiesmagazin.de/freiesMagazin-2009-03</tt></a><br />
[15] <a href="http://wiki.contextgarden.net/"><tt class="big">http://wiki.contextgarden.net/</tt></a><br />
[16] <a href="http://www.ctan.org/"><tt class="big">http://www.ctan.org/</tt></a><br />
[17] <a href="http://projekte.dante.de/Trennmuster"><tt class="big">http://projekte.dante.de/Trennmuster</tt></a><br />
[18] <a href="http://texstudio.sourceforge.net/"><tt class="big">http://texstudio.sourceforge.net/</tt></a><br />
[19] <a href="http://www.dante.de/events/Herbst2013/Programm.html"><tt class="big">http://www.dante.de/events/Herbst2013/Programm.html</tt></a><br />
[20] <a href="http://www.dante.de/DTK.html"><tt class="big">http://www.dante.de/DTK.html</tt></a><br />
[21] <a href="http://tex.stackexchange.com/"><tt class="big">http://tex.stackexchange.com/</tt></a><br />
    

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="1" align="center"><b>Autoreninformation</b></td></tr>
<tr><td align="left"><b>Dominik Wagenführ</b>&nbsp;(<a href="http://www.deesaster.org/blog/">Webseite</a>)
ist seit einigen Jahren DANTE-Mitglied und nutzt LaTeX fast täglich für
seine Arbeit bei <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font>.
    </td></tr></table>
<br />

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=DANTE-Herbsttagung 2013#comment-form"><i>Diesen Artikel kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
<h1><font color="#595959"><a id="fm_13_12_rezension_technisches_schreiben" name="fm_13_12_rezension_technisches_schreiben">Rezension: Technisches Schreiben</a></font></h1>von Dominik Wagenführ

<div class="p"><!----></div>
    <b>V</b><b>iele Menschen müssen heutzutage für ihre Arbeit oder ihr Hobby Dokumente 
schreiben. Bei der Arbeit im Software-Bereich betrifft das Designdokumente 
und Schnittstellenbeschreibungen (APIs), im Hardware-Bereich betrifft es 
eher Schaltbilder oder Pin-Belegungen. In beiden Fällen sind die Schreiber 
oft nicht extra dafür ausgebildet worden. Das Buch „Technisches Schreiben“ 
soll dabei helfen, bessere Dokumente zu verfassen.</b>

<div class="p"><!----></div>
<b>Redaktioneller Hinweis:</b> <i>Wir danken dem Carl Hanser Verlag für die Bereitstellung eines Rezensionsexemplares.</i>

<div class="p"><!----></div>

<h2>Für wen ist das Buch gedacht?</h2>


Wie in der Einleitung geschrieben gibt es sowohl bei der täglichen Arbeit 
als auch in freiwilligen Projekten viel zu dokumentieren. Kaum jemand hat 
die Kunst des Schreibens erlernt; die meisten tun sich mehr oder weniger schwer 
damit. Einige verzweifeln bereits an einer kurzen Zusammenfassung oder an 
einer einfachen Inhaltsbeschreibung zu einem Thema. Andere haben mit der 
Aneinanderreihung von Wörtern keine Probleme, verstricken sich dafür aber in 
Wiederholungen und verlieren der roten Faden sehr schnell.

<div class="p"><!----></div>
Das Buch „Technisches Schreiben“ von Christoph Prevezanos versucht dabei 
allen Menschen zu dieser breiten Fähigkeitenspanne zu helfen – und schafft dies 
mehr oder weniger gut. Wirft man einen Blick in das erste Kapitel, sieht 
man, dass sehr viel Wert auf die Einhaltung von Normen (sowohl DIN als auch 
ISO) gelegt wird. Die Zielgruppe, für die diese Normen eine Bedeutung haben 
ist aber, im Vergleich zu der gesamten schreibenden Zunft, eher klein. 
Manche Leser könnten sich davon sogar abgeschreckt fühlen.

<div class="p"><!----></div>
Ignoriert man die Norm-Hinweise aber einfach oder sieht sie nur als nettes 
Beiwerk an, gibt es zahlreiche Kapitel, die für jeden Dokumenten-Schreiber 
hilfreich sein können. Sei es zum Beispiel bei einem Artikel für ein Magazin (wie 
diesem hier), einer Anleitung in einem Wiki, einem Blogbeitrag oder bei 
einer API-Beschreibung für ein großes Software-Projekt – den einen oder 
anderen Tipp kann man immer mitnehmen.

<div class="p"><!----></div>
Die Zielgruppe streut sich daher sehr breit. Einige Kapitel betreffen  
nur eine eingeschränkte Zielgruppe, die an Universitäten oder Behörden 
beschäftigt ist. Andere Kapitel wiederum können für jeden hilfreiche 
Hinweise zum besseren Schreiben liefern.

<div class="p"><!----></div>

<h2>Was steht drin?</h2>


Nach der Einleitung weist der Autor zunächst in Kapitel 2 auf die 
verschiedenen Dokumentationswerkzeuge hin. Sehr schön ist, dass nicht nur – 
wie bei einigen anderen Büchern – der Quasi-Standard Microsoft Office 
vorgestellt wird, sondern auch freie Alternativen wie Libre Office oder 
OpenOffice. Selbst LaTeX findet Erwähnung, wird es doch sehr häufig an 
Universitäten in den naturwissenschaftlichen Fächern eingesetzt.

<div class="p"><!----></div>
Neben dem Standard-Schreibwerkzeug wird auf viele kleine technische Details 
eingegangen: Wie wichtig sind Format-Vorlagen (Antwort: Sehr wichtig!), 
welche Schriften sind passend und wie gestaltet man die einzelnen 
Seitenelemente. Leider wird hierbei sehr wenig auf Online-Medien 
eingegangen. So gibt es zahlreiche Formatierungshinweise für Kopf- und 
Fußzeilen, Seitenränder etc., die es in einem Wiki oder einem Blog in der 
Art nicht gibt. Hier hätte man sich vielleicht doch noch einen kleinen 
Exkurs in die digitale Welt erhofft, der auf die Eigenheiten beim 
Online-Schreiben eingeht.

<div class="p"><!----></div>
Das dritte Kapitel behandelt den wichtigen Punkt der Planung. Denn oft führt 
wildes Drauflosschreiben nicht zu einem gut strukturierten Text, um den es 
dann auch in Kapitel 4 geht. Aber auch hier werden mehr die kleineren 
technischen Details behandelt, die im wissenschaftlichen Bereich sicherlich eher 
gefragt sind als im normalen Berufsalltag oder für ein Hobby-Projekt.

<div class="p"><!----></div>
Am interessantesten und für eine sehr große Zielgruppe am geeignetsten sind 
die Kapitel 5 bis 7. Kapitel 5 befasst sich sehr ausführlich mit Zitaten. 
Nach den letztjährigen Problemen einiger Politiker, eine ordentlich zitierte 
Quelle anzugeben, sollte man das Thema nicht unterschätzen. Aber selbst für 
den normalen Alltag sind Zitate oder zumindest Quellnachweise nahezu 
unerlässlich. Dank dem neuen 
Leistungsschutzrecht&nbsp;<a href="https://de.wikipedia.org/wiki/Leistungsschutzrecht_f%C3%BCr_Presseverleger">[1]</a>
und zahlreichen Abmahnanwälten sollte man sich auch als Blogger 
über die aktuelle Rechtslage informieren. Und der neue Kollege wird es einem 
danken, wenn er das Dokument, auf das man verweist, auch wirklich sofort 
findet und nicht erst ewig suchen muss.

<div class="p"><!----></div>
Der kleine Abstecher in Sachen Interpunktion am Ende von Kapitel 5 ist 
ebenfalls sehr praktisch und lehrreich. Von „korrekten“ und "inkorrekten" 
Anführungszeichen bis hin zur richtigen Benutzung von Binde- und 
Gedankenstrichen – alles ist dabei.

<div class="p"><!----></div>
Kapitel 6 umfasst den mit am wichtigsten, aber auch schwierigsten Teil 
eines Dokuments, nämlich Sprache und Ausdruck. Beides ist etwas, was man nur 
mit viel Geduld, aber vor allem viel Praxis lernen kann. Konkret lernt man 
gutes Schreiben nicht durch das Lesen von Büchern. Neben den Grundlagen zur 
richtigen Wortwahl und gutem Satzbau wird auch auf die Ansprache der Leser 
und die Geschlechterfrage eingegangen. In beiden Punkten gibt es zahlreiche und 
verschiedene Meinungen, sodass man die des Autors teilen kann, aber nicht 
muss.

<div class="p"><!----></div>
Ebenfalls interessant ist das siebte Kapitel zu Fremd- und Modewörtern. 
Diese sollte man nur so einsetzen, wie es das Zielpublikum auch verarbeiten 
kann. So deuten viele Fachbegriffe vielleicht auch darauf hin, dass man die 
Materie verstanden hat, aber ob man sie ebenso einem Laien vermitteln kann, 
ist eine andere Frage. Anglizismen werden auch behandelt, ebenso wie 
„falsche Freunde“, d.&nbsp;h. englische Wörter, die ähnlich zu einem deutschen 
Wort klingen, aber etwas ganz anderes bedeuten (so wie „gift“ oder „handy”).

<div class="p"><!----></div>
Im vorletzten inhaltlichen Kapitel geht es um den Einsatz von Bildern und 
Tabellen. Hier wird auch erklärt, wie man fremde Bilder korrekt wiedergibt – 
etwas, was im Fazit noch eine Rolle spielen wird.

<div class="p"><!----></div>
Das vorletzte Kapitel behandelt dann noch Verzeichnisse jeglicher Art und 
den Abschluss bieten die etwas trockenen Normen.

<div class="p"><!----></div>

<h2>Ist das Buch zu empfehlen?</h2>


Die Frage nach einer Empfehlung ist schwer zu beantworten. Insgesamt lesen 
sich die ersten Kapitel etwas schwerer, da sie von der Thematik her auch 
etwas trockener sind. Wer beschäftigt sich schon gerne mit Anhängen, 
Fußnoten oder dem Inhaltsverzeichnis? Nutzt man diese nicht ganz korrekt, 
macht das in der Regel einen guten Text nicht wesentlich schlechter, auch 
wenn er formal nicht ganz korrekt ist.

<div class="p"><!----></div>
Das ist auch etwas, worauf Christoph Prevezanos sehr oft pocht: die 
Einhaltung von Formen und Normen. Offen gestanden benötigt man das außer in 
einigen akademischen Berufen und speziellen Tätigkeitsfeldern eher weniger. 
Wer Dokumente nur „nebenbei“ schreibt (sei es im Berufsalltag oder im 
Privatleben), den wird selten interessieren, welche Normen man für Ränder 
oder Kopf- und Fußzeile einhalten muss. Diese Abschnitte oder Kapitel habe 
ich daher auch sehr schnell überlesen.

<div class="p"><!----></div>
Anders ist es bei den inhaltlichen Themen. Wie baut sich ein Dokument, ein 
Kapitel, ein Absatz oder ein Satz auf? Welche Wortwahl ist geeignet und 
welche weniger? Und wie zitiert man richtig? Dies sind wichtige Hinweise, 
die man im Buch finden kann.

<div class="p"><!----></div>
Der größte Kritikpunkt geht an das Kapitel zu der Verwendung von Bildern. 
Der Autor hält sich hier nämlich nicht an seine eigenen Hinweise. So wird in 
Kapitel 8 auf Seite 157/158 extra auf Creative-Commons-Lizenzen hingewiesen. 
Auf Seite 10 wird aber ein Bild von Libre Office der Document Foundation 
benutzt, dessen 
Bilder&nbsp;<a href="https://www.libreoffice.org/features/writer/screenshot-of-writer-the-libreoffice-word-processor/">[2]</a>
aber in der Regel unter einer CC-Lizenz stehen, die nicht mit angegeben ist. 
Hier wird also vermutlich gegen eine Lizenz verstoßen.

<div class="p"><!----></div>
Daneben wird auf Seite 14 ein Bild von Adobe FrameMaker aus der Wikipedia 
verwendet&nbsp;<a href="http://en.wikipedia.org/wiki/File:FrameMaker_9.0_WindowsVista_screencap.png">[3]</a>.
Die Quelle wird korrekt angegeben, das Bild wird bei 
Wikipedia aber als „non free“ markiert. Im amerikanischen Raum fällt die 
Verwendung im privaten Bereich sicherlich unter Fair Use, in den deutschen 
Gerichtssälen gab es dazu noch kein Urteil, was die Verwendung von 
Screenshots mit rechtlicher geschützter Software angeht. Dennoch ist die 
Verwendung zumindest etwas wackelig.

<div class="p"><!----></div>
Etwas unverständlich ist auch der erste Satz in Kapitel 8.5: „<em>Es gibt keine 
Bildzitate!</em>“ Sicherlich darf man der Wikipedia nicht alles glauben, aber es 
gibt sogar einen extra Artikel zu dem 
Thema&nbsp;<a href="https://de.wikipedia.org/wiki/Bildzitat">[4]</a>. Selbst das Landgericht 
Berlin hat hierzu ein Urteil erlassen, was das Zitieren von Bildern angeht. 
Insofern sind die Aussagen des Autors nicht verständlich.

<div class="p"><!----></div>
Sieht man über diese kleineren Probleme hinweg, enthält das Buch vor allem 
in den mittleren drei Kapiteln einige interessante und hilfreiche 
Informationen. Ob es dabei hilft, ein besserer Autor zu werden, muss aber 
wahrscheinlich jeder für sich selbst beantworten.

<div class="p"><!----></div>
<b>Redaktioneller Hinweis:</b> <i></i> Da es schade wäre, wenn das Buch bei Dominik Wagenführ im Regal 
verstaubt, wird es verlost. Dazu ist folgende Frage zu beantworten:

<div class="p"><!----></div>
„<em>Wie nennt man die „Fußnoten“, die nicht am unteren Rand, sondern erst am Ende des Kapitels oder des Buches gesetzt werden?</em>“

<div class="p"><!----></div>


Die Antwort kann bis zum <b>8. Dezember 2013, 23:59 Uhr</b> über die 
Kommentarfunktion oder per E-Mail an redaktion@freiesmagazin.de geschickt 
werden. Die Kommentare werden bis zum Ende der Verlosung nicht 
freigeschaltet. Das Buch wird unter allen Einsendern, die die Frage richtig 
beantworten konnten, verlost.

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="2" align="center"><b>Buchinformationen</b></td></tr>
<tr><td><b>Titel</b> </td><td>Technisches Schreiben&nbsp;<a href="http://www.hanser-fachbuch.de/buch/Technisches+Schreiben/9783446437210">[5]</a> </td></tr>
<tr><td><b>Autor</b> </td><td>Christoph Prevezanos  </td></tr>
<tr><td><b>Verlag</b> </td><td>Carl Hanser Verlag, 2013 </td></tr>
<tr><td><b>Umfang</b> </td><td>231 Seiten </td></tr>
<tr><td><b>ISBN</b> </td><td>978-3-446-43721-0 </td></tr>
<tr><td><b>Preis</b> </td><td>19,99 Euro
        </td></tr></table>
<br />

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="https://de.wikipedia.org/wiki/Leistungsschutzrecht_f%C3%BCr_Presseverleger"><tt class="big">https://de.wikipedia.org/wiki/Leistungsschutzrecht_für_Presseverleger</tt></a><br />
[2] <a href="https://www.libreoffice.org/features/writer/screenshot-of-writer-the-libreoffice-word-processor/"><tt class="big">https://www.libreoffice.org/features/writer/screenshot-of-writer-the-libreoffice-word-processor/</tt></a><br />
[3] <a href="http://en.wikipedia.org/wiki/File:FrameMaker_9.0_WindowsVista_screencap.png"><tt class="big">http://en.wikipedia.org/wiki/File:FrameMaker_9.0_WindowsVista_screencap.png</tt></a><br />
[4] <a href="https://de.wikipedia.org/wiki/Bildzitat"><tt class="big">https://de.wikipedia.org/wiki/Bildzitat</tt></a><br />
[5] <a href="http://www.hanser-fachbuch.de/buch/Technisches+Schreiben/9783446437210"><tt class="big">http://www.hanser-fachbuch.de/buch/Technisches+Schreiben/9783446437210</tt></a><br />
    

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="1" align="center"><b>Autoreninformation</b></td></tr>
<tr><td align="left"><b>Dominik Wagenführ</b>&nbsp;(<a href="http://www.deesasterorg/blog/">Webseite</a>)
schreibt sowohl für <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> als auch für seinen Blog zahlreiche 
Artikel. Ebenso muss er beruflich fast täglich technische Dokumente 
verfassen und bewerten, weswegen er sich für dieses Buch interessierte.
    </td></tr></table>
<br />

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=Rezension: Technisches Schreiben#comment-form"><i>Diesen Artikel kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
<h1><font color="#595959"><a id="fm_13_12_rezension_linux_hochverfuegbarkeit" name="fm_13_12_rezension_linux_hochverfuegbarkeit">Rezension: Linux Hochverfügbarkeit – Einsatzszenarien und Praxislösungen</a></font></h1>von Michael Niedermair

<div class="p"><!----></div>
    <b>D</b><b>as Buch „Linux Hochverfügbarkeit“ zeigt an konkreten Praxisbeispielen und 
Einsatzszenarien, wie man mit Linux Hochverfügbarkeit (engl. High 
Availability, kurz HA) in seinem Netzwerk erreicht. Sei es vom kleinen 
System bis hin zum Datacenter. Gegenüber der ersten Auflage hat sich der 
Umfang fast verdoppelt.</b>

<div class="p"><!----></div>
Der Autor Oliver Liebel ist Diplom-Ingenieur im Bereich Elektrotechnik und 
LPI-zertifizierter Linux-Experte. Er ist als Administrator, Berater und 
IT-Trainer seit vielen Jahren tätig. Nachdem die erste Auflage schon sehr 
gute Kritiken erfahren hat, sind natürlich die Erwartungen an die zweite 
Auflage sehr hoch. Die nächsten Zeilen verraten, ob die zweite Auflage 
diesen Erwartungen gerecht wird.

<div class="p"><!----></div>
<b>Redaktioneller Hinweis:</b> <i>Wir danken Galileo Computing für die Bereitstellung eines Rezensionsexemplares.</i>

<div class="p"><!----></div>

<h2>Was steht drin?</h2>


Das Buch ist in vier Teile mit insgesamt 27 Kapiteln unterteilt. Es beginnt 
mit dem Vorwort und dem Einführungskapitel „Mission Critical – 
ausfallsichere Server“ und endet mit dem Anhang, welcher Beispieldateien, 
Paketlisten, Manpages und das Stichwortverzeichnis enthält. Der Schwerpunkt 
liegt dabei deutlich auf HA-Cluster/HA-Storage-Cluster.

<div class="p"><!----></div>
Das erste Kapitel (zwölf Seiten) stellt das Einführungskapitel dar und 
behandelt grundsätzliche Fragen zu Redundanz, Parallelität etc. 

<div class="p"><!----></div>
Teil I des Buches hat das Thema „Hochverfügbarkeit (HA) auf der 
Server-Ebene“ und umfasst fünf Kapitel. 

<div class="p"><!----></div>
Das zweite Kapitel (34 Seiten) zeigt, was man bei der lokalen Verfügbarkeit 
alles machen kann. Dies fängt bei der Überlegung an, welche Komponenten 
eines Servers redundant sein und welche Komponenten überwacht werden 
müssen, beispielsweise die Temperatur der CPU, die Lüfter etc. Danach geht 
es um die CPU, Control Groups und die Einstellungen der CPU, beispielsweise 
über cpuset. Abgeschlossen wird das Kapitel mit dem Thema Bonding, d.&nbsp;h. die 
Zusammenschaltung mehrerer Netzwerkkarten zu einem logischen Device. 

<div class="p"><!----></div>
In Kapitel 3 (16 Seiten) wird das lokale Storage behandelt. Es beginnt mit
den Architekturen wie SCSI/SAS bzw. SATA, gefolgt vom Einsatz von SSDs. 
Im Anschluss folgt die Disk-Überwachung mit SMART. 

<div class="p"><!----></div>
In Kapitel 4 (70 Seiten) werden Festplatten mittels RAID zu einem logischen 
Device verbunden, wobei die verschiedenen Level erläutert werden. Dabei werden auch 
die Unterschiede zwischen Hard- und Software-RAID dargestellt. Das praktische 
Anwenden der verschiedenen Tools für das Erstellen, Testen und so weiter rundet das 
Kapitel ab. 

<div class="p"><!----></div>
In Kapitel 5 (24 Seiten) wird beschrieben, wie man mit LVM (Logical Volume 
Manager) Storages virtualisiert, d.&nbsp;h. anlegt, Snapshots erzeugt und spiegelt.

<div class="p"><!----></div>
Kapitel 6 (25 Seiten) hat das Dateisystem BTRFS (B-tree FS; alternativ 
„Butter FS“ oder „Better FS“) und dessen Einsatz als Schwerpunkt.

<div class="p"><!----></div>
Teil II des Buches fasst die zehn Kapitel zu Hochverfügbarkeits-Cluster 
zusammen.

<div class="p"><!----></div>
Das Kapitel 7 (elf Seiten) stellt Vorüberlegungen zu HA-Clustern an, 
erläutert die verschiedenen Clustertypen etc.

<div class="p"><!----></div>
In Kapitel 8 (neun Seiten) werden dann die „Basics“ vermittelt, wie Ressourcen, 
Agenten, die technischen Schichten von Heartbeat bzw. Corosync und 
Pacemaker. Nachfolgend wird dann die Clustersoftware in Kapitel 9 (16 
Seiten) beschrieben.

<div class="p"><!----></div>
Kapitel 10 (neun Seiten) hat das Thema „NTPD – The Time Machine“ und 
beschäftigt sich mit der Zeitsynchronisation. Danach geht es in Kapitel 11 
(26 Seiten) um das Setup der Cluster-Kommunikation mit Corosync und Heartbeat.

<div class="p"><!----></div>
Das Kapitel 12 (34 Seiten) widmet sich Pacemaker, einem Programm für die 
Ressourcenverwaltung. Den Start macht der Cluster-Monitor, gefolgt von der 
crm-Shell, deren Konfiguration und Bedienung.

<div class="p"><!----></div>
Kapitel 13 (52 Seiten) steht unter dem Thema „Management von 
Cluster-Ressourcen“ und beschreibt beispielsweise die Verwaltung und Integration 
von Ressourcen, Migration, Rechteverwaltung usw.

<div class="p"><!----></div>
Cluster-Beispiele, wie sie in der Praxis vorkommen, werden in Kapitel 14 (69 
Seiten) behandelt. Danach folgen Kapitel 15 (neun Seiten) und Kapitel 16 (sechs 
Seiten), die kurz das Arbeiten mit Pacemaker 1.1.8, Corosync 2.x und pcs 
behandeln und wie man einen eigenen OCF-Resource-Agenten (Open Cluster 
Framework) erstellt.

<div class="p"><!----></div>
Teil III des Buches fast sieben Kapitel zu hochverfügbaren Storage-Clustern 
zusammen.

<div class="p"><!----></div>
In dem umfangreichsten Kapitel 17 (106 Seiten) geht es um ausfallsichere 
Shared-Nothing-Cluster mithilfe von DRBD (Distributed Replicated Blockdevice). Es 
beginnt mit den Vorbereitungen, der Diskussion „Wozu und wozu nicht?“, der 
Funktionalität und behandelt anschließend das Setup. Es werden viele Möglichkeiten 
besprochen, wie beispielsweise DRBD-Master/Slave im S3/LDAP-Cluster, 
Schnappschüsse, Clonen, Master/Slave mit NFS beziehungsweise OCFS2 und noch vieles mehr.

<div class="p"><!----></div>
Kapitel 18 (sieben Seiten) zeigt die Möglichkeiten der Beta/Pre-Release-Version 
DRBD 9.x.

<div class="p"><!----></div>
In Kapitel 19 (fünf Seiten) geht es um gerechte Verteilung mit GlusterFS und 
Ceph, wobei hier nur sehr kurz die beiden Varianten überschaubar dargestellt 
werden. In Kapitel 20 (67 Seiten)  geht es dann in der Tiefe um das 
Dateisystem Ceph, in Kapitel 21 (zwölf Seiten) um das Dateisystem GlusterFS.

<div class="p"><!----></div>
Das Thema „Cluster für Datacenter“ ist Thema des Kapitels 22 (16 Seiten). Es 
behandelt die Vorbetrachtungen, das Setup und das Feintuning, gefolgt von 
Geo-Replication etc. und einem abschließenden Fazit.

<div class="p"><!----></div>
In Kapitel 23 (14 Seiten) geht es um iSCSI im Cluster, d.&nbsp;h. die Nutzung des 
SCSI-Protokolls über TCP.

<div class="p"><!----></div>
Der letzte Teil IV fast vier Kapitel zu Debugging im Cluster zusammen.

<div class="p"><!----></div>
Kapitel 24 (21 Seiten) hat das Thema „Node-Fencing mit STONITH“  und 
beschäftigt sich mit der Konsistenz-Sicherheit im Cluster, gefolgt von 
Kapitel 25 (sieben Seiten) mit dem eigentlichen Debuggen.

<div class="p"><!----></div>
Das Kapitel 26 (56 Seiten) beschäftigt sich dann mit der Virtualisierung im 
Cluster und stellt zu Anfang erstmals die Konzepte vor, gefolgt von Xen und 
KVM.

<div class="p"><!----></div>
In Kapitel 27 (16 Seiten) werden das Backup und das Disaster Recovery behandelt.

<div class="p"><!----></div>
Im Anhang (40 Seiten) finden sich die Beispieldateien, die Paketlisten und 
so manche Manpage.

<div class="p"><!----></div>
Am Ende folgt das Stichwortverzeichnis mit insgesamt 18 Seiten.

<div class="p"><!----></div>

<h2>Wie liest es sich?</h2>


Das Buch ist für den Linux-Profi geschrieben, der sich praxisnah in 
Hochverfügbarkeit einarbeiten oder hier sein Wissen vertiefen will. Sehr 
gute Kenntnisse über Linux sind Voraussetzung. Für den Anfänger ist das Buch 
nicht geeignet.

<div class="p"><!----></div>
Das Buch liest sich sehr gut. Fast jedes Kapitel wird mit einem netten, 
teilweise humorvollen, amüsanten Einstieg eingeleitet, was dazu beiträgt, 
dass man trotz des komplexen, anspruchsvollen Themas das Buch nicht beiseite 
legt, auch wenn es doch einen stattlichen Umfang von über 800 Seiten hat, 
der so manchen doch abschrecken könnte. Der Aufbau der Kapitel ist fast 
immer gleich: Einstieg, Einführung in das Thema und theoretische 
Vorbetrachtungen und dann die konkreten Praxisbeispiele mit Beispieldateien. 
Ein Fazit mit einer kritischen Betrachtung schließt meist das Kapitel ab.

<div class="p"><!----></div>
Die Beispiele bzw. Kommandos lassen sich gut nachvollziehen. Man kann der 
Beschreibung gut folgen und auch der schon erfahrene Leser findet das eine 
oder andere interessante Kapitel. 

<div class="p"><!----></div>
Man darf aber nicht den Zeitaufwand unterschätzen, vom Lesen des Buches beziehungsweise
der einzelnen Kapitel bis zum Ausprobieren direkt am Rechner.

<div class="p"><!----></div>

<h2>Kritik</h2>


Das Buch ist für Linux-Profis geschrieben und für diese auch sehr gut geeignet. Man 
merkt deutlich, dass der Autor viel Erfahrung und Wissen zu diesem Thema 
hat und stets vermittelt er, dass er weiß, wovon er schreibt. Besonders muss 
man hier die vielen Praxisbeispiele hervorheben, die das Buch von Anfang bis 
Ende durchziehen und spannend, interessant und sehr hilfreich sind. 
Konzepte und Tools, die sich nicht bewährt haben, werden vom Autor konsequent 
dargestellt und genannt. 

<div class="p"><!----></div>
Das Stichwortverzeichnis ist für den Buchumfang sehr gut und man findet die 
entsprechenden Stellen schnell. Das Buch hat in der zweiten Auflage ein 
Hardcover, mit Daumenkino für die Kapitel und zusätzlichem Bändchen als 
Einlage.

<div class="p"><!----></div>
Das Preis-Leistungs-Verhältnis (Buch, Umfang und Preis) ist 
gut und wirkt nicht überteuert.

<div class="p"><!----></div>
Insgesamt betrachtet muss man die zweite Auflage als sehr gut bewerten und die 
anfangs gesetzten Erwartungen wurden voll erfüllt – ein „Sternchen“ zum „Sehr 
gut“ kann hier ohne Bedenken erteilt werden. 

<div class="p"><!----></div>
Das Buch kann als umfassender Leitfaden und als Referenzwerk für HA-Clustering 
und HA-Storage-Clustering unter Linux genannt werden und wird einen 
dauerhaften Platz neben meinem Schreibtisch finden.

<div class="p"><!----></div>
<b>Redaktioneller Hinweis:</b> <i></i> Galileo Computing war so freundlich und hat ein zweites
Exemplar des Buches zur Verlosung zur Verfügung gestellt.
Dazu ist folgende Frage zu beantworten:

<div class="p"><!----></div>
„<em>Wofür steht die Abkürzung HA?</em>“

<div class="p"><!----></div>


Die Antwort kann bis zum <b>8. Dezember 2013, 23:59 Uhr</b> über die 
Kommentarfunktion oder per E-Mail an redaktion@freiesmagazin.de geschickt 
werden. Die Kommentare werden bis zum Ende der Verlosung nicht 
freigeschaltet. Das Buch wird unter allen Einsendern, die die Frage richtig 
beantworten konnten, verlost.

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="2" align="center"><b>Buchinformationen</b></td></tr>
<tr><td><b>Titel</b> </td><td>Linux Hochverfügbarkeit&nbsp;<a href="http://www.galileocomputing.de/katalog/buecher/titel/gp/titelID-3420">[1]</a> </td></tr>
<tr><td><b>Autor</b> </td><td>Oliver Liebel  </td></tr>
<tr><td><b>Verlag</b> </td><td>Galileo Computing, 2013 </td></tr>
<tr><td><b>Umfang</b> </td><td>848 Seiten </td></tr>
<tr><td><b>ISBN</b> </td><td>978-3-8362-2542-7 </td></tr>
<tr><td><b>Preis</b> </td><td>49,90 € (Druck), 44,90 € (Online), 59,90 € (Buch und Online)
        </td></tr></table>
<br />

<div class="p"><!----></div>
    <font color="#595959"><font size="+1">Links</font></font><br />
        
[1] <a href="http://www.galileocomputing.de/katalog/buecher/titel/gp/titelID-3420"><tt class="big">http://www.galileocomputing.de/katalog/buecher/titel/gp/titelID-3420</tt></a><br />
    

<div class="p"><!----></div>
        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="1" align="center"><b>Autoreninformation</b></td></tr>
<tr><td align="left"><b>Michael Niedermair</b>
ist Lehrer an der <a href="http://www.bsinfo.musin.de/">Münchener IT-Schule</a> und 
Koordinator für den Bereich Programmierung und Anwendungsentwicklung und 
unterrichtet seit 2005 Linux.
    </td></tr></table>
<br />

<div class="p"><!----></div>
        <a href="http://www.freiesmagazin.de/comment/reply/351?edit[subject]=Rezension: Linux Hochverf%C3%BCgbarkeit - Einsatzszenarien und Praxisl%C3%B6sungen#comment-form"><i>Diesen Artikel kommentieren</i></a><br /><br />
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
    






                        
<h1><font color="#595959"><a id="fm_13_12_veranstaltungen" name="fm_13_12_veranstaltungen">Veranstaltungskalender</a></font></h1>


        
<table border="1" cellspacing="0" cellpadding="3">
<tr><td colspan="5" align="center"><b>Messen</b></td></tr>
<tr><td align="left"><b>Veranstaltung</b> </td><td><b>Ort</b> </td><td align="left"><b>Datum</b> </td><td><b>Eintritt</b> </td><td align="left"><b>Link</b> </td></tr>
<tr><td align="left">
Chaos Communication Congress </td><td>Hamburg </td><td align="left">27.12.–30.12.2013 </td><td>80 EUR </td><td align="left"><a href="https://events.ccc.de/congress/2013"><tt class="big">https://events.ccc.de/congress/2013</tt></a> </td></tr>
<tr><td align="left">Global Game Jam </td><td>Weltweit </td><td align="left">24.01.–26.01.2014 </td><td>frei </td><td align="left"><a href="http://globalgamejam.org/"><tt class="big">http://globalgamejam.org/</tt></a> </td></tr>
<tr><td align="left">FOSDEM </td><td>Brüssel </td><td align="left">01.02.–02.02.2014 </td><td>– </td><td align="left"><a href="https://fosdem.org/"><tt class="big">https://fosdem.org/</tt></a> </td></tr>
<tr><td align="left">CeBIT </td><td>Hannover </td><td align="left">10.03.–14.03.2014 </td><td>60 EUR </td><td align="left"><a href="https://www.cebit.de/"><tt class="big">https://www.cebit.de/</tt></a> </td></tr>
<tr><td align="left">Chemnitzer Linux-Tage </td><td>Chemnitz </td><td align="left">15.03.–16.03.2014 </td><td>8 EUR </td><td align="left"><a href="http://chemnitzer.linux-tage.de/"><tt class="big">http://chemnitzer.linux-tage.de/</tt></a> </td></tr>
<tr><td align="left">FOSSGIS </td><td>Berlin </td><td align="left">19.03.–21.03.2014 </td><td>– </td><td align="left"><a href="https://www.fossgis.de/konferenz/2014/"><tt class="big">https://www.fossgis.de/konferenz/2014/</tt></a> </td></tr>
<tr><td align="left">Easterhegg </td><td>Stuttgart </td><td align="left">18.04.–21.04.2014 </td><td>– </td><td align="left"><a href="https://eh14.easterhegg.eu/"><tt class="big">https://eh14.easterhegg.eu/</tt></a> </td></tr>
</table>

    <font size="-1">(Alle Angaben ohne Gewähr!)</font>

<div class="p"><!----></div>
    Sie kennen eine Linux-Messe, welche noch nicht auf der Liste zu
    finden ist? Dann schreiben Sie eine E-Mail mit den Informationen zu
    Datum und Ort an <img src="freiesMagazin-2013-12-bilder-Dateien/redaktionmail.png" alt="redaktion ETT freiesmagazin PUNKT de" height="17" width="168" align="top" />.


<div class="p"><!----></div>
<a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
                        
<h1><font color="#595959"><a id="fm_13_12_vorschau" name="fm_13_12_vorschau">Vorschau</a></font></h1>


<b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> erscheint am ersten Sonntag eines Monats. Die Januar-Ausgabe
wird voraussichtlich am 5. Januar u.&nbsp;a. mit folgenden Themen veröffentlicht:

<ul>
<li> Rezension: SQLite</li>
<li> Rezension: Eclipse IDE kurz&nbsp;&amp;&nbsp;gut</li>
</ul>
Es kann leider vorkommen, dass wir aus internen Gründen angekündigte Artikel verschieben müssen. Wir bitten dafür um Verständnis.

<div class="p"><!----></div>
<a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
                            
<h1><font color="#595959"><a id="fm_13_12_konventionen" name="fm_13_12_konventionen">Konventionen</a></font></h1>


    An einigen Stellen benutzen wir Sonderzeichen mit einer bestimmten
    Bedeutung. Diese sind hier zusammengefasst:<br />
        
<table>
<tr><td><b><tt class="big">$</tt></b>:  </td><td align="left">Shell-Prompt </td></tr>
<tr><td><b><tt class="big">#</tt></b>:  </td><td align="left">Prompt einer Root-Shell – Ubuntu-Nutzer können
                      hier auch einfach in einer normalen Shell ein
                      <b><tt class="big">sudo</tt></b> vor die Befehle setzen.</td></tr>
<tr><td><b><tt class="big">~</tt></b>: </td><td align="left">Abkürzung für das eigene Benutzerverzeichnis
                      <b><tt class="big">/home/BENUTZERNAME</tt></b> </td></tr></table>
            <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>
                                    
<h1><font color="#595959"><a id="fm_13_12_impressum" name="fm_13_12_impressum">Impressum <font size="+1">ISSN 1867-7991</font></a></font></h1>


    <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> erscheint als PDF, EPUB und HTML einmal monatlich.<br />
    Erscheinungsdatum: 1. Dezember 2013<br />

<div class="p"><!----></div>
    
<table>
<tr><td align="left"><b>Kontakt</b></td></tr>
<tr><td align="left">E-Mail </td><td align="left"><img src="freiesMagazin-2013-12-bilder-Dateien/redaktionmail.png" alt="redaktion ETT freiesmagazin PUNKT de" height="17" width="168" align="top" /> </td></tr>
<tr><td align="left">Postanschrift </td><td align="left"><b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> </td></tr>
<tr><td align="left"></td><td align="left">c/o Dominik Wagenführ </td></tr>
<tr><td align="left"></td><td align="left">Beethovenstr. 9/1 </td></tr>
<tr><td align="left"></td><td align="left">71277 Rutesheim </td></tr>
<tr><td align="left">Webpräsenz </td><td align="left"><a href="http://www.freiesmagazin.de/">http://www.freiesmagazin.de/</a> </td></tr>

<tr><td align="left"><b>Autoren dieser Ausgabe</b></td></tr>
<tr><td align="left">Hans-Joachim Baader </td><td align="left"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_ubuntu_und_kubuntu_13_10">Ubuntu und Kubuntu 13.10</a>, <a href="freiesMagazin-2013-12-bilder.html#fm_13_12_openvpn">Mit OpenVPN Firmen-Firewalls überwinden</a>  </td></tr>
<tr><td align="left">Markus Herrmann </td><td align="left"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_gpu_computing">GPU-Computing mit R</a>  </td></tr>
<tr><td align="left">Markus Lilienthal </td><td align="left"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_gpu_computing">GPU-Computing mit R</a>  </td></tr>
<tr><td align="left">Martin Manns </td><td align="left"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_tabellenkalkulationen">Diagramme in Linux – Vier Tabellenkalkulationen im Vergleich</a>  </td></tr>
<tr><td align="left">Mathias Menzer </td><td align="left"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_kernel">Der November im Kernelrückblick</a>  </td></tr>
<tr><td align="left">Michael Niedermair </td><td align="left"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_rezension_linux_hochverfuegbarkeit">Rezension: Linux Hochverfügbarkeit – Einsatzszenarien und Praxislösungen</a>  </td></tr>
<tr><td align="left">Maria Seliger </td><td align="left"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_aequivalente_windows_programme_2">Äquivalente Windows-Programme unter Linux – Teil 2</a>  </td></tr>
<tr><td align="left">Dominik Wagenführ </td><td align="left"><a href="freiesMagazin-2013-12-bilder.html#fm_13_12_dante_herbst2013">Rückblick: DANTE-Herbsttagung in Köln 2013</a>, <a href="freiesMagazin-2013-12-bilder.html#fm_13_12_rezension_technisches_schreiben">Rezension: Technisches Schreiben</a>  </td></tr>

<tr><td align="left">
<div class="p"><!----></div>
<b>Redaktion</b></td></tr>
<tr><td align="left">Matthias Sitte </td><td align="left"></td></tr>
<tr><td align="left">Dominik Wagenführ (Verantwortlicher Redakteur) </td></tr>

<tr><td align="left"><b>Satz und Layout</b></td></tr>
<tr><td align="left">Dominik Frey </td><td align="left">Moritz Kiefer </td></tr>
<tr><td align="left">Christoph Lehmann </td><td align="left"></td></tr>

<tr><td align="left"><b>Korrektur</b></td></tr>
<tr><td align="left">Daniel Braun </td><td align="left">Frank Brungräber </td></tr>
<tr><td align="left">Vicki Ebeling </td><td align="left">Stefan Fangmeier </td></tr>
<tr><td align="left">Mathias Menzer </td><td align="left">Christian Schnell </td></tr>
<tr><td align="left">Karsten Schuldt </td><td align="left">Toni Zimmer </td></tr>

<tr><td align="left"><b>Veranstaltungen</b></td></tr>
<tr><td align="left">Ronny Fischer </td></tr>

<tr><td align="left"><b>Logo-Design</b></td></tr>
<tr><td align="left">Arne Weinberg (<a href="http://creativecommons.org/licenses/by-sa/3.0/deed.de">CC-BY-SA 3.0 Unported</a>) </td></tr></table>


<div class="p"><!----></div>
    Dieses Magazin wurde mit LaTeX erstellt. Mit vollem Namen
    gekennzeichnete Beiträge geben nicht notwendigerweise die Meinung
    der Redaktion wieder. Wenn Sie <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> ausdrucken möchten, dann
    denken Sie bitte an die Umwelt und drucken Sie nur im Notfall. Die
    Bäume werden es Ihnen danken. ;-) <br />

<div class="p"><!----></div>
        Soweit nicht anders angegeben, stehen alle Artikel, Beiträge und Bilder in
    <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> unter der&nbsp;<a href="http://creativecommons.org/licenses/by-sa/3.0/deed.de">Creative-Commons-Lizenz CC-BY-SA 3.0 Unported</a>. Das Copyright liegt
    beim jeweiligen Autor. <b><font color="#595959">freies</font></b><font color="#FF630A">Magazin</font> unterliegt als Gesamtwerk ebenso
    der&nbsp;<a href="http://creativecommons.org/licenses/by-sa/3.0/deed.de">Creative-Commons-Lizenz CC-BY-SA 3.0 Unported</a> mit Ausnahme der
    Inhalte, die unter einer anderen Lizenz hierin veröffentlicht
    werden. Das Copyright liegt bei Dominik Wagenführ. Es wird erlaubt,
    das Werk/die Werke unter den Bestimmungen der Creative-Commons-Lizenz
    zu kopieren, zu verteilen und/oder zu modifizieren.
    Die xkcd-Comics stehen separat unter der&nbsp;<a href="http://creativecommons.org/licenses/by-nc/2.5/">Creative-Commons-Lizenz CC-BY-NC 2.5 Generic</a>. Das Copyright liegt
    bei&nbsp;<a href="http://www.xkcd.com/">Randall Munroe</a>.<br />

<div class="p"><!----></div>
    <a href="freiesMagazin-2013-12-bilder.html#fm_index">Zum Index</a><br /><hr class="sigilChapterBreak" />

<div class="p"><!----></div>

<small>File translated from
T<sub><font size="-1">E</font></sub>X
by <a href="http://hutchinson.belmont.ma.us/tth/">
T<sub><font size="-1">T</font></sub>H</a>,
version 3.89.<br />On  1 Dec 2013, 15:19.</small>
</div>
</body></html>
